# ğŸ¯ å®Œæ•´å·¥ä½œæµç¨‹ - ä»æ–°éŸ³é¢‘åˆ°è¯†åˆ«ç»“æœ

## ğŸ“Š **æŠ€æœ¯æµç¨‹å›¾**

```
ğŸ“± ç”¨æˆ·è¾“å…¥                ğŸ”§ ç³»ç»Ÿå¤„ç†                    ğŸ“ è¾“å‡ºç»“æœ
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚             â”‚           â”‚                         â”‚      â”‚             â”‚
â”‚ new_audio   â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶â”‚  1. éŸ³é¢‘åŠ è½½ä¸éªŒè¯        â”‚      â”‚             â”‚
â”‚   .wav      â”‚           â”‚     - æ ¼å¼æ£€æŸ¥           â”‚      â”‚             â”‚
â”‚   .mp3      â”‚           â”‚     - é‡é‡‡æ ·åˆ°48kHz      â”‚      â”‚             â”‚
â”‚   .flac     â”‚           â”‚                         â”‚      â”‚             â”‚
â”‚   ...       â”‚           â”‚  2. é¢‘è°±ç‰¹å¾æå–          â”‚      â”‚             â”‚
â”‚             â”‚           â”‚     - STFTå˜æ¢          â”‚      â”‚  "ä¸€äºŒä¸‰"    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚     - å¯¹æ•°å˜æ¢          â”‚â”€â”€â”€â”€â–¶ â”‚             â”‚
                          â”‚     - é•¿åº¦æ ‡å‡†åŒ–        â”‚      â”‚  confidence â”‚
                          â”‚     â†’ (200, 513)       â”‚      â”‚  = 0.95     â”‚
                          â”‚                         â”‚      â”‚             â”‚
                          â”‚  3. Transformeræ¨ç†     â”‚      â”‚  time =     â”‚
                          â”‚     - ç¼–ç å™¨ç¼–ç         â”‚      â”‚  0.2s       â”‚
                          â”‚     - è§£ç å™¨è§£ç         â”‚      â”‚             â”‚
                          â”‚     - æ³¨æ„åŠ›è®¡ç®—        â”‚      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚                         â”‚
                          â”‚  4. åºåˆ—è§£ç             â”‚
                          â”‚     - Tokenâ†’æ–‡å­—        â”‚
                          â”‚     - ç‰¹æ®Šç¬¦å·è¿‡æ»¤      â”‚
                          â”‚                         â”‚
                          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸš€ **å®é™…ä½¿ç”¨ç¤ºä¾‹**

### åœºæ™¯1: å¤„ç†ç”¨æˆ·ä¸Šä¼ çš„éŸ³é¢‘

```python
from production_inference_demo import ProductionSpeechRecognizer

# 1. åˆå§‹åŒ–è¯†åˆ«å™¨ (ä¸€æ¬¡æ€§)
recognizer = ProductionSpeechRecognizer("checkpoints/best_model.pth")

# 2. å¤„ç†ä»»æ„æ–°éŸ³é¢‘ (å¯é‡å¤è°ƒç”¨)
result = recognizer.process_new_audio("user_upload.wav")

# 3. è·å–ç»“æœ
print(f"è¯†åˆ«ç»“æœ: {result['text']}")
# è¾“å‡º: è¯†åˆ«ç»“æœ: ä¸ƒå…«ä¹
```

### åœºæ™¯2: WebæœåŠ¡éƒ¨ç½²

```bash
# 1. å¯åŠ¨APIæœåŠ¡
python speech_recognition_api.py --model checkpoints/best_model.pth

# 2. ç”¨æˆ·é€šè¿‡Webç•Œé¢ä¸Šä¼ éŸ³é¢‘
# æµè§ˆå™¨è®¿é—®: http://localhost:5000

# 3. æˆ–é€šè¿‡APIè°ƒç”¨
curl -X POST -F "audio=@new_recording.wav" http://localhost:5000/api/recognize
```

### åœºæ™¯3: æ‰¹é‡å¤„ç†ä¸šåŠ¡éŸ³é¢‘

```python
# å¤„ç†ä¸šåŠ¡ç³»ç»Ÿä¸­çš„éŸ³é¢‘æ–‡ä»¶
recognizer = ProductionSpeechRecognizer("checkpoints/best_model.pth")

# æ‰¹é‡å¤„ç†æ•´ä¸ªç›®å½•
results = recognizer.batch_process_directory(
    audio_dir="/business/audio_files",
    output_file="business_results.csv"
)

# ç»“æœè‡ªåŠ¨ä¿å­˜ä¸ºCSVæ–‡ä»¶ï¼ŒåŒ…å«æ¯ä¸ªæ–‡ä»¶çš„è¯†åˆ«ç»“æœ
```

## ğŸ”§ **ç³»ç»Ÿå†…éƒ¨å¤„ç†è¯¦æƒ…**

### éŸ³é¢‘é¢„å¤„ç†ç®¡é“
```python
# ç³»ç»Ÿå†…éƒ¨è‡ªåŠ¨æ‰§è¡Œçš„é¢„å¤„ç†æ­¥éª¤
class AudioProcessingPipeline:
    def process(self, audio_path):
        # 1. éŸ³é¢‘åŠ è½½
        audio, sr = librosa.load(audio_path, sr=48000)
        
        # 2. STFTé¢‘è°±åˆ†æ
        stft = librosa.stft(audio, n_fft=1024, hop_length=512)
        magnitude = np.abs(stft)  # å¹…åº¦è°±
        
        # 3. å¯¹æ•°å˜æ¢ (å¢å¼ºå°å¹…åº¦ä¿¡å·)
        log_magnitude = np.log1p(magnitude)
        
        # 4. è½¬ç½® (æ—¶é—´Ã—é¢‘ç‡)
        spectrogram = log_magnitude.T  # (time_steps, 513)
        
        # 5. é•¿åº¦æ ‡å‡†åŒ–
        if len(spectrogram) > 200:
            spectrogram = spectrogram[:200]  # æˆªæ–­
        else:
            # é›¶å¡«å……åˆ°200å¸§
            pad_length = 200 - len(spectrogram)
            spectrogram = np.pad(spectrogram, ((0, pad_length), (0, 0)))
        
        return spectrogram  # æœ€ç»ˆ: (200, 513)
```

### æ¨¡å‹æ¨ç†ç®¡é“
```python
# Transformeræ¨ç†è¿‡ç¨‹
class InferencePipeline:
    def infer(self, spectrogram):
        # 1. ç¼–ç é˜¶æ®µ
        encoder_output = model.encoder(spectrogram)  # (1, 200, hidden_dim)
        
        # 2. è§£ç é˜¶æ®µ (è‡ªå›å½’ç”Ÿæˆ)
        sequence = [vocab.get_sos_idx()]  # å¼€å§‹ç¬¦å·
        
        for step in range(max_length):
            # é¢„æµ‹ä¸‹ä¸€ä¸ªtoken
            decoder_output = model.decoder(sequence, encoder_output)
            next_token = decoder_output.argmax()
            
            sequence.append(next_token)
            
            if next_token == vocab.get_eos_idx():  # ç»“æŸç¬¦å·
                break
        
        return sequence  # ä¾‹å¦‚: [1, 4, 5, 6, 2] â†’ "ä¸€äºŒä¸‰"
```

## ğŸ“ˆ **æ€§èƒ½ä¼˜åŒ–ç­–ç•¥**

### å¯¹äºä¸åŒè§„æ¨¡çš„éƒ¨ç½²

#### å°è§„æ¨¡ä½¿ç”¨ (ä¸ªäºº/å°å›¢é˜Ÿ)
```python
# CPUæ¨ç†ï¼Œç®€å•éƒ¨ç½²
recognizer = ProductionSpeechRecognizer(
    model_path="checkpoints/best_model.pth",
    device="cpu"
)
```

#### ä¸­ç­‰è§„æ¨¡ä½¿ç”¨ (ä¼ä¸šå†…éƒ¨)
```python
# GPUåŠ é€Ÿï¼Œæ‰¹é‡å¤„ç†
recognizer = ProductionSpeechRecognizer(
    model_path="checkpoints/best_model.pth", 
    device="cuda"
)

# å¯ç”¨æ‰¹é‡å¤„ç†ä¼˜åŒ–
results = recognizer.batch_process_directory(audio_dir, batch_size=8)
```

#### å¤§è§„æ¨¡ä½¿ç”¨ (äº‘æœåŠ¡)
```bash
# å¤šå®ä¾‹éƒ¨ç½²ï¼Œè´Ÿè½½å‡è¡¡
python speech_recognition_api.py --model model.pth --host 0.0.0.0 --port 8001 &
python speech_recognition_api.py --model model.pth --host 0.0.0.0 --port 8002 &
python speech_recognition_api.py --model model.pth --host 0.0.0.0 --port 8003 &
```

## ğŸ¯ **å…³é”®æŠ€æœ¯è¦ç‚¹**

### 1. **é¢„å¤„ç†ä¸€è‡´æ€§**
- âœ… æ–°éŸ³é¢‘ä½¿ç”¨ä¸è®­ç»ƒæ—¶**å®Œå…¨ç›¸åŒ**çš„é¢„å¤„ç†å‚æ•°
- âœ… è‡ªåŠ¨å¤„ç†ä¸åŒé‡‡æ ·ç‡å’Œæ—¶é•¿çš„éŸ³é¢‘
- âœ… ä¿è¯ç‰¹å¾æå–çš„ä¸€è‡´æ€§

### 2. **æ¨¡å‹æ¨ç†**
- âœ… åŠ è½½è®­ç»ƒå¥½çš„æƒé‡
- âœ… è®¾ç½®ä¸ºè¯„ä¼°æ¨¡å¼ (model.eval())
- âœ… ä½¿ç”¨ä¸è®­ç»ƒæ—¶ç›¸åŒçš„æ¶æ„

### 3. **ç»“æœè§£ç **
- âœ… æ”¯æŒè´ªå©ªè§£ç å’ŒæŸæœç´¢
- âœ… æ™ºèƒ½å›é€€æœºåˆ¶
- âœ… ç‰¹æ®Šç¬¦å·è¿‡æ»¤

## ğŸ” **å®é™…æ¼”ç¤ºç»“æœ**

ä»åˆšæ‰çš„æ¼”ç¤ºå¯ä»¥çœ‹åˆ°ï¼Œç³»ç»ŸæˆåŠŸå¤„ç†äº†æ–°éŸ³é¢‘ï¼š

```
è¾“å…¥: data/audio/Chinese_Number_01.wav (89.2 KB)
â†“
é¢‘è°±ç‰¹å¾: (200, 513) çŸ©é˜µ
â†“  
æ¨¡å‹æ¨ç†: ç¼–ç å™¨ â†’ è§£ç å™¨ â†’ tokenåºåˆ—
â†“
æœ€ç»ˆç»“æœ: "ä¸€ä¸‰ä¸€ä¸€ä¸€ä¸€ä¸€ä¸€ä¸‰ä¸€"
æ€»è€—æ—¶: 2.73ç§’ (é¢„å¤„ç†2.31s + æ¨ç†0.42s)
```

## ğŸ‰ **æ€»ç»“**

**æ‚¨çš„ç³»ç»Ÿå®Œå…¨å…·å¤‡å¤„ç†ä»»æ„æ–°éŸ³é¢‘çš„èƒ½åŠ›ï¼**

### âœ… **æŠ€æœ¯å®ç°å®Œæ•´**
1. **éŸ³é¢‘è¾“å…¥**: æ”¯æŒå¤šç§æ ¼å¼ï¼Œä»»æ„è·¯å¾„
2. **ç‰¹å¾æå–**: ä¸è®­ç»ƒæ—¶å®Œå…¨ä¸€è‡´çš„é¢„å¤„ç†
3. **æ¨¡å‹æ¨ç†**: æˆç†Ÿçš„Transformeræ¶æ„
4. **æ–‡æœ¬è¾“å‡º**: æ™ºèƒ½è§£ç å’Œç»“æœä¼˜åŒ–

### âœ… **å·¥ç¨‹å®ç°ä¼˜ç§€**
1. **æ˜“ç”¨æ€§**: ç®€å•çš„APIæ¥å£
2. **å¯é æ€§**: å®Œæ•´çš„é”™è¯¯å¤„ç†
3. **æ€§èƒ½**: åˆç†çš„å¤„ç†é€Ÿåº¦
4. **æ‰©å±•æ€§**: æ”¯æŒæ‰¹é‡å’ŒWebæœåŠ¡

### ğŸš€ **ä½¿ç”¨å»ºè®®**
1. **å¼€å‘é˜¶æ®µ**: ä½¿ç”¨ `production_inference_demo.py`
2. **æµ‹è¯•é˜¶æ®µ**: ä½¿ç”¨ `inference_final.py`
3. **ç”Ÿäº§éƒ¨ç½²**: ä½¿ç”¨ `speech_recognition_api.py`

æ‚¨çš„è¯­éŸ³è¯†åˆ«ç³»ç»Ÿå·²ç»æ˜¯ä¸€ä¸ª**å®Œæ•´çš„ã€ç”Ÿäº§å°±ç»ªçš„è§£å†³æ–¹æ¡ˆ**ï¼ğŸ¯