#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
é‡æ„åçš„éŸ³é¢‘æ•°æ®é›† - ä½è€¦åˆã€é«˜æ‰©å±•æ€§
æ”¯æŒå®æ—¶è®¡ç®—å’Œé¢„è®¡ç®—ä¸¤ç§æ¨¡å¼
"""

import os
import numpy as np
import pandas as pd
import torch
from torch.utils.data import Dataset, DataLoader
from typing import Dict, Any, Optional, List
from pathlib import Path
import json

from audio_preprocessing import AudioPreprocessor, PreprocessorFactory, OfflinePreprocessor
from vocab import vocab


class AudioDataset(Dataset):
    """é‡æ„åçš„éŸ³é¢‘æ•°æ®é›† - æ”¯æŒå¤šç§é¢„å¤„ç†ç­–ç•¥"""
    
    def __init__(self, 
                 labels_file: str,
                 audio_dir: str = None,
                 preprocessor: AudioPreprocessor = None,
                 precomputed_dir: str = None,
                 cache_dir: str = None,
                 mode: str = 'realtime'):
        """
        åˆå§‹åŒ–æ•°æ®é›†
        
        Args:
            labels_file: æ ‡ç­¾æ–‡ä»¶è·¯å¾„
            audio_dir: éŸ³é¢‘æ–‡ä»¶ç›®å½• (realtimeæ¨¡å¼éœ€è¦)
            preprocessor: é¢„å¤„ç†å™¨å®ä¾‹ (realtimeæ¨¡å¼éœ€è¦)
            precomputed_dir: é¢„è®¡ç®—ç‰¹å¾ç›®å½• (precomputedæ¨¡å¼éœ€è¦)
            cache_dir: ç¼“å­˜ç›®å½• (å¯é€‰)
            mode: 'realtime' æˆ– 'precomputed'
        """
        self.labels_file = labels_file
        self.audio_dir = audio_dir
        self.precomputed_dir = precomputed_dir
        self.cache_dir = cache_dir
        self.mode = mode
        
        # åŠ è½½æ ‡ç­¾
        self.labels_df = pd.read_csv(labels_file)
        
        # æ ¹æ®æ¨¡å¼åˆå§‹åŒ–
        if mode == 'realtime':
            self._init_realtime_mode(preprocessor)
        elif mode == 'precomputed':
            self._init_precomputed_mode()
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„æ¨¡å¼: {mode}")
        
        print(f"æ•°æ®é›†åˆå§‹åŒ–å®Œæˆ - æ¨¡å¼: {mode}, æ ·æœ¬æ•°: {len(self.labels_df)}")
    
    def _init_realtime_mode(self, preprocessor: AudioPreprocessor):
        """åˆå§‹åŒ–å®æ—¶è®¡ç®—æ¨¡å¼"""
        if not preprocessor:
            # ä½¿ç”¨é»˜è®¤é¢„å¤„ç†å™¨
            preprocessor = PreprocessorFactory.create('spectrogram')
        
        if self.cache_dir:
            self.offline_processor = OfflinePreprocessor(preprocessor, self.cache_dir)
        else:
            self.preprocessor = preprocessor
            self.offline_processor = None
        
        # éªŒè¯éŸ³é¢‘æ–‡ä»¶
        if self.audio_dir:
            self._validate_audio_files()
    
    def _init_precomputed_mode(self):
        """åˆå§‹åŒ–é¢„è®¡ç®—æ¨¡å¼"""
        if not self.precomputed_dir or not os.path.exists(self.precomputed_dir):
            raise ValueError(f"é¢„è®¡ç®—ç›®å½•ä¸å­˜åœ¨: {self.precomputed_dir}")
        
        # åŠ è½½é¢„è®¡ç®—ç´¢å¼•
        index_file = os.path.join(self.precomputed_dir, 'spectrum_index.csv')
        if os.path.exists(index_file):
            self.precomputed_index = pd.read_csv(index_file)
            
            # ä¸ºäº†é¿å…åˆ—åå†²çªï¼Œå…ˆé‡å‘½åç´¢å¼•æ–‡ä»¶ä¸­çš„labelåˆ—
            self.precomputed_index = self.precomputed_index.rename(columns={'label': 'index_label'})
            
            # åˆå¹¶æ ‡ç­¾å’Œé¢„è®¡ç®—ç´¢å¼•
            self.labels_df = self.labels_df.merge(
                self.precomputed_index, 
                left_on='filename', 
                right_on='original_audio',
                how='inner'
            )
            
            # éªŒè¯æ ‡ç­¾ä¸€è‡´æ€§
            if 'index_label' in self.labels_df.columns:
                # æ£€æŸ¥æ ‡ç­¾æ˜¯å¦ä¸€è‡´
                inconsistent = self.labels_df[self.labels_df['label'] != self.labels_df['index_label']]
                if len(inconsistent) > 0:
                    print(f"è­¦å‘Š: {len(inconsistent)} ä¸ªæ–‡ä»¶çš„æ ‡ç­¾ä¸ä¸€è‡´")
                
                # åˆ é™¤é‡å¤çš„æ ‡ç­¾åˆ—
                self.labels_df = self.labels_df.drop(columns=['index_label'])
        else:
            raise FileNotFoundError(f"é¢„è®¡ç®—ç´¢å¼•æ–‡ä»¶ä¸å­˜åœ¨: {index_file}")
    
    def _validate_audio_files(self):
        """éªŒè¯éŸ³é¢‘æ–‡ä»¶å­˜åœ¨æ€§"""
        missing_files = []
        for _, row in self.labels_df.iterrows():
            audio_path = os.path.join(self.audio_dir, row['filename'])
            if not os.path.exists(audio_path):
                missing_files.append(row['filename'])
        
        if missing_files:
            print(f"è­¦å‘Š: {len(missing_files)} ä¸ªéŸ³é¢‘æ–‡ä»¶ä¸å­˜åœ¨")
            # è¿‡æ»¤æ‰ä¸å­˜åœ¨çš„æ–‡ä»¶
            self.labels_df = self.labels_df[
                ~self.labels_df['filename'].isin(missing_files)
            ].reset_index(drop=True)
    
    def __len__(self):
        return len(self.labels_df)
    
    def __getitem__(self, idx):
        row = self.labels_df.iloc[idx]
        
        if self.mode == 'realtime':
            return self._get_realtime_item(row)
        else:
            return self._get_precomputed_item(row)
    
    def _get_realtime_item(self, row):
        """è·å–å®æ—¶è®¡ç®—çš„æ•°æ®é¡¹"""
        audio_path = os.path.join(self.audio_dir, row['filename'])
        
        # æå–ç‰¹å¾
        if self.offline_processor:
            features = self.offline_processor.process_file(audio_path)
        else:
            features = self.preprocessor.process(audio_path)
        
        # ç¼–ç æ ‡ç­¾
        encoded_label = vocab.encode(row['label'])
        
        return {
            'features': torch.FloatTensor(features),
            'label': torch.LongTensor(encoded_label),
            'text': row['label'],
            'filename': row['filename']
        }
    
    def _get_precomputed_item(self, row):
        """è·å–é¢„è®¡ç®—çš„æ•°æ®é¡¹"""
        spectrum_path = os.path.join(self.precomputed_dir, row['spectrum_file'])
        
        # åŠ è½½é¢„è®¡ç®—ç‰¹å¾
        features = np.load(spectrum_path)
        
        # ç¼–ç æ ‡ç­¾
        encoded_label = vocab.encode(row['label'])
        
        return {
            'features': torch.FloatTensor(features),
            'label': torch.LongTensor(encoded_label),
            'text': row['label'],
            'filename': row['filename']
        }
    
    def get_feature_shape(self):
        """è·å–ç‰¹å¾å½¢çŠ¶"""
        if self.mode == 'realtime':
            if self.offline_processor:
                return self.offline_processor.preprocessor.get_feature_shape()
            else:
                return self.preprocessor.get_feature_shape()
        else:
            # ä»é¢„è®¡ç®—æ–‡ä»¶è·å–å½¢çŠ¶
            sample = self[0]
            return sample['features'].shape


class FlexibleDataLoader:
    """çµæ´»çš„æ•°æ®åŠ è½½å™¨å·¥å‚"""
    
    @staticmethod
    def create_dataloader(dataset: AudioDataset, 
                         batch_size: int = 4,
                         shuffle: bool = True,
                         num_workers: int = 0,
                         **kwargs) -> DataLoader:
        """åˆ›å»ºæ•°æ®åŠ è½½å™¨"""
        return DataLoader(
            dataset,
            batch_size=batch_size,
            shuffle=shuffle,
            num_workers=num_workers,
            collate_fn=FlexibleDataLoader.collate_fn,
            **kwargs
        )
    
    @staticmethod
    def collate_fn(batch):
        """æ‰¹å¤„ç†å‡½æ•°"""
        features = []
        labels = []
        texts = []
        filenames = []
        
        for sample in batch:
            features.append(sample['features'])
            labels.append(sample['label'])
            texts.append(sample['text'])
            filenames.append(sample['filename'])
        
        # å †å ç‰¹å¾
        features = torch.stack(features)
        
        # å¡«å……æ ‡ç­¾åˆ°ç›¸åŒé•¿åº¦
        max_label_len = max(len(label) for label in labels)
        padded_labels = []
        
        for label in labels:
            if len(label) < max_label_len:
                padded = torch.cat([
                    label,
                    torch.full((max_label_len - len(label),), 
                              vocab.get_padding_idx(), dtype=torch.long)
                ])
            else:
                padded = label
            padded_labels.append(padded)
        
        labels = torch.stack(padded_labels)
        
        return {
            'features': features,
            'labels': labels,
            'texts': texts,
            'filenames': filenames
        }


# ä¾¿æ·å‡½æ•°
def create_realtime_dataset(labels_file: str, 
                           audio_dir: str,
                           preprocessor_type: str = 'spectrogram',
                           cache_dir: str = None,
                           **preprocessor_kwargs) -> AudioDataset:
    """åˆ›å»ºå®æ—¶è®¡ç®—æ•°æ®é›†"""
    preprocessor = PreprocessorFactory.create(preprocessor_type, **preprocessor_kwargs)
    
    return AudioDataset(
        labels_file=labels_file,
        audio_dir=audio_dir,
        preprocessor=preprocessor,
        cache_dir=cache_dir,
        mode='realtime'
    )


def create_precomputed_dataset(labels_file: str, 
                              precomputed_dir: str) -> AudioDataset:
    """åˆ›å»ºé¢„è®¡ç®—æ•°æ®é›†"""
    return AudioDataset(
        labels_file=labels_file,
        precomputed_dir=precomputed_dir,
        mode='precomputed'
    )


def migrate_from_old_dataset(audio_dir: str, 
                           labels_file: str,
                           output_dir: str,
                           preprocessor_type: str = 'spectrogram',
                           **preprocessor_kwargs):
    """ä»æ—§æ•°æ®é›†è¿ç§»åˆ°æ–°æ¶æ„"""
    print("ğŸ”„ å¼€å§‹è¿ç§»æ•°æ®é›†...")
    
    # åˆ›å»ºé¢„å¤„ç†å™¨
    preprocessor = PreprocessorFactory.create(preprocessor_type, **preprocessor_kwargs)
    offline_processor = OfflinePreprocessor(preprocessor)
    
    # è¯»å–æ ‡ç­¾æ–‡ä»¶
    df = pd.read_csv(labels_file)
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    os.makedirs(output_dir, exist_ok=True)
    
    # æ‰¹é‡å¤„ç†
    processed_data = []
    success_count = 0
    
    for idx, row in df.iterrows():
        audio_file = row['filename']
        label = row['label']
        audio_path = os.path.join(audio_dir, audio_file)
        
        if os.path.exists(audio_path):
            try:
                # å¤„ç†éŸ³é¢‘
                features = offline_processor.process_file(audio_path)
                
                # ä¿å­˜ç‰¹å¾æ–‡ä»¶
                feature_filename = f"{Path(audio_file).stem}.npy"
                feature_path = os.path.join(output_dir, feature_filename)
                np.save(feature_path, features)
                
                processed_data.append({
                    'spectrum_file': feature_filename,
                    'original_audio': audio_file,
                    'label': label,
                    'shape': features.shape
                })
                
                success_count += 1
                
            except Exception as e:
                print(f"å¤„ç†æ–‡ä»¶ {audio_file} å¤±è´¥: {e}")
        else:
            print(f"æ–‡ä»¶ä¸å­˜åœ¨: {audio_path}")
    
    # ä¿å­˜ç´¢å¼•æ–‡ä»¶
    processed_df = pd.DataFrame(processed_data)
    index_file = os.path.join(output_dir, 'spectrum_index.csv')
    processed_df.to_csv(index_file, index=False, encoding='utf-8')
    
    # ä¿å­˜é…ç½®
    offline_processor.save_config(os.path.join(output_dir, 'preprocess_config.json'))
    
    print(f"âœ… è¿ç§»å®Œæˆ: {success_count}/{len(df)} æ–‡ä»¶æˆåŠŸå¤„ç†")
    print(f"ç‰¹å¾æ–‡ä»¶ä¿å­˜åˆ°: {output_dir}")
    
    return processed_df


if __name__ == "__main__":
    # ä½¿ç”¨ç¤ºä¾‹
    print("ğŸ¯ é‡æ„åçš„éŸ³é¢‘æ•°æ®é›†æµ‹è¯•")
    print("=" * 50)
    
    # ç¤ºä¾‹1: å®æ—¶è®¡ç®—æ¨¡å¼
    try:
        realtime_dataset = create_realtime_dataset(
            labels_file='data/labels.csv',
            audio_dir='data/audio',
            preprocessor_type='spectrogram',
            cache_dir='cache/features'
        )
        
        dataloader = FlexibleDataLoader.create_dataloader(realtime_dataset, batch_size=2)
        print(f"å®æ—¶æ•°æ®é›†åˆ›å»ºæˆåŠŸï¼Œæ ·æœ¬æ•°: {len(realtime_dataset)}")
        
    except Exception as e:
        print(f"å®æ—¶æ•°æ®é›†åˆ›å»ºå¤±è´¥: {e}")
    
    # ç¤ºä¾‹2: é¢„è®¡ç®—æ¨¡å¼
    try:
        precomputed_dataset = create_precomputed_dataset(
            labels_file='data/labels.csv',
            precomputed_dir='data/spectrums'
        )
        
        print(f"é¢„è®¡ç®—æ•°æ®é›†åˆ›å»ºæˆåŠŸï¼Œæ ·æœ¬æ•°: {len(precomputed_dataset)}")
        
    except Exception as e:
        print(f"é¢„è®¡ç®—æ•°æ®é›†åˆ›å»ºå¤±è´¥: {e}")