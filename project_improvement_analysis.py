#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
é¡¹ç›®æ”¹è¿›åˆ†æè„šæœ¬
å…¨é¢è¯„ä¼°é¡¹ç›®çš„æ”¹è¿›ç©ºé—´å’Œä¼˜åŒ–å»ºè®®
"""

import os
import json
import torch
from pathlib import Path

def analyze_current_project_status():
    """åˆ†æå½“å‰é¡¹ç›®çŠ¶æ€"""
    print("ğŸ” å½“å‰é¡¹ç›®çŠ¶æ€åˆ†æ")
    print("=" * 50)
    
    # æ£€æŸ¥é¡¹ç›®å®Œæ•´æ€§
    core_files = {
        'model.py': 'æ¨¡å‹å®šä¹‰',
        'vocab.py': 'è¯æ±‡è¡¨ç®¡ç†',
        'audio_preprocessing.py': 'éŸ³é¢‘é¢„å¤„ç†',
        'audio_dataset.py': 'æ•°æ®é›†ç®¡ç†',
        'train_small.py': 'å°æ¨¡å‹è®­ç»ƒ',
        'inference_final.py': 'æ¨ç†ç³»ç»Ÿ',
        'data/labels.csv': 'æ ‡ç­¾æ•°æ®',
        'data/features/spectrum_index.csv': 'é¢„è®¡ç®—ç‰¹å¾'
    }
    
    print("ğŸ“‹ æ ¸å¿ƒç»„ä»¶æ£€æŸ¥:")
    for file, desc in core_files.items():
        status = "âœ…" if os.path.exists(file) else "âŒ"
        print(f"  {status} {desc}: {file}")
    
    # æ£€æŸ¥æ•°æ®è§„æ¨¡
    if os.path.exists('data/labels.csv'):
        import pandas as pd
        df = pd.read_csv('data/labels.csv')
        print(f"\nğŸ“Š æ•°æ®è§„æ¨¡:")
        print(f"  æ ·æœ¬æ•°é‡: {len(df)}")
        print(f"  ç±»åˆ«æ•°é‡: {df['label'].nunique()}")
        print(f"  ç±»åˆ«åˆ†å¸ƒ: {df['label'].value_counts().to_dict()}")
    
    return True

def analyze_model_architecture():
    """åˆ†ææ¨¡å‹æ¶æ„çš„æ”¹è¿›ç©ºé—´"""
    print("\nğŸ—ï¸ æ¨¡å‹æ¶æ„åˆ†æ")
    print("=" * 50)
    
    improvements = {
        "âœ… å·²å®ç°çš„ä¼˜ç§€è®¾è®¡": [
            "Transformeræ¶æ„ (ç¼–ç å™¨-è§£ç å™¨)",
            "ä½ç½®ç¼–ç æ”¯æŒåºåˆ—å»ºæ¨¡",
            "æ³¨æ„åŠ›æœºåˆ¶å¤„ç†é•¿åºåˆ—",
            "æ¨¡å—åŒ–è®¾è®¡ä¾¿äºæ‰©å±•",
            "å¤šç§æ¨¡å‹è§„æ¨¡é…ç½®"
        ],
        "ğŸ”§ å¯ä»¥æ”¹è¿›çš„æ–¹é¢": [
            "æ·»åŠ é¢„è®­ç»ƒæ¨¡å‹æ”¯æŒ (å¦‚Wav2Vec2)",
            "å®ç°å¤šå¤´æ³¨æ„åŠ›å¯è§†åŒ–",
            "æ·»åŠ æ®‹å·®è¿æ¥å’Œå±‚å½’ä¸€åŒ–ä¼˜åŒ–",
            "æ”¯æŒå˜é•¿åºåˆ—çš„åŠ¨æ€padding",
            "å®ç°æ¨¡å‹è’¸é¦æŠ€æœ¯"
        ],
        "ğŸš€ é«˜çº§åŠŸèƒ½æ‰©å±•": [
            "æ”¯æŒå¤šè¯­è¨€è¯†åˆ«",
            "æ·»åŠ è¯­è¨€æ¨¡å‹èåˆ",
            "å®ç°ç«¯åˆ°ç«¯ä¼˜åŒ–",
            "æ”¯æŒæµå¼è¯†åˆ«",
            "æ·»åŠ è¯´è¯äººé€‚åº”"
        ]
    }
    
    for category, items in improvements.items():
        print(f"\n{category}:")
        for item in items:
            print(f"  â€¢ {item}")
    
    return improvements

def analyze_training_improvements():
    """åˆ†æè®­ç»ƒè¿‡ç¨‹çš„æ”¹è¿›ç©ºé—´"""
    print("\nğŸ¯ è®­ç»ƒè¿‡ç¨‹æ”¹è¿›åˆ†æ")
    print("=" * 50)
    
    improvements = {
        "âœ… å½“å‰è®­ç»ƒä¼˜åŠ¿": [
            "å¤šç§æ¨¡å‹è§„æ¨¡é…ç½® (small/medium/large)",
            "è‡ªåŠ¨æ•°æ®åŠ è½½å’Œé¢„å¤„ç†",
            "TensorBoardæ—¥å¿—è®°å½•",
            "æ£€æŸ¥ç‚¹ä¿å­˜å’Œæ¢å¤",
            "æ—©åœæœºåˆ¶é˜²æ­¢è¿‡æ‹Ÿåˆ"
        ],
        "ğŸ”§ è®­ç»ƒç­–ç•¥æ”¹è¿›": [
            "å®ç°å­¦ä¹ ç‡é¢„çƒ­ (Warmup)",
            "æ·»åŠ ä½™å¼¦é€€ç«è°ƒåº¦",
            "å®ç°æ¢¯åº¦ç´¯ç§¯æ”¯æŒå¤§æ‰¹æ¬¡",
            "æ·»åŠ æ··åˆç²¾åº¦è®­ç»ƒ",
            "å®ç°è¯¾ç¨‹å­¦ä¹  (Curriculum Learning)"
        ],
        "ğŸ“Š æ•°æ®å¢å¼ºæ”¹è¿›": [
            "æ›´ä¸°å¯Œçš„éŸ³é¢‘å¢å¼º (å·²æœ‰åŸºç¡€ç‰ˆæœ¬)",
            "SpecAugmenté¢‘è°±å¢å¼º",
            "æ—¶é—´æ©ç å’Œé¢‘ç‡æ©ç ",
            "å™ªå£°æ³¨å…¥å’Œæ··å“æ¨¡æ‹Ÿ",
            "å¤šæ¡ä»¶è®­ç»ƒæ•°æ®"
        ]
    }
    
    for category, items in improvements.items():
        print(f"\n{category}:")
        for item in items:
            print(f"  â€¢ {item}")
    
    return improvements

def create_adaptive_configs():
    """åˆ›å»ºè‡ªé€‚åº”é…ç½®æ–‡ä»¶"""
    print("\nâš™ï¸ åˆ›å»ºè‡ªé€‚åº”é…ç½®æ–‡ä»¶")
    print("=" * 50)
    
    configs = {
        "tiny": {
            "description": "è¶…å°æ¨¡å‹ - é€‚åˆå¿«é€Ÿå®éªŒå’Œèµ„æºå—é™ç¯å¢ƒ",
            "config": {
                "experiment_name": "speech_recognition_tiny",
                "batch_size": 1,
                "learning_rate": 0.0001,
                "weight_decay": 1e-5,
                "grad_clip": 0.5,
                "num_epochs": 100,
                "save_every": 20,
                "hidden_dim": 32,
                "encoder_layers": 1,
                "decoder_layers": 1,
                "dropout": 0.1,
                "audio_dir": "data/audio",
                "labels_file": "data/labels.csv"
            }
        },
        "small": {
            "description": "å°æ¨¡å‹ - é€‚åˆå°æ•°æ®é›† (10-100æ ·æœ¬)",
            "config": {
                "experiment_name": "speech_recognition_small",
                "batch_size": 2,
                "learning_rate": 0.00005,
                "weight_decay": 1e-6,
                "grad_clip": 1.0,
                "num_epochs": 200,
                "save_every": 25,
                "hidden_dim": 64,
                "encoder_layers": 2,
                "decoder_layers": 2,
                "dropout": 0.2,
                "audio_dir": "data/audio",
                "labels_file": "data/labels.csv"
            }
        },
        "medium": {
            "description": "ä¸­ç­‰æ¨¡å‹ - é€‚åˆä¸­ç­‰æ•°æ®é›† (100-1000æ ·æœ¬)",
            "config": {
                "experiment_name": "speech_recognition_medium",
                "batch_size": 4,
                "learning_rate": 0.0001,
                "weight_decay": 1e-5,
                "grad_clip": 1.0,
                "num_epochs": 150,
                "save_every": 15,
                "hidden_dim": 128,
                "encoder_layers": 3,
                "decoder_layers": 3,
                "dropout": 0.3,
                "audio_dir": "data/audio",
                "labels_file": "data/labels.csv"
            }
        },
        "large": {
            "description": "å¤§æ¨¡å‹ - é€‚åˆå¤§æ•°æ®é›† (1000+æ ·æœ¬)",
            "config": {
                "experiment_name": "speech_recognition_large",
                "batch_size": 8,
                "learning_rate": 0.0001,
                "weight_decay": 1e-4,
                "grad_clip": 1.0,
                "num_epochs": 100,
                "save_every": 10,
                "hidden_dim": 256,
                "encoder_layers": 4,
                "decoder_layers": 4,
                "dropout": 0.4,
                "audio_dir": "data/audio",
                "labels_file": "data/labels.csv"
            }
        },
        "xlarge": {
            "description": "è¶…å¤§æ¨¡å‹ - é€‚åˆå¤§è§„æ¨¡æ•°æ®é›† (10000+æ ·æœ¬)",
            "config": {
                "experiment_name": "speech_recognition_xlarge",
                "batch_size": 16,
                "learning_rate": 0.0002,
                "weight_decay": 1e-4,
                "grad_clip": 1.0,
                "num_epochs": 50,
                "save_every": 5,
                "hidden_dim": 512,
                "encoder_layers": 6,
                "decoder_layers": 6,
                "dropout": 0.5,
                "audio_dir": "data/audio",
                "labels_file": "data/labels.csv"
            }
        }
    }
    
    # ä¿å­˜é…ç½®æ–‡ä»¶
    os.makedirs('configs', exist_ok=True)
    
    for size, info in configs.items():
        config_file = f"configs/config_{size}.json"
        with open(config_file, 'w', encoding='utf-8') as f:
            json.dump(info['config'], f, indent=2, ensure_ascii=False)
        
        print(f"âœ… {info['description']}")
        print(f"   æ–‡ä»¶: {config_file}")
        print(f"   å‚æ•°: hidden_dim={info['config']['hidden_dim']}, "
              f"layers={info['config']['encoder_layers']}, "
              f"batch_size={info['config']['batch_size']}")
    
    return configs

def analyze_system_improvements():
    """åˆ†æç³»ç»Ÿçº§æ”¹è¿›"""
    print("\nğŸ”§ ç³»ç»Ÿçº§æ”¹è¿›åˆ†æ")
    print("=" * 50)
    
    improvements = {
        "ğŸš€ æ€§èƒ½ä¼˜åŒ–": [
            "GPUåŠ é€Ÿæ”¯æŒ (å·²æœ‰åŸºç¡€)",
            "å¤šè¿›ç¨‹æ•°æ®åŠ è½½",
            "å†…å­˜æ˜ å°„å¤§æ–‡ä»¶å¤„ç†",
            "æ¨¡å‹é‡åŒ–å’Œå‰ªæ",
            "ONNXå¯¼å‡ºæ”¯æŒ"
        ],
        "ğŸ“Š ç›‘æ§å’Œè°ƒè¯•": [
            "æ›´è¯¦ç»†çš„è®­ç»ƒæŒ‡æ ‡",
            "å­¦ä¹ ç‡å’ŒæŸå¤±å¯è§†åŒ–",
            "æ¢¯åº¦ç›‘æ§å’Œåˆ†æ",
            "æ¨¡å‹æƒé‡åˆ†å¸ƒå¯è§†åŒ–",
            "æ¨ç†æ—¶é—´åˆ†æ"
        ],
        "ğŸ”„ å·¥ç¨‹åŒ–æ”¹è¿›": [
            "Dockerå®¹å™¨åŒ–éƒ¨ç½²",
            "REST APIæœåŠ¡",
            "æ‰¹é‡æ¨ç†é˜Ÿåˆ—",
            "æ¨¡å‹ç‰ˆæœ¬ç®¡ç†",
            "A/Bæµ‹è¯•æ¡†æ¶"
        ],
        "ğŸ›¡ï¸ é²æ£’æ€§æå‡": [
            "å¼‚å¸¸å¤„ç†å®Œå–„",
            "è¾“å…¥éªŒè¯å’Œæ¸…æ´—",
            "æ¨¡å‹å¥åº·æ£€æŸ¥",
            "è‡ªåŠ¨é‡è¯•æœºåˆ¶",
            "é™çº§ç­–ç•¥"
        ]
    }
    
    for category, items in improvements.items():
        print(f"\n{category}:")
        for item in items:
            print(f"  â€¢ {item}")
    
    return improvements

def create_parameter_tuning_guide():
    """åˆ›å»ºå‚æ•°è°ƒä¼˜æŒ‡å—"""
    print("\nğŸ“š å‚æ•°è°ƒä¼˜æŒ‡å—")
    print("=" * 50)
    
    guide = {
        "æ•°æ®è§„æ¨¡å¯¹åº”çš„é…ç½®å»ºè®®": {
            "10-50æ ·æœ¬": "ä½¿ç”¨tinyæˆ–smallé…ç½®ï¼Œé«˜dropoutï¼Œä½å­¦ä¹ ç‡",
            "50-200æ ·æœ¬": "ä½¿ç”¨smallé…ç½®ï¼Œé€‚ä¸­dropoutï¼Œæ­£å¸¸å­¦ä¹ ç‡",
            "200-1000æ ·æœ¬": "ä½¿ç”¨mediumé…ç½®ï¼Œæ ‡å‡†å‚æ•°",
            "1000-10000æ ·æœ¬": "ä½¿ç”¨largeé…ç½®ï¼Œå¯ä»¥å¢åŠ æ¨¡å‹å¤æ‚åº¦",
            "10000+æ ·æœ¬": "ä½¿ç”¨xlargeé…ç½®ï¼Œå…¨é¢ä¼˜åŒ–"
        },
        "å…³é”®å‚æ•°è°ƒä¼˜ç­–ç•¥": {
            "hidden_dim": "æ¨¡å‹å®¹é‡ï¼Œæ•°æ®è¶Šå¤šå¯ä»¥è¶Šå¤§ (32â†’512)",
            "encoder/decoder_layers": "æ¨¡å‹æ·±åº¦ï¼Œæ·±åº¦å¢åŠ éœ€è¦æ›´å¤šæ•°æ® (1â†’6)",
            "dropout": "æ­£åˆ™åŒ–å¼ºåº¦ï¼Œå°æ•°æ®é›†ç”¨é«˜dropout (0.1â†’0.5)",
            "learning_rate": "å­¦ä¹ é€Ÿåº¦ï¼Œå°æ•°æ®é›†ç”¨å°å­¦ä¹ ç‡ (1e-5â†’2e-4)",
            "batch_size": "æ‰¹å¤§å°ï¼Œå—å†…å­˜é™åˆ¶ï¼Œå½±å“è®­ç»ƒç¨³å®šæ€§ (1â†’16)",
            "num_epochs": "è®­ç»ƒè½®æ•°ï¼Œå°æ•°æ®é›†éœ€è¦æ›´å¤šè½®æ¬¡ (50â†’200)"
        },
        "åŠ¨æ€è°ƒæ•´å»ºè®®": {
            "è¿‡æ‹Ÿåˆ": "å¢åŠ dropoutï¼Œå‡å°‘æ¨¡å‹å¤§å°ï¼Œå¢åŠ æ•°æ®å¢å¼º",
            "æ¬ æ‹Ÿåˆ": "å¢åŠ æ¨¡å‹å®¹é‡ï¼Œé™ä½dropoutï¼Œå¢åŠ è®­ç»ƒè½®æ•°",
            "è®­ç»ƒä¸ç¨³å®š": "é™ä½å­¦ä¹ ç‡ï¼Œå¢åŠ æ¢¯åº¦è£å‰ªï¼Œå‡å°æ‰¹å¤§å°",
            "æ”¶æ•›å¤ªæ…¢": "å¢åŠ å­¦ä¹ ç‡ï¼Œä½¿ç”¨å­¦ä¹ ç‡è°ƒåº¦ï¼Œæ£€æŸ¥æ•°æ®è´¨é‡"
        }
    }
    
    for category, items in guide.items():
        print(f"\n{category}:")
        for key, value in items.items():
            print(f"  â€¢ {key}: {value}")
    
    # ä¿å­˜è°ƒä¼˜æŒ‡å—
    with open('configs/parameter_tuning_guide.json', 'w', encoding='utf-8') as f:
        json.dump(guide, f, indent=2, ensure_ascii=False)
    
    print(f"\nğŸ“ è°ƒä¼˜æŒ‡å—å·²ä¿å­˜: configs/parameter_tuning_guide.json")
    
    return guide

def suggest_immediate_improvements():
    """å»ºè®®ç«‹å³å¯å®æ–½çš„æ”¹è¿›"""
    print("\nğŸ’¡ ç«‹å³å¯å®æ–½çš„æ”¹è¿›å»ºè®®")
    print("=" * 50)
    
    immediate_improvements = [
        {
            "ä¼˜å…ˆçº§": "ğŸ”¥ é«˜",
            "æ”¹è¿›": "æ•°æ®å¢å¼º",
            "å®æ–½": "python data_augmentation.py",
            "æ•ˆæœ": "æ ·æœ¬æ•°é‡ä»10å¢åŠ åˆ°80+ï¼Œæ˜¾è‘—æå‡å‡†ç¡®ç‡"
        },
        {
            "ä¼˜å…ˆçº§": "ğŸ”¥ é«˜", 
            "æ”¹è¿›": "ä½¿ç”¨æ›´é€‚åˆçš„é…ç½®",
            "å®æ–½": "python train_small.py --config configs/config_small.json",
            "æ•ˆæœ": "æ›´å¥½çš„è¶…å‚æ•°ç»„åˆï¼Œæå‡è®­ç»ƒæ•ˆæœ"
        },
        {
            "ä¼˜å…ˆçº§": "ğŸŸ¡ ä¸­",
            "æ”¹è¿›": "å®ç°å­¦ä¹ ç‡è°ƒåº¦",
            "å®æ–½": "ä¿®æ”¹è®­ç»ƒè„šæœ¬æ·»åŠ CosineAnnealingLR",
            "æ•ˆæœ": "æ›´ç¨³å®šçš„è®­ç»ƒè¿‡ç¨‹"
        },
        {
            "ä¼˜å…ˆçº§": "ğŸŸ¡ ä¸­",
            "æ”¹è¿›": "æ·»åŠ éªŒè¯é›†åˆ†å‰²",
            "å®æ–½": "å®ç°train/validation split",
            "æ•ˆæœ": "æ›´å¥½çš„è¿‡æ‹Ÿåˆç›‘æ§"
        },
        {
            "ä¼˜å…ˆçº§": "ğŸŸ¢ ä½",
            "æ”¹è¿›": "æ¨¡å‹é›†æˆ",
            "å®æ–½": "è®­ç»ƒå¤šä¸ªæ¨¡å‹å¹¶é›†æˆé¢„æµ‹",
            "æ•ˆæœ": "è¿›ä¸€æ­¥æå‡å‡†ç¡®ç‡"
        }
    ]
    
    for improvement in immediate_improvements:
        print(f"\n{improvement['ä¼˜å…ˆçº§']} {improvement['æ”¹è¿›']}:")
        print(f"  å®æ–½æ–¹æ³•: {improvement['å®æ–½']}")
        print(f"  é¢„æœŸæ•ˆæœ: {improvement['æ•ˆæœ']}")
    
    return immediate_improvements

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ¯ é¡¹ç›®æ”¹è¿›åˆ†ææŠ¥å‘Š")
    print("=" * 60)
    
    # åˆ†æå½“å‰çŠ¶æ€
    analyze_current_project_status()
    
    # åˆ†æå„ä¸ªæ–¹é¢çš„æ”¹è¿›ç©ºé—´
    analyze_model_architecture()
    analyze_training_improvements()
    analyze_system_improvements()
    
    # åˆ›å»ºè‡ªé€‚åº”é…ç½®
    create_adaptive_configs()
    
    # åˆ›å»ºå‚æ•°è°ƒä¼˜æŒ‡å—
    create_parameter_tuning_guide()
    
    # å»ºè®®ç«‹å³æ”¹è¿›
    suggest_immediate_improvements()
    
    print(f"\nğŸ‰ åˆ†æå®Œæˆï¼")
    print(f"ğŸ“ é…ç½®æ–‡ä»¶å·²ä¿å­˜åˆ° configs/ ç›®å½•")
    print(f"ğŸ“š è¯¦ç»†æŒ‡å—è¯·æŸ¥çœ‹ç”Ÿæˆçš„æ–‡ä»¶")

if __name__ == "__main__":
    main()