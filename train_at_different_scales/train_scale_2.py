# -*- coding: utf-8 -*-
"""
æ”¹è¿›çš„è®­ç»ƒè„šæœ¬
è§£å†³è¿‡æ‹Ÿåˆé—®é¢˜ï¼Œæ·»åŠ æ•°æ®åˆ†å‰²å’Œæ­£åˆ™åŒ–
"""

import os
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.tensorboard import SummaryWriter
import numpy as np
from tqdm import tqdm
import argparse
import json
from datetime import datetime
from sklearn.model_selection import train_test_split

from model import create_model
from data_utils import AudioSpectrogramDataset, collate_fn
from vocab import vocab


class ImprovedTrainer:
    def __init__(self, model, train_loader, val_loader, device, config):
        self.model = model
        self.train_loader = train_loader
        self.val_loader = val_loader
        self.device = device
        self.config = config

        # ä¼˜åŒ–å™¨ - é™ä½å­¦ä¹ ç‡
        self.optimizer = optim.Adam(
            model.parameters(),
            lr=config['learning_rate'],
            weight_decay=config['weight_decay']
        )

        # å­¦ä¹ ç‡è°ƒåº¦å™¨ - æ›´ä¿å®ˆçš„è®¾ç½®
        self.scheduler = optim.lr_scheduler.ReduceLROnPlateau(
            self.optimizer,
            mode='min',
            factor=0.7,  # æ›´æ¸©å’Œçš„è¡°å‡
            patience=10,  # æ›´å¤§çš„è€å¿ƒ
            min_lr=1e-6
        )

        # æŸå¤±å‡½æ•° - æ·»åŠ æ ‡ç­¾å¹³æ»‘
        self.criterion = nn.CrossEntropyLoss(
            ignore_index=vocab.get_padding_idx(),
            label_smoothing=0.1  # æ ‡ç­¾å¹³æ»‘é˜²æ­¢è¿‡æ‹Ÿåˆ
        )

        # æ—¥å¿—
        self.writer = SummaryWriter(f"runs/{config['experiment_name']}")

        # è®­ç»ƒçŠ¶æ€
        self.epoch = 0
        self.best_val_loss = float('inf')
        self.train_losses = []
        self.val_losses = []
        self.patience_counter = 0
        self.max_patience = 20  # æ—©åœè€å¿ƒ

    def train_epoch(self):
        """è®­ç»ƒä¸€ä¸ªepoch"""
        self.model.train()
        total_loss = 0
        num_batches = len(self.train_loader)

        progress_bar = tqdm(self.train_loader, desc=f'Epoch {self.epoch + 1}')

        for batch_idx, batch in enumerate(progress_bar):
            # å…¼å®¹æ–°æ—§æ¥å£

            if 'features' in batch:

                spectrograms = batch['features'].to(self.device)

            else:

                spectrograms = (batch['features'] if 'features' in batch else batch['spectrograms']).to(self.device)
            labels = batch['labels'].to(self.device)

            # å‡†å¤‡è¾“å…¥å’Œç›®æ ‡
            tgt_input = labels[:, :-1]
            tgt_output = labels[:, 1:]

            # å‰å‘ä¼ æ’­
            self.optimizer.zero_grad()

            outputs = self.model(spectrograms, tgt_input)

            # è®¡ç®—æŸå¤±
            loss = self.criterion(
                outputs.reshape(-1, outputs.size(-1)),
                tgt_output.reshape(-1)
            )

            # åå‘ä¼ æ’­
            loss.backward()

            # æ¢¯åº¦è£å‰ª
            torch.nn.utils.clip_grad_norm_(self.model.parameters(), self.config['grad_clip'])

            self.optimizer.step()

            total_loss += loss.item()

            # æ›´æ–°è¿›åº¦æ¡
            progress_bar.set_postfix({
                'loss': f'{loss.item():.4f}',
                'avg_loss': f'{total_loss / (batch_idx + 1):.4f}'
            })

            # è®°å½•åˆ°tensorboard
            global_step = self.epoch * num_batches + batch_idx
            self.writer.add_scalar('Train/Loss', loss.item(), global_step)

        avg_loss = total_loss / num_batches
        self.train_losses.append(avg_loss)

        return avg_loss

    def validate(self):
        """éªŒè¯"""
        self.model.eval()
        total_loss = 0
        total_correct = 0
        total_tokens = 0

        with torch.no_grad():
            for batch in tqdm(self.val_loader, desc='Validation'):
                # å…¼å®¹æ–°æ—§æ¥å£

                if 'features' in batch:

                    spectrograms = batch['features'].to(self.device)

                else:

                    spectrograms = (batch['features'] if 'features' in batch else batch['spectrograms']).to(self.device)
                labels = batch['labels'].to(self.device)

                tgt_input = labels[:, :-1]
                tgt_output = labels[:, 1:]

                outputs = self.model(spectrograms, tgt_input)

                loss = self.criterion(
                    outputs.reshape(-1, outputs.size(-1)),
                    tgt_output.reshape(-1)
                )

                total_loss += loss.item()

                # è®¡ç®—å‡†ç¡®ç‡
                predictions = outputs.argmax(dim=-1)
                mask = (tgt_output != vocab.get_padding_idx())
                correct = (predictions == tgt_output) & mask
                total_correct += correct.sum().item()
                total_tokens += mask.sum().item()

        avg_loss = total_loss / len(self.val_loader)
        accuracy = total_correct / total_tokens if total_tokens > 0 else 0

        self.val_losses.append(avg_loss)

        # è®°å½•åˆ°tensorboard
        self.writer.add_scalar('Val/Loss', avg_loss, self.epoch)
        self.writer.add_scalar('Val/Accuracy', accuracy, self.epoch)

        return avg_loss, accuracy

    def save_checkpoint(self, filename):
        """ä¿å­˜æ£€æŸ¥ç‚¹"""
        checkpoint = {
            'epoch': self.epoch,
            'model_state_dict': self.model.state_dict(),
            'optimizer_state_dict': self.optimizer.state_dict(),
            'scheduler_state_dict': self.scheduler.state_dict(),
            'best_val_loss': self.best_val_loss,
            'train_losses': self.train_losses,
            'val_losses': self.val_losses,
            'config': self.config
        }

        torch.save(checkpoint, filename)
        print(f"æ£€æŸ¥ç‚¹å·²ä¿å­˜: {filename}")

    def train(self, num_epochs):
        """å®Œæ•´è®­ç»ƒæµç¨‹"""
        print(f"å¼€å§‹è®­ç»ƒï¼Œå…± {num_epochs} ä¸ªepoch")
        print(f"è®¾å¤‡: {self.device}")
        print(f"æ¨¡å‹å‚æ•°æ•°é‡: {sum(p.numel() for p in self.model.parameters())}")
        print(f"è®­ç»ƒæ ·æœ¬æ•°: {len(self.train_loader.dataset)}")
        print(f"éªŒè¯æ ·æœ¬æ•°: {len(self.val_loader.dataset)}")

        for epoch in range(num_epochs):
            self.epoch = epoch

            # è®­ç»ƒ
            train_loss = self.train_epoch()

            # éªŒè¯
            val_loss, val_acc = self.validate()

            # å­¦ä¹ ç‡è°ƒåº¦
            old_lr = self.optimizer.param_groups[0]['lr']
            self.scheduler.step(val_loss)
            new_lr = self.optimizer.param_groups[0]['lr']

            # æ‰“å°ç»“æœ
            print(f"Epoch {epoch + 1}/{num_epochs}:")
            print(f"  Train Loss: {train_loss:.4f}")
            print(f"  Val Loss: {val_loss:.4f}")
            print(f"  Val Acc: {val_acc:.4f}")
            print(f"  LR: {new_lr:.6f}")

            if new_lr != old_lr:
                print(f"  -> å­¦ä¹ ç‡ä» {old_lr:.6f} é™ä½åˆ° {new_lr:.6f}")

            # æ—©åœæ£€æŸ¥
            if val_loss < self.best_val_loss:
                self.best_val_loss = val_loss
                self.patience_counter = 0
                self.save_checkpoint(f"../checkpoints/best_model.pth")
                print("  -> æ–°çš„æœ€ä½³æ¨¡å‹!")
            else:
                self.patience_counter += 1
                if self.patience_counter >= self.max_patience:
                    print(f"  -> æ—©åœ: éªŒè¯æŸå¤±è¿ç»­{self.max_patience}ä¸ªepochæœªæ”¹å–„")
                    break

            # å®šæœŸä¿å­˜æ£€æŸ¥ç‚¹
            if (epoch + 1) % self.config['save_every'] == 0:
                self.save_checkpoint(f"checkpoints/checkpoint_epoch_{epoch + 1}.pth")

            print("-" * 50)

        print("è®­ç»ƒå®Œæˆ!")
        self.writer.close()


def split_dataset(audio_dir, labels_file, test_size=0.2, random_state=42):
    """åˆ†å‰²æ•°æ®é›†ä¸ºè®­ç»ƒé›†å’ŒéªŒè¯é›†"""
    import pandas as pd

    df = pd.read_csv(labels_file)

    # æ£€æŸ¥æ•°æ®é›†å¤§å°
    if len(df) < 5:
        print("âš ï¸  æ•°æ®é›†å¤ªå°ï¼Œæ— æ³•åˆ†å‰²ï¼Œä½¿ç”¨å…¨éƒ¨æ•°æ®è¿›è¡Œè®­ç»ƒå’ŒéªŒè¯")
        return df, df

    # æ£€æŸ¥æ¯ä¸ªæ ‡ç­¾çš„æ ·æœ¬æ•°
    label_counts = df['label'].value_counts()
    min_samples = label_counts.min()

    print(f"æ ‡ç­¾åˆ†å¸ƒ: {dict(label_counts)}")

    if min_samples < 2:
        print("âš ï¸  éƒ¨åˆ†æ ‡ç­¾åªæœ‰1ä¸ªæ ·æœ¬ï¼Œæ— æ³•è¿›è¡Œåˆ†å±‚åˆ†å‰²")
        print("ä½¿ç”¨éšæœºåˆ†å‰²ä»£æ›¿åˆ†å±‚åˆ†å‰²")

        # ä½¿ç”¨ç®€å•çš„éšæœºåˆ†å‰²
        train_df, val_df = train_test_split(
            df,
            test_size=test_size,
            random_state=random_state,
            shuffle=True
        )
    else:
        # å¯ä»¥è¿›è¡Œåˆ†å±‚åˆ†å‰²
        print("ä½¿ç”¨åˆ†å±‚åˆ†å‰²ä¿æŒæ ‡ç­¾åˆ†å¸ƒ")
        train_df, val_df = train_test_split(
            df,
            test_size=test_size,
            random_state=random_state,
            stratify=df['label']
        )

    print(f"æ•°æ®åˆ†å‰²ç»“æœ:")
    print(f"  è®­ç»ƒé›†: {len(train_df)} æ ·æœ¬")
    print(f"  éªŒè¯é›†: {len(val_df)} æ ·æœ¬")

    # æ˜¾ç¤ºåˆ†å‰²åçš„æ ‡ç­¾åˆ†å¸ƒ
    print(f"  è®­ç»ƒé›†æ ‡ç­¾: {dict(train_df['label'].value_counts())}")
    print(f"  éªŒè¯é›†æ ‡ç­¾: {dict(val_df['label'].value_counts())}")

    return train_df, val_df


def create_dataloader_from_df(df, audio_dir, batch_size, shuffle=True):
    """ä»DataFrameåˆ›å»ºæ•°æ®åŠ è½½å™¨ - ä½¿ç”¨ç»Ÿä¸€å·¥å…·"""
    from data_utils import get_dataloader
    
    # åˆ›å»ºä¸´æ—¶æ ‡ç­¾æ–‡ä»¶
    temp_labels_file = f"temp_labels_{hash(str(df.values.tolist()))}.csv"
    df.to_csv(temp_labels_file, index=False, encoding='utf-8')

    try:
        # ä½¿ç”¨ç»Ÿä¸€çš„æ•°æ®åŠ è½½å™¨
        dataloader = get_dataloader(
            audio_dir=audio_dir,
            labels_file=temp_labels_file,
            batch_size=batch_size,
            shuffle=shuffle,
            mode='realtime'
        )
        return dataloader
    finally:
        # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        if os.path.exists(temp_labels_file):
            os.remove(temp_labels_file)


def main():
    """ä¸»å‡½æ•°"""
    # æ”¹è¿›çš„é»˜è®¤é…ç½®
    config = {
        'experiment_name': f'improved_speech_recognition_{datetime.now().strftime("%Y%m%d_%H%M%S")}',
        'batch_size': 2,  # å‡å°æ‰¹å¤§å°
        'learning_rate': 5e-5,  # é™ä½å­¦ä¹ ç‡
        'weight_decay': 1e-4,  # å¢åŠ æƒé‡è¡°å‡
        'grad_clip': 0.5,  # å‡å°æ¢¯åº¦è£å‰ª
        'num_epochs': 50,  # å‡å°‘è®­ç»ƒè½®æ•°
        'save_every': 10,
        'hidden_dim': 128,  # å‡å°æ¨¡å‹å¤§å°
        'encoder_layers': 2,  # å‡å°‘å±‚æ•°
        'decoder_layers': 2,
        'dropout': 0.3,  # å¢åŠ dropout
        'audio_dir': 'data/audio',
        'labels_file': 'data/labels.csv'
    }

    print("ğŸ”§ æ”¹è¿›çš„è®­ç»ƒè„šæœ¬")
    print("ä¸»è¦æ”¹è¿›:")
    print("  âœ… æ•°æ®é›†åˆ†å‰² (è®­ç»ƒ/éªŒè¯)")
    print("  âœ… é™ä½å­¦ä¹ ç‡å’Œæ¨¡å‹å¤æ‚åº¦")
    print("  âœ… æ·»åŠ æ­£åˆ™åŒ– (dropout, weight_decay, label_smoothing)")
    print("  âœ… æ—©åœæœºåˆ¶")
    print("=" * 60)

    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"ä½¿ç”¨è®¾å¤‡: {device}")

    os.makedirs('../checkpoints', exist_ok=True)
    os.makedirs('../runs', exist_ok=True)

    try:
        # åˆ†å‰²æ•°æ®é›†
        train_df, val_df = split_dataset(
            config['audio_dir'],
            config['labels_file']
        )

        # åˆ›å»ºæ•°æ®åŠ è½½å™¨
        train_loader = create_dataloader_from_df(
            train_df,
            config['audio_dir'],
            config['batch_size'],
            shuffle=True
        )

        val_loader = create_dataloader_from_df(
            val_df,
            config['audio_dir'],
            config['batch_size'],
            shuffle=False
        )

    except Exception as e:
        print(f"æ•°æ®åŠ è½½å¤±è´¥: {e}")
        return

    # åˆ›å»ºæ¨¡å‹
    model = create_model(
        vocab_size=vocab.vocab_size,
        hidden_dim=config['hidden_dim'],
        encoder_layers=config['encoder_layers'],
        decoder_layers=config['decoder_layers'],
        dropout=config['dropout']
    ).to(device)

    # åˆ›å»ºè®­ç»ƒå™¨
    trainer = ImprovedTrainer(model, train_loader, val_loader, device, config)

    # å¼€å§‹è®­ç»ƒ
    try:
        trainer.train(config['num_epochs'])
    except KeyboardInterrupt:
        print("è®­ç»ƒè¢«ä¸­æ–­")
        trainer.save_checkpoint("checkpoints/interrupted.pth")


if __name__ == "__main__":
    main()