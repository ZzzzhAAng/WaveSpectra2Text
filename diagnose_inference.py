#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ¨ç†é—®é¢˜è¯Šæ–­è„šæœ¬
åˆ†æä¸ºä»€ä¹ˆè¯†åˆ«ç»“æœä¸ºç©º
"""

import os
import torch
import numpy as np
from inference import SpeechRecognizer
from vocab import vocab

def diagnose_empty_results(model_path, test_audio):
    """è¯Šæ–­ç©ºç»“æœé—®é¢˜"""
    print("ğŸ” è¯Šæ–­æ¨ç†ç©ºç»“æœé—®é¢˜")
    print("=" * 50)
    
    try:
        # åˆ›å»ºè¯†åˆ«å™¨
        recognizer = SpeechRecognizer(model_path)
        print(f"âœ… æ¨¡å‹åŠ è½½æˆåŠŸ")
        
        # æµ‹è¯•éŸ³é¢‘é¢„å¤„ç†
        print(f"\n1ï¸âƒ£ æµ‹è¯•éŸ³é¢‘é¢„å¤„ç†...")
        spectrogram = recognizer._extract_spectrogram(test_audio)
        print(f"  é¢‘è°±å½¢çŠ¶: {spectrogram.shape}")
        print(f"  é¢‘è°±èŒƒå›´: [{spectrogram.min():.3f}, {spectrogram.max():.3f}]")
        
        # æµ‹è¯•ç¼–ç å™¨
        print(f"\n2ï¸âƒ£ æµ‹è¯•ç¼–ç å™¨...")
        with torch.no_grad():
            encoder_output = recognizer.model.encode(spectrogram)
            print(f"  ç¼–ç å™¨è¾“å‡ºå½¢çŠ¶: {encoder_output.shape}")
            print(f"  ç¼–ç å™¨è¾“å‡ºèŒƒå›´: [{encoder_output.min():.3f}, {encoder_output.max():.3f}]")
        
        # è¯¦ç»†æµ‹è¯•è´ªå©ªè§£ç è¿‡ç¨‹
        print(f"\n3ï¸âƒ£ è¯¦ç»†è´ªå©ªè§£ç è¿‡ç¨‹...")
        decoded_seq = diagnose_greedy_decode(recognizer.model, encoder_output)
        print(f"  æœ€ç»ˆè§£ç åºåˆ—: {decoded_seq.tolist()}")
        
        # æµ‹è¯•è¯æ±‡è¡¨è§£ç 
        print(f"\n4ï¸âƒ£ æµ‹è¯•è¯æ±‡è¡¨è§£ç ...")
        text = vocab.decode(decoded_seq.tolist())
        print(f"  è§£ç æ–‡æœ¬: '{text}'")
        print(f"  æ–‡æœ¬é•¿åº¦: {len(text)}")
        
        # æ£€æŸ¥è¯æ±‡è¡¨
        print(f"\n5ï¸âƒ£ æ£€æŸ¥è¯æ±‡è¡¨...")
        print(f"  è¯æ±‡è¡¨å¤§å°: {vocab.vocab_size}")
        print(f"  ç‰¹æ®Štoken: PAD={vocab.get_padding_idx()}, SOS={vocab.get_sos_idx()}, EOS={vocab.get_eos_idx()}")
        print(f"  è¯æ±‡æ˜ å°„: {vocab.word_to_idx}")
        
        # æµ‹è¯•æŸæœç´¢
        print(f"\n6ï¸âƒ£ æµ‹è¯•æŸæœç´¢è§£ç ...")
        beam_seq, beam_score = diagnose_beam_search(recognizer.model, encoder_output)
        beam_text = vocab.decode(beam_seq.tolist())
        print(f"  æŸæœç´¢åºåˆ—: {beam_seq.tolist()}")
        print(f"  æŸæœç´¢æ–‡æœ¬: '{beam_text}'")
        print(f"  æŸæœç´¢å¾—åˆ†: {beam_score:.3f}")
        
        return text, beam_text
        
    except Exception as e:
        print(f"âŒ è¯Šæ–­è¿‡ç¨‹å‡ºé”™: {e}")
        import traceback
        traceback.print_exc()
        return None, None

def diagnose_greedy_decode(model, encoder_output, max_length=10):
    """è¯Šæ–­è´ªå©ªè§£ç è¿‡ç¨‹"""
    device = encoder_output.device
    
    # åˆå§‹åŒ–è§£ç åºåˆ—
    decoded_seq = torch.LongTensor([[vocab.get_sos_idx()]]).to(device)
    print(f"  åˆå§‹åºåˆ—: {decoded_seq.tolist()} (SOS token)")
    
    for step in range(max_length):
        with torch.no_grad():
            # è·å–ä¸‹ä¸€ä¸ªtokençš„æ¦‚ç‡
            output = model.decode_step(decoded_seq, encoder_output)
            probs = torch.softmax(output[:, -1, :], dim=-1)
            next_token = output[:, -1, :].argmax(dim=-1, keepdim=True)
            
            print(f"  æ­¥éª¤ {step+1}:")
            print(f"    è¾“å‡ºlogitså½¢çŠ¶: {output.shape}")
            print(f"    ä¸‹ä¸€ä¸ªtoken: {next_token.item()} ('{vocab.idx_to_word.get(next_token.item(), 'UNK')}')")
            print(f"    æ¦‚ç‡: {probs[0, next_token.item()].item():.4f}")
            print(f"    å‰5ä¸ªæœ€é«˜æ¦‚ç‡: {torch.topk(probs, 5)[1].tolist()}")
            
            # æ·»åŠ åˆ°åºåˆ—ä¸­
            decoded_seq = torch.cat([decoded_seq, next_token], dim=1)
            print(f"    å½“å‰åºåˆ—: {decoded_seq.tolist()}")
            
            # å¦‚æœç”Ÿæˆäº†ç»“æŸç¬¦å·ï¼Œåœæ­¢è§£ç 
            if next_token.item() == vocab.get_eos_idx():
                print(f"    é‡åˆ°EOS tokenï¼Œåœæ­¢è§£ç ")
                break
    
    return decoded_seq.squeeze(0)

def diagnose_beam_search(model, encoder_output, beam_size=3, max_length=10):
    """è¯Šæ–­æŸæœç´¢è§£ç è¿‡ç¨‹"""
    device = encoder_output.device
    
    # åˆå§‹åŒ–æŸ
    beams = [(torch.LongTensor([[vocab.get_sos_idx()]]).to(device), 0.0)]
    print(f"  åˆå§‹æŸ: {beams[0][0].tolist()}")
    
    for step in range(max_length):
        print(f"  æŸæœç´¢æ­¥éª¤ {step+1}:")
        new_beams = []
        
        for i, (seq, score) in enumerate(beams):
            if seq[0, -1].item() == vocab.get_eos_idx():
                new_beams.append((seq, score))
                print(f"    æŸ {i}: å·²ç»“æŸ {seq.tolist()}")
                continue
            
            # è·å–ä¸‹ä¸€ä¸ªtokençš„æ¦‚ç‡
            with torch.no_grad():
                output = model.decode_step(seq, encoder_output)
                probs = torch.softmax(output[:, -1, :], dim=-1)
            
            # è·å–top-kå€™é€‰
            top_probs, top_indices = torch.topk(probs, beam_size)
            print(f"    æŸ {i}: å½“å‰åºåˆ— {seq.tolist()}")
            print(f"    æŸ {i}: å€™é€‰tokens {top_indices.tolist()[0]} æ¦‚ç‡ {top_probs.tolist()[0]}")
            
            for j in range(beam_size):
                new_seq = torch.cat([seq, top_indices[:, j:j + 1]], dim=1)
                new_score = score + torch.log(top_probs[:, j]).item()
                new_beams.append((new_seq, new_score))
        
        # ä¿ç•™æœ€å¥½çš„beam_sizeä¸ªå€™é€‰
        new_beams.sort(key=lambda x: x[1], reverse=True)
        beams = new_beams[:beam_size]
        
        print(f"    ä¿ç•™çš„æŸ: {[beam[0].tolist() for beam in beams]}")
        
        # æ£€æŸ¥æ˜¯å¦æ‰€æœ‰æŸéƒ½ç»“æŸäº†
        if all(seq[0, -1].item() == vocab.get_eos_idx() for seq, _ in beams):
            print(f"    æ‰€æœ‰æŸéƒ½ç»“æŸ")
            break
    
    # è¿”å›æœ€ä½³åºåˆ—
    best_seq, best_score = beams[0]
    return best_seq.squeeze(0), best_score

def check_model_training_status(model_path):
    """æ£€æŸ¥æ¨¡å‹è®­ç»ƒçŠ¶æ€"""
    print("\nğŸ” æ£€æŸ¥æ¨¡å‹è®­ç»ƒçŠ¶æ€")
    print("-" * 30)
    
    try:
        checkpoint = torch.load(model_path, map_location='cpu')
        
        print(f"è®­ç»ƒepoch: {checkpoint.get('epoch', 'Unknown')}")
        print(f"æœ€ä½³éªŒè¯æŸå¤±: {checkpoint.get('best_val_loss', 'Unknown')}")
        print(f"é…ç½®: {checkpoint.get('config', 'Unknown')}")
        
        # æ£€æŸ¥æ¨¡å‹æƒé‡
        state_dict = checkpoint['model_state_dict']
        
        # æ£€æŸ¥ä¸€äº›å…³é”®å±‚çš„æƒé‡
        for name, param in state_dict.items():
            if 'embedding' in name or 'output_projection' in name:
                print(f"  {name}: å½¢çŠ¶={param.shape}, èŒƒå›´=[{param.min():.3f}, {param.max():.3f}]")
                
        return True
        
    except Exception as e:
        print(f"âŒ æ£€æŸ¥æ¨¡å‹å¤±è´¥: {e}")
        return False

def suggest_solutions():
    """æä¾›è§£å†³æ–¹æ¡ˆå»ºè®®"""
    print("\nğŸ’¡ è§£å†³æ–¹æ¡ˆå»ºè®®")
    print("=" * 50)
    
    solutions = [
        "1. ç»§ç»­è®­ç»ƒæ›´å¤šepoch (å½“å‰28å¯èƒ½ä¸å¤Ÿ)",
        "2. æ£€æŸ¥è®­ç»ƒæŸå¤±æ˜¯å¦è¿˜åœ¨ä¸‹é™",
        "3. é™ä½å­¦ä¹ ç‡ï¼Œå»¶é•¿è®­ç»ƒæ—¶é—´",
        "4. æ£€æŸ¥è®­ç»ƒæ•°æ®æ˜¯å¦æ­£ç¡®åŠ è½½",
        "5. å°è¯•ä½¿ç”¨æ›´å°çš„æ¨¡å‹é¿å…è¿‡æ‹Ÿåˆ",
        "6. å¢åŠ æ•°æ®å¢å¼ºæé«˜è®­ç»ƒæ•ˆæœ"
    ]
    
    for solution in solutions:
        print(f"  {solution}")

def main():
    """ä¸»å‡½æ•°"""
    model_path = "checkpoints/test_model.pth"
    test_audio = "data/audio/Chinese_Number_01.wav"
    
    if not os.path.exists(model_path):
        print(f"âŒ æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {model_path}")
        return
    
    if not os.path.exists(test_audio):
        print(f"âŒ æµ‹è¯•éŸ³é¢‘ä¸å­˜åœ¨: {test_audio}")
        return
    
    # æ£€æŸ¥æ¨¡å‹çŠ¶æ€
    check_model_training_status(model_path)
    
    # è¯Šæ–­æ¨ç†é—®é¢˜
    text, beam_text = diagnose_empty_results(model_path, test_audio)
    
    # æä¾›è§£å†³æ–¹æ¡ˆ
    suggest_solutions()
    
    print(f"\nğŸ¯ è¯Šæ–­æ€»ç»“:")
    print(f"  è´ªå©ªè§£ç ç»“æœ: '{text}'")
    print(f"  æŸæœç´¢ç»“æœ: '{beam_text}'")
    
    if not text or text.strip() == '':
        print("âŒ ç¡®è®¤å­˜åœ¨ç©ºç»“æœé—®é¢˜")
        print("ğŸ’¡ å»ºè®®: ç»§ç»­è®­ç»ƒæ¨¡å‹æˆ–è°ƒæ•´è®­ç»ƒå‚æ•°")
    else:
        print("âœ… è§£ç æ­£å¸¸ï¼Œå¯èƒ½æ˜¯æ˜¾ç¤ºé—®é¢˜")

if __name__ == "__main__":
    main()