# ğŸš€ ç”Ÿäº§ç¯å¢ƒä½¿ç”¨æŒ‡å—

## ğŸ¯ æˆç†Ÿæ¨¡å‹å¤„ç†æ–°éŸ³é¢‘çš„å®Œæ•´æµç¨‹

å½“æ‚¨çš„æ¨¡å‹è®­ç»ƒæˆç†Ÿåï¼Œå¤„ç†ä»»æ„æ–°éŸ³é¢‘æ–‡ä»¶çš„æµç¨‹å¦‚ä¸‹ï¼š

### ğŸ“‹ **å®Œæ•´æŠ€æœ¯æµç¨‹**

```
æ–°éŸ³é¢‘æ–‡ä»¶ â†’ é¢‘è°±æå– â†’ æ¨¡å‹æ¨ç† â†’ æ–‡æœ¬è§£ç  â†’ æœ€ç»ˆç»“æœ

ğŸµ input.wav â†’ ğŸ“Š (200,513) â†’ ğŸ§  Transformer â†’ ğŸ“ [1,4,5,2] â†’ âœ¨ "ä¸€äºŒ"
```

### ğŸ”§ **è¯¦ç»†æ­¥éª¤è§£æ**

#### æ­¥éª¤1: éŸ³é¢‘é¢„å¤„ç† (é¢‘è°±ç‰¹å¾æå–)
```python
# ç³»ç»Ÿè‡ªåŠ¨æ‰§è¡Œä»¥ä¸‹æ­¥éª¤ï¼š
audio, sr = librosa.load(audio_path, sr=48000)           # åŠ è½½éŸ³é¢‘
stft = librosa.stft(audio, n_fft=1024, hop_length=512)   # STFTå˜æ¢
magnitude = np.abs(stft)                                 # å¹…åº¦è°±
log_magnitude = np.log1p(magnitude)                      # å¯¹æ•°å˜æ¢
spectrogram = log_magnitude.T                            # è½¬ç½® (æ—¶é—´Ã—é¢‘ç‡)
# ç»“æœ: (200, 513) çš„é¢‘è°±ç‰¹å¾çŸ©é˜µ
```

#### æ­¥éª¤2: æ¨¡å‹æ¨ç†
```python
# ç¼–ç é˜¶æ®µ: é¢‘è°± â†’ éšè—è¡¨ç¤º
encoder_output = model.encode(spectrogram)  # (1, 200, hidden_dim)

# è§£ç é˜¶æ®µ: éšè—è¡¨ç¤º â†’ tokenåºåˆ—
decoded_sequence = model.decode(encoder_output)  # [1, 4, 5, 2] (SOS, ä¸€, äºŒ, EOS)
```

#### æ­¥éª¤3: æ–‡æœ¬è½¬æ¢
```python
# tokenåºåˆ— â†’ ä¸­æ–‡æ–‡æœ¬
text = vocab.decode([1, 4, 5, 2])  # "ä¸€äºŒ"
```

## ğŸ› ï¸ **å®é™…ä½¿ç”¨æ–¹æ³•**

### æ–¹æ³•1: å‘½ä»¤è¡Œä½¿ç”¨ (æœ€ç®€å•)

```bash
# å¤„ç†å•ä¸ªæ–°éŸ³é¢‘æ–‡ä»¶
python inference_final.py \
    --model checkpoints/best_model.pth \
    --audio /path/to/new_audio.wav

# æ‰¹é‡å¤„ç†æ–°éŸ³é¢‘ç›®å½•
python inference_final.py \
    --model checkpoints/best_model.pth \
    --audio_dir /path/to/new_audio_directory \
    --method auto
```

### æ–¹æ³•2: Python APIä½¿ç”¨

```python
from production_inference_demo import ProductionSpeechRecognizer

# 1. åˆå§‹åŒ–è¯†åˆ«å™¨ (åŠ è½½è®­ç»ƒå¥½çš„æ¨¡å‹)
recognizer = ProductionSpeechRecognizer(
    model_path="checkpoints/best_model.pth",
    device="cpu"  # æˆ– "cuda" å¦‚æœæœ‰GPU
)

# 2. å¤„ç†å•ä¸ªæ–°éŸ³é¢‘æ–‡ä»¶
result = recognizer.process_new_audio("/path/to/new_audio.wav")

if result['success']:
    print(f"è¯†åˆ«ç»“æœ: {result['text']}")
    print(f"å¤„ç†æ—¶é—´: {result['processing_time']['total']:.3f}ç§’")
    print(f"é¢‘è°±å½¢çŠ¶: {result['spectrogram_shape']}")
else:
    print(f"è¯†åˆ«å¤±è´¥: {result['error']}")

# 3. æ‰¹é‡å¤„ç†
results = recognizer.batch_process_directory(
    audio_dir="/path/to/audio_directory",
    output_file="recognition_results.csv"
)
```

### æ–¹æ³•3: Web APIæœåŠ¡ (ç”Ÿäº§éƒ¨ç½²)

```bash
# 1. å¯åŠ¨APIæœåŠ¡
python speech_recognition_api.py --model checkpoints/best_model.pth --host 0.0.0.0 --port 5000

# 2. ä½¿ç”¨Webç•Œé¢
# æµè§ˆå™¨è®¿é—®: http://localhost:5000

# 3. ä½¿ç”¨APIæ¥å£
curl -X POST -F "audio=@new_audio.wav" http://localhost:5000/api/recognize
```

## ğŸµ **æ”¯æŒçš„éŸ³é¢‘æ ¼å¼**

ç³»ç»Ÿæ”¯æŒä»¥ä¸‹éŸ³é¢‘æ ¼å¼ï¼š
- **WAV** (æ¨è) - æ— æŸï¼Œå¤„ç†æœ€å¿«
- **MP3** - å‹ç¼©æ ¼å¼ï¼Œå¹¿æ³›æ”¯æŒ
- **FLAC** - æ— æŸå‹ç¼©
- **M4A** - Appleæ ¼å¼
- **OGG** - å¼€æºæ ¼å¼

**éŸ³é¢‘è¦æ±‚**:
- é‡‡æ ·ç‡: ä»»æ„ (ç³»ç»Ÿä¼šè‡ªåŠ¨é‡é‡‡æ ·åˆ°48kHz)
- æ—¶é•¿: å»ºè®®0.5-10ç§’ (ç³»ç»Ÿä¼šè‡ªåŠ¨å¤„ç†é•¿åº¦)
- è´¨é‡: æ¸…æ™°çš„è¯­éŸ³ï¼Œæœ€å¥½æ— èƒŒæ™¯å™ªéŸ³

## ğŸ“Š **æ€§èƒ½ç‰¹å¾**

### å¤„ç†é€Ÿåº¦ (CPU)
- **å•æ–‡ä»¶**: 0.1-0.3ç§’
- **æ‰¹é‡å¤„ç†**: çº¦2-5æ–‡ä»¶/ç§’
- **GPUåŠ é€Ÿ**: å¯æå‡3-5å€é€Ÿåº¦

### å†…å­˜å ç”¨
- **å•æ–‡ä»¶**: ~50MB
- **æ‰¹é‡å¤„ç†**: ~100-200MB
- **æ¨¡å‹å¤§å°**: æ ¹æ®é…ç½® (1MB-50MB)

## ğŸ”§ **é«˜çº§ä½¿ç”¨åœºæ™¯**

### åœºæ™¯1: å®æ—¶è¯­éŸ³è¯†åˆ«æœåŠ¡
```python
# éƒ¨ç½²ä¸ºå¾®æœåŠ¡
python speech_recognition_api.py \
    --model checkpoints/best_model.pth \
    --host 0.0.0.0 \
    --port 8080 \
    --device cuda
```

### åœºæ™¯2: æ‰¹é‡éŸ³é¢‘å¤„ç†
```python
# å¤„ç†å¤§é‡éŸ³é¢‘æ–‡ä»¶
recognizer = ProductionSpeechRecognizer("checkpoints/best_model.pth")
results = recognizer.batch_process_directory(
    audio_dir="/data/new_audio_files",
    output_file="batch_results.csv"
)
```

### åœºæ™¯3: é›†æˆåˆ°å…¶ä»–ç³»ç»Ÿ
```python
# ä½œä¸ºæ¨¡å—é›†æˆ
from production_inference_demo import ProductionSpeechRecognizer

class MyAudioProcessor:
    def __init__(self):
        self.recognizer = ProductionSpeechRecognizer("model.pth")
    
    def process_user_audio(self, audio_file):
        result = self.recognizer.process_new_audio(audio_file)
        return result['text']
```

## ğŸ›¡ï¸ **ç”Ÿäº§ç¯å¢ƒæ³¨æ„äº‹é¡¹**

### å®‰å…¨æ€§
- **æ–‡ä»¶éªŒè¯**: æ£€æŸ¥æ–‡ä»¶æ ¼å¼å’Œå¤§å°
- **è·¯å¾„å®‰å…¨**: ä½¿ç”¨secure_filenameå¤„ç†æ–‡ä»¶å
- **èµ„æºé™åˆ¶**: é™åˆ¶ä¸Šä¼ æ–‡ä»¶å¤§å°å’Œå¤„ç†æ—¶é—´

### å¯é æ€§
- **å¼‚å¸¸å¤„ç†**: å®Œæ•´çš„é”™è¯¯å¤„ç†æœºåˆ¶
- **èµ„æºæ¸…ç†**: è‡ªåŠ¨æ¸…ç†ä¸´æ—¶æ–‡ä»¶
- **å¥åº·æ£€æŸ¥**: æä¾›æœåŠ¡çŠ¶æ€ç›‘æ§

### å¯æ‰©å±•æ€§
- **è´Ÿè½½å‡è¡¡**: æ”¯æŒå¤šå®ä¾‹éƒ¨ç½²
- **ç¼“å­˜æœºåˆ¶**: ç›¸åŒéŸ³é¢‘é¿å…é‡å¤è®¡ç®—
- **é˜Ÿåˆ—å¤„ç†**: æ”¯æŒå¼‚æ­¥æ‰¹é‡å¤„ç†

## ğŸ“ˆ **å…¸å‹ä½¿ç”¨æµç¨‹ç¤ºä¾‹**

### ç”¨æˆ·åœºæ™¯: è¯†åˆ«æ–°å½•åˆ¶çš„ä¸­æ–‡æ•°å­—éŸ³é¢‘

```python
# 1. ç”¨æˆ·å½•åˆ¶äº†æ–°çš„éŸ³é¢‘æ–‡ä»¶ "my_recording.wav"
# 2. ç³»ç»Ÿå¤„ç†æµç¨‹:

recognizer = ProductionSpeechRecognizer("checkpoints/best_model.pth")

# è‡ªåŠ¨æ‰§è¡Œ:
# - åŠ è½½éŸ³é¢‘å¹¶é‡é‡‡æ ·åˆ°48kHz
# - æå–STFTé¢‘è°±ç‰¹å¾ (200, 513)
# - ä½¿ç”¨Transformerç¼–ç å™¨ç¼–ç 
# - ä½¿ç”¨æ³¨æ„åŠ›è§£ç å™¨è§£ç 
# - è½¬æ¢tokenåºåˆ—ä¸ºä¸­æ–‡æ–‡æœ¬

result = recognizer.process_new_audio("my_recording.wav")

print(f"è¯†åˆ«ç»“æœ: {result['text']}")  # ä¾‹å¦‚: "äº”"
print(f"å¤„ç†æ—¶é—´: {result['processing_time']['total']:.3f}ç§’")
```

## ğŸ‰ **å…³é”®ä¼˜åŠ¿**

### âœ… **å®Œå…¨ç‹¬ç«‹**
- ä¸éœ€è¦åŸå§‹è®­ç»ƒæ•°æ®
- ä¸éœ€è¦é‡æ–°é¢„å¤„ç†
- åªéœ€è¦è®­ç»ƒå¥½çš„æ¨¡å‹æ–‡ä»¶

### âœ… **å³æ’å³ç”¨**
- æ”¯æŒä»»æ„è·¯å¾„çš„éŸ³é¢‘æ–‡ä»¶
- è‡ªåŠ¨å¤„ç†ä¸åŒæ ¼å¼å’Œé‡‡æ ·ç‡
- ç»Ÿä¸€çš„è¾“å…¥è¾“å‡ºæ¥å£

### âœ… **ç”Ÿäº§å°±ç»ª**
- å®Œæ•´çš„é”™è¯¯å¤„ç†
- æ€§èƒ½ç›‘æ§å’Œæ—¥å¿—
- Web APIå’Œå‘½ä»¤è¡ŒåŒæ¥å£

---

**æ€»ç»“**: æ‚¨çš„ç³»ç»Ÿå·²ç»å®Œå…¨å…·å¤‡äº†å¤„ç†ä»»æ„æ–°éŸ³é¢‘æ–‡ä»¶çš„èƒ½åŠ›ï¼Œä»æŠ€æœ¯æ¶æ„åˆ°å·¥ç¨‹å®ç°éƒ½éå¸¸å®Œå–„ï¼ğŸš€