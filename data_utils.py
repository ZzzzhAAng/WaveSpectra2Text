# -*- coding: utf-8 -*-
"""
æ•°æ®å¤„ç†å·¥å…· - é‡æ„ç‰ˆæœ¬
ä½¿ç”¨æ–°çš„ä½è€¦åˆæ¶æ„ï¼Œæ”¯æŒå¤šç§é¢„å¤„ç†ç­–ç•¥å’Œæ•°æ®åŠ è½½æ¨¡å¼
"""

import os
import numpy as np
import pandas as pd
import torch
from torch.utils.data import DataLoader
import warnings

# å¯¼å…¥æ–°çš„æ¨¡å—
from audio_preprocess import PreprocessorFactory
from audio_dataset import AudioDataset, FlexibleDataLoader, create_realtime_dataset, create_precomputed_dataset
from vocab import vocab

warnings.filterwarnings('ignore')


# ä¸ºäº†å‘åå…¼å®¹ï¼Œä¿ç•™æ—§çš„ç±»åå’Œæ¥å£
class AudioSpectrogramDataset(AudioDataset):
    """éŸ³é¢‘é¢‘è°±æ•°æ®é›† - å…¼å®¹æ—§æ¥å£çš„åŒ…è£…å™¨"""

    def __init__(self, audio_dir, labels_file, sample_rate=48000, n_fft=1024,
                 hop_length=512, max_length=200, use_cache=True):
        """
        Args:
            audio_dir: éŸ³é¢‘æ–‡ä»¶ç›®å½•
            labels_file: æ ‡ç­¾æ–‡ä»¶è·¯å¾„
            sample_rate: é‡‡æ ·ç‡
            n_fft: FFTçª—å£å¤§å°
            hop_length: è·³è·ƒé•¿åº¦
            max_length: æœ€å¤§åºåˆ—é•¿åº¦
            use_cache: æ˜¯å¦ä½¿ç”¨ç¼“å­˜ (æ–°å¢å‚æ•°)
        """
        print("âš ï¸  ä½¿ç”¨å…¼å®¹æ¨¡å¼ - å»ºè®®è¿ç§»åˆ°æ–°çš„ AudioDataset æ¥å£")

        # åˆ›å»ºé¢„å¤„ç†å™¨
        preprocessor = PreprocessorFactory.create(
            'spectrogram',
            sample_rate=sample_rate,
            n_fft=n_fft,
            hop_length=hop_length,
            max_length=max_length
        )

        # ä½¿ç”¨ç¼“å­˜ç›®å½•
        cache_dir = 'cache/legacy_features' if use_cache else None

        # è°ƒç”¨çˆ¶ç±»åˆå§‹åŒ–
        super().__init__(
            labels_file=labels_file,
            audio_dir=audio_dir,
            preprocessor=preprocessor,
            cache_dir=cache_dir,
            mode='realtime'
        )

        # ä¸ºäº†å…¼å®¹æ—§æ¥å£ï¼Œè®¾ç½®ä¸€äº›å±æ€§
        self.audio_dir = audio_dir
        self.sample_rate = sample_rate
        self.n_fft = n_fft
        self.hop_length = hop_length
        self.max_length = max_length

    def __getitem__(self, idx):
        """è·å–æ•°æ®é¡¹ - å…¼å®¹æ—§æ¥å£"""
        sample = super().__getitem__(idx)

        # é‡å‘½åé”®ä»¥ä¿æŒå…¼å®¹æ€§
        return {
            'spectrogram': sample['features'],  # é‡å‘½å features -> spectrogram
            'label': sample['label'],
            'text': sample['text'],
            'filename': sample['filename']
        }


def collate_fn(batch):
    """æ‰¹å¤„ç†å‡½æ•° - å…¼å®¹æ—§æ¥å£"""
    # è½¬æ¢é”®å
    converted_batch = []
    for sample in batch:
        converted_batch.append({
            'features': sample['spectrogram'],  # é‡å‘½å spectrogram -> features
            'label': sample['label'],
            'text': sample['text'],
            'filename': sample['filename']
        })

    # ä½¿ç”¨æ–°çš„ collate_fn
    result = FlexibleDataLoader.collate_fn(converted_batch)

    # é‡å‘½åè¾“å‡ºé”®ä»¥ä¿æŒå…¼å®¹æ€§
    return {
        'spectrograms': result['features'],  # é‡å‘½å features -> spectrograms
        'labels': result['labels'],
        'texts': result['texts'],
        'filenames': result['filenames']
    }


def create_labels_file_if_not_exists(labels_file='data/labels.csv'):
    """å¦‚æœæ ‡ç­¾æ–‡ä»¶ä¸å­˜åœ¨ï¼Œåˆ›å»ºç¤ºä¾‹æ ‡ç­¾æ–‡ä»¶ - ä½¿ç”¨ç»Ÿä¸€å·¥å…·"""
    from common_utils import LabelManager
    
    if os.path.exists(labels_file):
        print(f"æ ‡ç­¾æ–‡ä»¶å·²å­˜åœ¨: {labels_file}")
        return

    # ä½¿ç”¨ç»Ÿä¸€å·¥å…·åˆ›å»ºæ ‡ç­¾æ¨¡æ¿
    success = LabelManager.create_labels_template('data/audio', labels_file, auto_labels=True)
    
    if not success:
        # å¦‚æœæ²¡æœ‰éŸ³é¢‘æ–‡ä»¶ï¼Œåˆ›å»ºç¤ºä¾‹æ ‡ç­¾æ–‡ä»¶
        labels_data = {
            'filename': [
                '1.wav', '2.wav', '3.wav', '4.wav', '5.wav',
                '6.wav', '7.wav', '8.wav', '9.wav', '10.wav'
            ],
            'label': ['ä¸€', 'äºŒ', 'ä¸‰', 'å››', 'äº”', 'å…­', 'ä¸ƒ', 'å…«', 'ä¹', 'å']
        }

        df = pd.DataFrame(labels_data)
        df.to_csv(labels_file, index=False, encoding='utf-8')
        print(f"å·²åˆ›å»ºç¤ºä¾‹æ ‡ç­¾æ–‡ä»¶: {labels_file}")
        print("è¯·æ ¹æ®ä½ çš„å®é™…éŸ³é¢‘æ–‡ä»¶ä¿®æ”¹æ ‡ç­¾æ–‡ä»¶ä¸­çš„filenameå­—æ®µ")


def check_audio_files(audio_dir, labels_file):
    """æ£€æŸ¥éŸ³é¢‘æ–‡ä»¶æ˜¯å¦å­˜åœ¨ - ä½¿ç”¨ç»Ÿä¸€å·¥å…·"""
    from common_utils import LabelManager
    
    # ä½¿ç”¨ç»Ÿä¸€å·¥å…·è¿›è¡ŒéªŒè¯ï¼Œä½†ä¿æŒåŸæœ‰çš„è¾“å‡ºæ ¼å¼
    if not os.path.exists(labels_file):
        print(f"é”™è¯¯: æ ‡ç­¾æ–‡ä»¶ä¸å­˜åœ¨ {labels_file}")
        return False

    df = pd.read_csv(labels_file)
    missing_files = []
    existing_files = []

    for _, row in df.iterrows():
        audio_path = os.path.join(audio_dir, row['filename'])
        if os.path.exists(audio_path):
            existing_files.append(row['filename'])
        else:
            missing_files.append(row['filename'])

    print(f"éŸ³é¢‘æ–‡ä»¶æ£€æŸ¥ç»“æœ:")
    print(f"  æ‰¾åˆ°çš„æ–‡ä»¶: {len(existing_files)}")
    print(f"  ç¼ºå¤±çš„æ–‡ä»¶: {len(missing_files)}")

    if existing_files:
        print(f"  å­˜åœ¨çš„æ–‡ä»¶: {existing_files[:5]}{'...' if len(existing_files) > 5 else ''}")

    if missing_files:
        print(f"  ç¼ºå¤±çš„æ–‡ä»¶: {missing_files}")
        print("è¯·ç¡®ä¿éŸ³é¢‘æ–‡ä»¶å­˜åœ¨äºæŒ‡å®šç›®å½•ä¸­")

    return len(missing_files) == 0


def get_dataloader(audio_dir='data/audio', labels_file='data/labels.csv',
                   batch_size=4, shuffle=True, num_workers=0, mode='auto', **kwargs):
    """
    è·å–æ•°æ®åŠ è½½å™¨ - æ”¯æŒå¤šç§æ¨¡å¼

    Args:
        audio_dir: éŸ³é¢‘æ–‡ä»¶ç›®å½•
        labels_file: æ ‡ç­¾æ–‡ä»¶è·¯å¾„
        batch_size: æ‰¹å¤§å°
        shuffle: æ˜¯å¦æ‰“ä¹±æ•°æ®
        num_workers: å·¥ä½œè¿›ç¨‹æ•°
        mode: æ•°æ®åŠ è½½æ¨¡å¼ ('auto', 'realtime', 'precomputed', 'legacy')
        **kwargs: å…¶ä»–å‚æ•°
    """
    if mode == 'auto':
        # è‡ªåŠ¨é€‰æ‹©æ¨¡å¼
        precomputed_dir = kwargs.get('precomputed_dir', 'data/features')
        if os.path.exists(os.path.join(precomputed_dir, 'spectrum_index.csv')):
            print("ğŸš€ æ£€æµ‹åˆ°é¢„è®¡ç®—ç‰¹å¾ï¼Œä½¿ç”¨é¢„è®¡ç®—æ¨¡å¼")
            mode = 'precomputed'
        else:
            print("âš¡ ä½¿ç”¨å®æ—¶è®¡ç®—æ¨¡å¼")
            mode = 'realtime'

    if mode == 'legacy':
        # å…¼å®¹æ—§æ¥å£
        dataset = AudioSpectrogramDataset(audio_dir, labels_file, **kwargs)
        return DataLoader(
            dataset,
            batch_size=batch_size,
            shuffle=shuffle,
            num_workers=num_workers,
            collate_fn=collate_fn
        )

    elif mode == 'realtime':
        # å®æ—¶è®¡ç®—æ¨¡å¼
        dataset = create_realtime_dataset(
            labels_file=labels_file,
            audio_dir=audio_dir,
            cache_dir=kwargs.get('cache_dir', 'cache/features'),
            **kwargs
        )

    elif mode == 'precomputed':
        # é¢„è®¡ç®—æ¨¡å¼
        precomputed_dir = kwargs.get('precomputed_dir', 'data/features')
        dataset = create_precomputed_dataset(
            labels_file=labels_file,
            precomputed_dir=precomputed_dir
        )

    else:
        raise ValueError(f"ä¸æ”¯æŒçš„æ¨¡å¼: {mode}")

    return FlexibleDataLoader.create_dataloader(
        dataset,
        batch_size=batch_size,
        shuffle=shuffle,
        num_workers=num_workers
    )


# æ–°å¢ä¾¿æ·å‡½æ•°
def get_realtime_dataloader(audio_dir='data/audio', labels_file='data/labels.csv',
                           batch_size=4, shuffle=True, num_workers=0, **kwargs):
    """è·å–å®æ—¶è®¡ç®—æ•°æ®åŠ è½½å™¨"""
    return get_dataloader(
        audio_dir=audio_dir,
        labels_file=labels_file,
        batch_size=batch_size,
        shuffle=shuffle,
        num_workers=num_workers,
        mode='realtime',
        **kwargs
    )


def get_precomputed_dataloader(labels_file='data/labels.csv', precomputed_dir='data/features',
                              batch_size=4, shuffle=True, num_workers=0):
    """è·å–é¢„è®¡ç®—æ•°æ®åŠ è½½å™¨"""
    return get_dataloader(
        labels_file=labels_file,
        batch_size=batch_size,
        shuffle=shuffle,
        num_workers=num_workers,
        mode='precomputed',
        precomputed_dir=precomputed_dir
    )


if __name__ == "__main__":
    print("ğŸ¯ é‡æ„åçš„æ•°æ®å¤„ç†å·¥å…·æµ‹è¯•")
    print("=" * 50)

    # æ£€æŸ¥å¹¶åˆ›å»ºæ ‡ç­¾æ–‡ä»¶
    create_labels_file_if_not_exists()

    # æ£€æŸ¥éŸ³é¢‘æ–‡ä»¶
    audio_dir = 'data/audio'
    labels_file = 'data/labels.csv'

    if check_audio_files(audio_dir, labels_file):
        print("âœ… æ‰€æœ‰éŸ³é¢‘æ–‡ä»¶éƒ½å­˜åœ¨ï¼Œå¯ä»¥å¼€å§‹è®­ç»ƒ")

        # æµ‹è¯•ä¸åŒæ¨¡å¼çš„æ•°æ®åŠ è½½
        try:
            print("\nğŸ§ª æµ‹è¯•è‡ªåŠ¨æ¨¡å¼æ•°æ®åŠ è½½...")
            dataloader = get_dataloader(batch_size=2, mode='auto')
            print(f"æ•°æ®é›†å¤§å°: {len(dataloader.dataset)}")

            # è·å–ä¸€ä¸ªæ‰¹æ¬¡
            for batch in dataloader:
                print(f"ç‰¹å¾å½¢çŠ¶: {batch['features'].shape}")
                print(f"æ ‡ç­¾å½¢çŠ¶: {batch['labels'].shape}")
                print(f"æ–‡æœ¬: {batch['texts']}")
                print(f"æ–‡ä»¶å: {batch['filenames']}")
                break

            print("\nğŸ§ª æµ‹è¯•å…¼å®¹æ¨¡å¼æ•°æ®åŠ è½½...")
            legacy_dataloader = get_dataloader(batch_size=2, mode='legacy')

            for batch in legacy_dataloader:
                print(f"é¢‘è°±å½¢çŠ¶ (å…¼å®¹): {batch['spectrograms'].shape}")
                print(f"æ ‡ç­¾å½¢çŠ¶ (å…¼å®¹): {batch['labels'].shape}")
                break

            print("\nâœ… æ‰€æœ‰æµ‹è¯•é€šè¿‡!")
            print("\nğŸ’¡ ä½¿ç”¨å»ºè®®:")
            print("1. å¯¹äºå¤§æ•°æ®é›†ï¼Œå»ºè®®å…ˆè¿è¡Œæ‰¹é‡é¢„å¤„ç†:")
            print("   python batch_preprocess.py --audio_dir data/audio --labels_file data/labels.csv")
            print("2. ç„¶åä½¿ç”¨é¢„è®¡ç®—æ¨¡å¼è·å¾—æœ€ä½³æ€§èƒ½:")
            print("   get_dataloader(mode='precomputed')")
            print("3. å¯¹äºå°æ•°æ®é›†æˆ–å¼€å‘é˜¶æ®µï¼Œå¯ä»¥ä½¿ç”¨å®æ—¶æ¨¡å¼:")
            print("   get_dataloader(mode='realtime')")

        except Exception as e:
            print(f"âŒ æµ‹è¯•æ•°æ®åŠ è½½æ—¶å‡ºé”™: {e}")
            print("è¯·ç¡®ä¿å®‰è£…äº†librosaå’Œç›¸å…³ä¾èµ–")
            import traceback
            traceback.print_exc()
    else:
        print("âš ï¸  éƒ¨åˆ†éŸ³é¢‘æ–‡ä»¶ç¼ºå¤±ï¼Œè¯·æ£€æŸ¥æ–‡ä»¶è·¯å¾„")
        print("ğŸ’¡ æç¤º: å¯ä»¥è¿è¡Œä»¥ä¸‹å‘½ä»¤åˆ›å»ºç¤ºä¾‹æ•°æ®:")
        print("   python batch_preprocess.py --migrate")