#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
é…ç½®ç®¡ç†ç³»ç»Ÿ
æ”¯æŒYAMLé…ç½®æ–‡ä»¶ï¼Œæä¾›é»˜è®¤é…ç½®å’Œé…ç½®éªŒè¯
"""

import os
import yaml
from typing import Dict, Any, Optional
from pathlib import Path
from datetime import datetime


class ConfigManager:
    """é…ç½®ç®¡ç†å™¨"""
    
    def __init__(self, config_path: Optional[str] = None):
        """
        åˆå§‹åŒ–é…ç½®ç®¡ç†å™¨
        
        Args:
            config_path: é…ç½®æ–‡ä»¶è·¯å¾„
        """
        self.config_path = config_path
        self.config = {}
        
        if config_path and os.path.exists(config_path):
            self.load_config(config_path)
        else:
            self.config = self.get_default_config()
    
    def load_config(self, config_path: str) -> Dict[str, Any]:
        """
        åŠ è½½é…ç½®æ–‡ä»¶
        
        Args:
            config_path: é…ç½®æ–‡ä»¶è·¯å¾„
            
        Returns:
            é…ç½®å­—å…¸
        """
        with open(config_path, 'r', encoding='utf-8') as f:
            if config_path.endswith('.yaml') or config_path.endswith('.yml'):
                self.config = yaml.safe_load(f)
            else:
                # å‡è®¾æ˜¯JSONæ ¼å¼
                import json
                self.config = json.load(f)
        
        # éªŒè¯é…ç½®
        self.validate_config()
        return self.config
    
    def save_config(self, config_path: str) -> None:
        """
        ä¿å­˜é…ç½®åˆ°æ–‡ä»¶
        
        Args:
            config_path: é…ç½®æ–‡ä»¶è·¯å¾„
        """
        with open(config_path, 'w', encoding='utf-8') as f:
            if config_path.endswith('.yaml') or config_path.endswith('.yml'):
                yaml.dump(self.config, f, default_flow_style=False, allow_unicode=True)
            else:
                import json
                json.dump(self.config, f, indent=2, ensure_ascii=False)
    
    def validate_config(self) -> None:
        """éªŒè¯é…ç½®çš„æœ‰æ•ˆæ€§"""
        required_keys = [
            'batch_size', 'learning_rate', 'num_epochs', 
            'hidden_dim', 'encoder_layers', 'decoder_layers'
        ]
        
        for key in required_keys:
            if key not in self.config:
                raise ValueError(f"ç¼ºå°‘å¿…éœ€çš„é…ç½®é¡¹: {key}")
        
        # éªŒè¯æ•°å€¼èŒƒå›´
        if self.config['batch_size'] <= 0:
            raise ValueError("batch_size å¿…é¡»å¤§äº0")
        
        if not 0 < self.config['learning_rate'] < 1:
            raise ValueError("learning_rate å¿…é¡»åœ¨0å’Œ1ä¹‹é—´")
        
        if self.config['num_epochs'] <= 0:
            raise ValueError("num_epochs å¿…é¡»å¤§äº0")
    
    def get_default_config(self) -> Dict[str, Any]:
        """è·å–é»˜è®¤é…ç½®"""
        return {
            'experiment_name': 'default_experiment',
            'batch_size': 4,
            'learning_rate': 0.001,
            'weight_decay': 1e-4,
            'grad_clip': 1.0,
            'num_epochs': 100,
            'save_every': 10,
            'hidden_dim': 256,
            'encoder_layers': 4,
            'decoder_layers': 4,
            'dropout': 0.1,
            'max_patience': 20,
            'label_smoothing': 0.1,
            'audio_dir': 'data/audio',
            'labels_file': 'data/labels.csv',
            'device': 'auto',  # auto, cpu, cuda
            'num_workers': 0,
            'pin_memory': True,
            'shuffle': True,
            'validation_split': 0.2,
            'random_seed': 42,
            'log_level': 'INFO',
            'tensorboard_log_dir': 'experiments/runs',
            'checkpoint_dir': 'experiments/checkpoints',
            'log_dir': 'experiments/logs'
        }
    
    def update_config(self, updates: Dict[str, Any]) -> None:
        """
        æ›´æ–°é…ç½®
        
        Args:
            updates: è¦æ›´æ–°çš„é…ç½®é¡¹
        """
        self.config.update(updates)
        self.validate_config()
    
    def get(self, key: str, default: Any = None) -> Any:
        """è·å–é…ç½®é¡¹"""
        return self.config.get(key, default)
    
    def __getitem__(self, key: str) -> Any:
        """æ”¯æŒå­—å…¸å¼è®¿é—®"""
        return self.config[key]
    
    def __setitem__(self, key: str, value: Any) -> None:
        """æ”¯æŒå­—å…¸å¼è®¾ç½®"""
        self.config[key] = value


def get_default_config(scale: str = 'medium') -> Dict[str, Any]:
    """
    è·å–ä¸åŒè§„æ¨¡çš„é»˜è®¤é…ç½®
    
    Args:
        scale: æ•°æ®é›†è§„æ¨¡ ('small', 'medium', 'large', 'xlarge')
        
    Returns:
        é…ç½®å­—å…¸
    """
    configs = {
        'small': {
            'experiment_name': f'small_dataset_{datetime.now().strftime("%Y%m%d_%H%M%S")}',
            'batch_size': 1,
            'learning_rate': 1e-5,
            'weight_decay': 1e-3,
            'grad_clip': 0.1,
            'num_epochs': 30,
            'save_every': 10,
            'hidden_dim': 64,
            'encoder_layers': 1,
            'decoder_layers': 1,
            'dropout': 0.5,
            'max_patience': 15,
            'label_smoothing': 0.1,
            'device': 'auto',
            'checkpoint_dir': 'checkpoints',
            'log_dir': 'logs',
            'tensorboard_log_dir': 'runs',
            'labels_file': 'data/labels.csv',
            'audio_dir': 'data/audio',
            'validation_split': 0.2,
            'random_seed': 42,
            'shuffle': True,
            'num_workers': 0,
            'pin_memory': False
        },
        'medium': {
            'experiment_name': f'medium_dataset_{datetime.now().strftime("%Y%m%d_%H%M%S")}',
            'batch_size': 2,
            'learning_rate': 5e-5,
            'weight_decay': 1e-4,
            'grad_clip': 0.5,
            'num_epochs': 50,
            'save_every': 10,
            'hidden_dim': 128,
            'encoder_layers': 2,
            'decoder_layers': 2,
            'dropout': 0.3,
            'max_patience': 20,
            'label_smoothing': 0.1,
            'device': 'auto',
            'checkpoint_dir': 'checkpoints',
            'log_dir': 'logs',
            'tensorboard_log_dir': 'runs',
            'labels_file': 'data/labels.csv',
            'audio_dir': 'data/audio',
            'validation_split': 0.2,
            'random_seed': 42,
            'shuffle': True,
            'num_workers': 0,
            'pin_memory': False
        },
        'large': {
            'experiment_name': f'large_dataset_{datetime.now().strftime("%Y%m%d_%H%M%S")}',
            'batch_size': 4,
            'learning_rate': 1e-4,
            'weight_decay': 1e-5,
            'grad_clip': 1.0,
            'num_epochs': 100,
            'save_every': 20,
            'hidden_dim': 256,
            'encoder_layers': 4,
            'decoder_layers': 4,
            'dropout': 0.2,
            'max_patience': 25,
            'label_smoothing': 0.1,
            'device': 'auto',
            'checkpoint_dir': 'checkpoints',
            'log_dir': 'logs',
            'tensorboard_log_dir': 'runs',
            'labels_file': 'data/labels.csv',
            'audio_dir': 'data/audio',
            'validation_split': 0.2,
            'random_seed': 42,
            'shuffle': True,
            'num_workers': 0,
            'pin_memory': False
        },
        'xlarge': {
            'experiment_name': f'xlarge_dataset_{datetime.now().strftime("%Y%m%d_%H%M%S")}',
            'batch_size': 8,
            'learning_rate': 2e-4,
            'weight_decay': 1e-6,
            'grad_clip': 1.0,
            'num_epochs': 200,
            'save_every': 20,
            'hidden_dim': 512,
            'encoder_layers': 6,
            'decoder_layers': 6,
            'dropout': 0.1,
            'max_patience': 30,
            'label_smoothing': 0.1,
            'device': 'auto',
            'checkpoint_dir': 'checkpoints',
            'log_dir': 'logs',
            'tensorboard_log_dir': 'runs',
            'labels_file': 'data/labels.csv',
            'audio_dir': 'data/audio',
            'validation_split': 0.2,
            'random_seed': 42,
            'shuffle': True,
            'num_workers': 0,
            'pin_memory': False
        }
    }
    
    base_config = ConfigManager().get_default_config()
    scale_config = configs.get(scale, configs['medium'])
    base_config.update(scale_config)
    
    return base_config


def create_config_file(config_path: str, scale: str = 'medium') -> None:
    """
    åˆ›å»ºé…ç½®æ–‡ä»¶
    
    Args:
        config_path: é…ç½®æ–‡ä»¶è·¯å¾„
        scale: æ•°æ®é›†è§„æ¨¡
    """
    config = get_default_config(scale)
    
    with open(config_path, 'w', encoding='utf-8') as f:
        if config_path.endswith('.yaml') or config_path.endswith('.yml'):
            yaml.dump(config, f, default_flow_style=False, allow_unicode=True)
        else:
            import json
            json.dump(config, f, indent=2, ensure_ascii=False)
    
    print(f"é…ç½®æ–‡ä»¶å·²åˆ›å»º: {config_path}")


if __name__ == "__main__":
    # æµ‹è¯•é…ç½®ç®¡ç†
    print("ğŸ§ª é…ç½®ç®¡ç†ç³»ç»Ÿæµ‹è¯•")
    print("=" * 50)
    
    # æµ‹è¯•é»˜è®¤é…ç½®
    config_manager = ConfigManager()
    print("âœ… é»˜è®¤é…ç½®åŠ è½½æˆåŠŸ")
    
    # æµ‹è¯•ä¸åŒè§„æ¨¡é…ç½®
    for scale in ['small', 'medium', 'large', 'xlarge']:
        config = get_default_config(scale)
        print(f"âœ… {scale} è§„æ¨¡é…ç½®: {config['hidden_dim']} éšè—å±‚, {config['batch_size']} æ‰¹å¤§å°")
    
    # æµ‹è¯•é…ç½®éªŒè¯
    try:
        config_manager.update_config({'batch_size': -1})
    except ValueError as e:
        print(f"âœ… é…ç½®éªŒè¯æ­£å¸¸: {e}")
    
    print("\nğŸ’¡ ä½¿ç”¨æ–¹å¼:")
    print("from wavespectra2text.training.config import ConfigManager, get_default_config")
    print("config = ConfigManager('config.yaml')")
    print("config = get_default_config('medium')")
