#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æŸæœç´¢é—®é¢˜åˆ†æè„šæœ¬
è¯Šæ–­ä¸ºä»€ä¹ˆæŸæœç´¢æ€»æ˜¯è¿”å›ç©ºç»“æœ
"""

import os
import torch
import numpy as np
from inference_improved import ImprovedSpeechRecognizer
from vocab import vocab

def analyze_model_bias(model_path):
    """åˆ†ææ¨¡å‹å¯¹ä¸åŒtokençš„åç½®"""
    print("ğŸ” åˆ†ææ¨¡å‹tokenåç½®")
    print("-" * 40)
    
    try:
        recognizer = ImprovedSpeechRecognizer(model_path)
        
        # è·å–ä¸€ä¸ªæµ‹è¯•æ ·æœ¬
        test_audio = "data/audio/Chinese_Number_01.wav"
        spectrogram = recognizer._extract_spectrogram(test_audio).to(recognizer.device)
        
        with torch.no_grad():
            encoder_output = recognizer.model.encode(spectrogram)
            
            # åˆ†æç¬¬ä¸€æ­¥çš„è¾“å‡ºåˆ†å¸ƒ
            initial_seq = torch.LongTensor([[vocab.get_sos_idx()]]).to(recognizer.device)
            output = recognizer.model.decode_step(initial_seq, encoder_output)
            logits = output[:, -1, :]  # ç¬¬ä¸€æ­¥çš„logits
            probs = torch.softmax(logits, dim=-1)
            
            print("ç¬¬ä¸€æ­¥è§£ç çš„tokenæ¦‚ç‡åˆ†å¸ƒ:")
            for idx, prob in enumerate(probs[0]):
                token_name = vocab.idx_to_word.get(idx, f'IDX_{idx}')
                print(f"  {token_name}: {prob.item():.4f}")
            
            # æ£€æŸ¥EOS tokençš„æ¦‚ç‡
            eos_prob = probs[0, vocab.get_eos_idx()].item()
            print(f"\nâš ï¸  EOS tokenæ¦‚ç‡: {eos_prob:.4f}")
            
            if eos_prob > 0.3:
                print("âŒ EOS tokenæ¦‚ç‡è¿‡é«˜ï¼Œè¿™è§£é‡Šäº†ä¸ºä»€ä¹ˆæŸæœç´¢æ€»æ˜¯é€‰æ‹©ç»“æŸ")
            elif eos_prob > 0.1:
                print("âš ï¸  EOS tokenæ¦‚ç‡åé«˜ï¼Œå¯èƒ½å½±å“æŸæœç´¢")
            else:
                print("âœ… EOS tokenæ¦‚ç‡æ­£å¸¸")
            
            return eos_prob
            
    except Exception as e:
        print(f"âŒ åˆ†æå¤±è´¥: {e}")
        return None

def test_improved_beam_search(model_path, test_audio):
    """æµ‹è¯•æ”¹è¿›çš„æŸæœç´¢"""
    print("\nğŸ”§ æµ‹è¯•æ”¹è¿›çš„æŸæœç´¢")
    print("-" * 40)
    
    try:
        recognizer = ImprovedSpeechRecognizer(model_path)
        spectrogram = recognizer._extract_spectrogram(test_audio).to(recognizer.device)
        
        with torch.no_grad():
            encoder_output = recognizer.model.encode(spectrogram)
            
            # æµ‹è¯•ä¸åŒçš„æŸæœç´¢é…ç½®
            configs = [
                {"beam_size": 1, "max_length": 5},
                {"beam_size": 3, "max_length": 5},
                {"beam_size": 5, "max_length": 5},
                {"beam_size": 3, "max_length": 10},
            ]
            
            for i, config in enumerate(configs):
                print(f"\né…ç½® {i+1}: æŸå¤§å°={config['beam_size']}, æœ€å¤§é•¿åº¦={config['max_length']}")
                
                # ä½¿ç”¨æ”¹è¿›çš„æŸæœç´¢
                beam_seq, beam_score = improved_beam_search(
                    recognizer.model, encoder_output, 
                    beam_size=config['beam_size'], 
                    max_length=config['max_length']
                )
                
                beam_text = vocab.decode(beam_seq.tolist())
                print(f"  ç»“æœ: '{beam_text}'")
                print(f"  åºåˆ—: {beam_seq.tolist()}")
                print(f"  å¾—åˆ†: {beam_score:.3f}")
                
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")

def improved_beam_search(model, encoder_output, beam_size=3, max_length=10, eos_penalty=-1.0):
    """æ”¹è¿›çš„æŸæœç´¢ - æ·»åŠ EOSæƒ©ç½š"""
    device = encoder_output.device
    beams = [(torch.LongTensor([[vocab.get_sos_idx()]]).to(device), 0.0)]
    
    for step in range(max_length):
        new_beams = []
        
        for seq, score in beams:
            if seq[0, -1].item() == vocab.get_eos_idx():
                new_beams.append((seq, score))
                continue
            
            with torch.no_grad():
                output = model.decode_step(seq, encoder_output)
                logits = output[:, -1, :]
                
                # å¯¹EOS tokenæ·»åŠ æƒ©ç½š (å¦‚æœåºåˆ—å¤ªçŸ­)
                if seq.size(1) < 3:  # å¦‚æœåºåˆ—é•¿åº¦å°äº3ï¼Œæƒ©ç½šEOS
                    logits[0, vocab.get_eos_idx()] += eos_penalty
                
                probs = torch.softmax(logits, dim=-1)
            
            top_probs, top_indices = torch.topk(probs, beam_size)
            
            for i in range(beam_size):
                new_seq = torch.cat([seq, top_indices[:, i:i + 1]], dim=1)
                new_score = score + torch.log(top_probs[:, i]).item()
                new_beams.append((new_seq, new_score))
        
        new_beams.sort(key=lambda x: x[1], reverse=True)
        beams = new_beams[:beam_size]
        
        if all(seq[0, -1].item() == vocab.get_eos_idx() for seq, _ in beams):
            break
    
    best_seq, best_score = beams[0]
    return best_seq.squeeze(0), best_score

def suggest_beam_search_fixes():
    """å»ºè®®æŸæœç´¢ä¿®å¤æ–¹æ¡ˆ"""
    print("\nğŸ’¡ æŸæœç´¢ä¿®å¤å»ºè®®")
    print("=" * 50)
    
    suggestions = [
        {
            "é—®é¢˜": "EOS tokenæ¦‚ç‡è¿‡é«˜",
            "è§£å†³æ–¹æ¡ˆ": [
                "1. åœ¨æŸæœç´¢ä¸­å¯¹çŸ­åºåˆ—çš„EOSæ·»åŠ æƒ©ç½š",
                "2. è°ƒæ•´è®­ç»ƒæ—¶çš„æ ‡ç­¾å¹³æ»‘",
                "3. å¢åŠ æœ€å°åºåˆ—é•¿åº¦é™åˆ¶"
            ]
        },
        {
            "é—®é¢˜": "æ¨¡å‹è®­ç»ƒä¸å……åˆ†",
            "è§£å†³æ–¹æ¡ˆ": [
                "1. ç»§ç»­è®­ç»ƒæ›´å¤šepoch",
                "2. é™ä½å­¦ä¹ ç‡ç²¾ç»†è°ƒä¼˜",
                "3. æ£€æŸ¥è®­ç»ƒæŸå¤±æ›²çº¿"
            ]
        },
        {
            "é—®é¢˜": "æŸæœç´¢å‚æ•°ä¸å½“",
            "è§£å†³æ–¹æ¡ˆ": [
                "1. å°è¯•ä¸åŒçš„æŸå¤§å° (1, 3, 5)",
                "2. è°ƒæ•´æœ€å¤§åºåˆ—é•¿åº¦",
                "3. æ·»åŠ é•¿åº¦æƒ©ç½šæœºåˆ¶"
            ]
        }
    ]
    
    for suggestion in suggestions:
        print(f"\nğŸ¯ {suggestion['é—®é¢˜']}:")
        for solution in suggestion['è§£å†³æ–¹æ¡ˆ']:
            print(f"  {solution}")

def create_fixed_beam_search_recognizer():
    """åˆ›å»ºä¿®å¤ç‰ˆæŸæœç´¢è¯†åˆ«å™¨"""
    print("\nğŸ› ï¸ åˆ›å»ºä¿®å¤ç‰ˆæŸæœç´¢è¯†åˆ«å™¨")
    print("-" * 40)
    
    code = '''
class FixedBeamSearchRecognizer(ImprovedSpeechRecognizer):
    """ä¿®å¤ç‰ˆæŸæœç´¢è¯†åˆ«å™¨"""
    
    def _beam_search_fixed(self, encoder_output, beam_size=3, max_length=10):
        """ä¿®å¤ç‰ˆæŸæœç´¢ - æ·»åŠ EOSæƒ©ç½šå’Œé•¿åº¦å¥–åŠ±"""
        device = encoder_output.device
        beams = [(torch.LongTensor([[vocab.get_sos_idx()]]).to(device), 0.0)]
        
        for step in range(max_length):
            new_beams = []
            
            for seq, score in beams:
                if seq[0, -1].item() == vocab.get_eos_idx():
                    # å¯¹è¿‡çŸ­çš„åºåˆ—æ·»åŠ æƒ©ç½š
                    if seq.size(1) < 3:
                        score -= 2.0  # æƒ©ç½šè¿‡çŸ­åºåˆ—
                    new_beams.append((seq, score))
                    continue
                
                with torch.no_grad():
                    output = self.model.decode_step(seq, encoder_output)
                    logits = output[:, -1, :]
                    
                    # å¯¹è¿‡æ—©çš„EOSæ·»åŠ æƒ©ç½š
                    if seq.size(1) < 3:
                        logits[0, vocab.get_eos_idx()] -= 1.0
                    
                    probs = torch.softmax(logits, dim=-1)
                
                top_probs, top_indices = torch.topk(probs, beam_size)
                
                for i in range(beam_size):
                    new_seq = torch.cat([seq, top_indices[:, i:i + 1]], dim=1)
                    new_score = score + torch.log(top_probs[:, i]).item()
                    
                    # é•¿åº¦å¥–åŠ±
                    if top_indices[:, i].item() != vocab.get_eos_idx():
                        new_score += 0.1  # é¼“åŠ±ç”Ÿæˆæ›´é•¿åºåˆ—
                    
                    new_beams.append((new_seq, new_score))
            
            new_beams.sort(key=lambda x: x[1], reverse=True)
            beams = new_beams[:beam_size]
            
            if all(seq[0, -1].item() == vocab.get_eos_idx() for seq, _ in beams):
                break
        
        best_seq, best_score = beams[0]
        return best_seq.squeeze(0), best_score
    '''
    
    print("ä¿®å¤ç‰ˆæŸæœç´¢ä»£ç å·²å‡†å¤‡å¥½")
    print("ä¸»è¦æ”¹è¿›:")
    print("1. âœ… å¯¹è¿‡çŸ­åºåˆ—çš„EOSæ·»åŠ æƒ©ç½š")
    print("2. âœ… å¯¹éEOS tokenæ·»åŠ é•¿åº¦å¥–åŠ±")
    print("3. âœ… åŠ¨æ€è°ƒæ•´EOSæ¦‚ç‡")
    
    return code

def main():
    """ä¸»å‡½æ•°"""
    model_path = "checkpoints/test_model.pth"
    test_audio = "data/audio/Chinese_Number_01.wav"
    
    if not os.path.exists(model_path):
        print(f"âŒ æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {model_path}")
        return
    
    print("ğŸ¯ æŸæœç´¢é—®é¢˜åˆ†æ")
    print("=" * 60)
    
    # åˆ†ææ¨¡å‹åç½®
    eos_prob = analyze_model_bias(model_path)
    
    # æµ‹è¯•æ”¹è¿›çš„æŸæœç´¢
    test_improved_beam_search(model_path, test_audio)
    
    # æä¾›ä¿®å¤å»ºè®®
    suggest_beam_search_fixes()
    
    # åˆ›å»ºä¿®å¤ç‰ˆè¯†åˆ«å™¨
    create_fixed_beam_search_recognizer()
    
    print(f"\nğŸ¯ æ€»ç»“:")
    if eos_prob and eos_prob > 0.3:
        print("âŒ æŸæœç´¢é—®é¢˜ä¸»è¦æ˜¯EOS tokenæ¦‚ç‡è¿‡é«˜")
        print("ğŸ’¡ å»ºè®®: ä½¿ç”¨è´ªå©ªè§£ç æˆ–ä¿®å¤æŸæœç´¢ç®—æ³•")
    elif eos_prob and eos_prob > 0.1:
        print("âš ï¸  æŸæœç´¢å¯èƒ½å—EOS tokenå½±å“")
        print("ğŸ’¡ å»ºè®®: å°è¯•ä¿®å¤ç‰ˆæŸæœç´¢æˆ–ç»§ç»­è®­ç»ƒ")
    else:
        print("âœ… æ¨¡å‹æ¦‚ç‡åˆ†å¸ƒç›¸å¯¹æ­£å¸¸")
        print("ğŸ’¡ å»ºè®®: æ£€æŸ¥æŸæœç´¢å‚æ•°æˆ–è®­ç»ƒæ›´å¤šepoch")

if __name__ == "__main__":
    main()