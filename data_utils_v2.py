#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ•°æ®å¤„ç†å·¥å…· V2 - é•¿æœŸé‡æ„ç‰ˆæœ¬
æ”¯æŒæ™ºèƒ½æ¨¡å¼åˆ‡æ¢ï¼Œæ¶ˆé™¤ä»£ç å†—ä½™
"""

import os
import pandas as pd
import torch
from torch.utils.data import Dataset, DataLoader
from vocab import vocab
from spectrum_utils import SpectrumProcessor
import warnings
warnings.filterwarnings('ignore')

class SmartAudioSpectrogramDataset(Dataset):
    """æ™ºèƒ½éŸ³é¢‘é¢‘è°±æ•°æ®é›† - è‡ªåŠ¨é€‰æ‹©æœ€ä¼˜å¤„ç†æ¨¡å¼"""
    
    def __init__(self, audio_dir, labels_file, spectrum_dir=None, 
                 sample_rate=48000, n_fft=1024, hop_length=512, max_length=200):
        """
        åˆå§‹åŒ–æ™ºèƒ½æ•°æ®é›†
        
        Args:
            audio_dir: éŸ³é¢‘æ–‡ä»¶ç›®å½•
            labels_file: æ ‡ç­¾æ–‡ä»¶è·¯å¾„
            spectrum_dir: é¢„å¤„ç†é¢‘è°±ç›®å½• (å¯é€‰ï¼Œå¦‚æœå­˜åœ¨åˆ™ä¼˜å…ˆä½¿ç”¨)
            å…¶ä»–å‚æ•°: é¢‘è°±å¤„ç†å‚æ•°
        """
        self.audio_dir = audio_dir
        self.spectrum_dir = spectrum_dir
        self.labels_file = labels_file
        
        # åˆ›å»ºç»Ÿä¸€çš„é¢‘è°±å¤„ç†å™¨
        self.spectrum_processor = SpectrumProcessor(sample_rate, n_fft, hop_length, max_length)
        
        # æ™ºèƒ½æ£€æµ‹å¤„ç†æ¨¡å¼
        self.processing_mode = self._detect_processing_mode()
        
        # åŠ è½½æ ‡ç­¾
        self.labels_df = pd.read_csv(labels_file)
        
        # å‡†å¤‡æ•°æ®
        self.data = []
        self._prepare_data()
    
    def _detect_processing_mode(self):
        """æ™ºèƒ½æ£€æµ‹æœ€ä¼˜çš„å¤„ç†æ¨¡å¼"""
        if self.spectrum_dir and os.path.exists(self.spectrum_dir):
            spectrum_index = os.path.join(self.spectrum_dir, 'spectrum_index.csv')
            if os.path.exists(spectrum_index):
                print("ğŸš€ æ£€æµ‹åˆ°é¢„å¤„ç†é¢‘è°±ï¼Œä½¿ç”¨é¢„å¤„ç†æ¨¡å¼")
                return 'preprocessed'
        
        print("âš¡ æœªæ£€æµ‹åˆ°é¢„å¤„ç†é¢‘è°±ï¼Œä½¿ç”¨å®æ—¶å¤„ç†æ¨¡å¼")
        return 'realtime'
    
    def _prepare_data(self):
        """æ ¹æ®å¤„ç†æ¨¡å¼å‡†å¤‡æ•°æ®"""
        if self.processing_mode == 'preprocessed':
            self._prepare_preprocessed_data()
        else:
            self._prepare_realtime_data()
        
        print(f"âœ… æ•°æ®å‡†å¤‡å®Œæˆ: {len(self.data)} ä¸ªæ ·æœ¬ ({self.processing_mode} æ¨¡å¼)")
    
    def _prepare_preprocessed_data(self):
        """å‡†å¤‡é¢„å¤„ç†æ•°æ®"""
        spectrum_index_file = os.path.join(self.spectrum_dir, 'spectrum_index.csv')
        
        try:
            spectrum_df = pd.read_csv(spectrum_index_file)
            
            # åˆå¹¶æ ‡ç­¾å’Œé¢‘è°±ç´¢å¼•
            merged_df = pd.merge(
                self.labels_df, 
                spectrum_df, 
                left_on='filename', 
                right_on='original_audio',
                how='inner'
            )
            
            for _, row in merged_df.iterrows():
                spectrum_path = os.path.join(self.spectrum_dir, row['spectrum_file'])
                
                if os.path.exists(spectrum_path):
                    encoded_label = vocab.encode(row['label'])
                    
                    self.data.append({
                        'source_path': spectrum_path,
                        'label': encoded_label,
                        'text': row['label'],
                        'filename': row['filename'],
                        'mode': 'preprocessed'
                    })
                else:
                    print(f"âš ï¸ é¢‘è°±æ–‡ä»¶ä¸å­˜åœ¨: {spectrum_path}")
        
        except Exception as e:
            print(f"âš ï¸ é¢„å¤„ç†æ¨¡å¼å¤±è´¥ï¼Œåˆ‡æ¢åˆ°å®æ—¶æ¨¡å¼: {e}")
            self.processing_mode = 'realtime'
            self._prepare_realtime_data()
    
    def _prepare_realtime_data(self):
        """å‡†å¤‡å®æ—¶å¤„ç†æ•°æ®"""
        for _, row in self.labels_df.iterrows():
            audio_file = row['filename']
            label = row['label']
            
            audio_path = os.path.join(self.audio_dir, audio_file)
            
            if os.path.exists(audio_path):
                encoded_label = vocab.encode(label)
                
                self.data.append({
                    'source_path': audio_path,
                    'label': encoded_label,
                    'text': label,
                    'filename': audio_file,
                    'mode': 'realtime'
                })
            else:
                print(f"âš ï¸ éŸ³é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {audio_path}")
    
    def __len__(self):
        return len(self.data)
    
    def __getitem__(self, idx):
        sample = self.data[idx]
        
        # æ ¹æ®æ¨¡å¼åŠ è½½é¢‘è°± - ä½¿ç”¨ç»Ÿä¸€çš„å¤„ç†å™¨
        if sample['mode'] == 'preprocessed':
            spectrogram = self.spectrum_processor.load_spectrum_from_file(sample['source_path'])
        else:
            spectrogram = self.spectrum_processor.extract_spectrum_from_audio(sample['source_path'])
        
        # å¤„ç†åŠ è½½å¤±è´¥çš„æƒ…å†µ
        if spectrogram is None:
            print(f"âš ï¸ é¢‘è°±åŠ è½½å¤±è´¥: {sample['source_path']}")
            # åˆ›å»ºé›¶é¢‘è°±ä½œä¸ºfallback
            spectrogram = self._create_zero_spectrum()
        
        # è½¬æ¢ä¸ºtensor
        spectrogram_tensor = torch.FloatTensor(spectrogram)
        label_tensor = torch.LongTensor(sample['label'])
        
        return {
            'spectrogram': spectrogram_tensor,
            'label': label_tensor,
            'text': sample['text'],
            'filename': sample['filename']
        }
    
    def _create_zero_spectrum(self):
        """åˆ›å»ºé›¶é¢‘è°±ä½œä¸ºfallback"""
        return np.zeros((self.spectrum_processor.max_length, self.spectrum_processor.freq_bins), dtype=np.float32)
    
    def get_processing_info(self):
        """è·å–å¤„ç†ä¿¡æ¯"""
        return {
            'mode': self.processing_mode,
            'total_samples': len(self.data),
            'spectrum_config': self.spectrum_processor.get_config()
        }

def collate_fn(batch):
    """æ‰¹å¤„ç†å‡½æ•° - ä¿æŒä¸åŸç‰ˆå…¼å®¹"""
    spectrograms = []
    labels = []
    texts = []
    filenames = []
    
    for sample in batch:
        spectrograms.append(sample['spectrogram'])
        labels.append(sample['label'])
        texts.append(sample['text'])
        filenames.append(sample['filename'])
    
    # å †å é¢‘è°±
    spectrograms = torch.stack(spectrograms)
    
    # å¡«å……æ ‡ç­¾åˆ°ç›¸åŒé•¿åº¦
    max_label_len = max(len(label) for label in labels)
    padded_labels = []
    
    for label in labels:
        if len(label) < max_label_len:
            padded = torch.cat([
                label, 
                torch.full((max_label_len - len(label),), vocab.get_padding_idx(), dtype=torch.long)
            ])
        else:
            padded = label
        padded_labels.append(padded)
    
    labels = torch.stack(padded_labels)
    
    return {
        'spectrograms': spectrograms,
        'labels': labels,
        'texts': texts,
        'filenames': filenames
    }

def get_smart_dataloader(audio_dir='data/audio', labels_file='data/labels.csv', 
                        spectrum_dir='data/spectrums', batch_size=4, shuffle=True, num_workers=0):
    """
    è·å–æ™ºèƒ½æ•°æ®åŠ è½½å™¨ - è‡ªåŠ¨é€‰æ‹©æœ€ä¼˜æ¨¡å¼
    
    Args:
        spectrum_dir: é¢„å¤„ç†é¢‘è°±ç›®å½•ï¼Œå¦‚æœå­˜åœ¨ä¸”æœ‰æ•ˆåˆ™ä½¿ç”¨é¢„å¤„ç†æ¨¡å¼
    """
    dataset = SmartAudioSpectrogramDataset(
        audio_dir=audio_dir,
        labels_file=labels_file,
        spectrum_dir=spectrum_dir
    )
    
    # æ˜¾ç¤ºå¤„ç†ä¿¡æ¯
    info = dataset.get_processing_info()
    print(f"ğŸ“Š æ•°æ®åŠ è½½å™¨ä¿¡æ¯: {info['mode']} æ¨¡å¼, {info['total_samples']} æ ·æœ¬")
    
    dataloader = DataLoader(
        dataset,
        batch_size=batch_size,
        shuffle=shuffle,
        num_workers=num_workers,
        collate_fn=collate_fn
    )
    
    return dataloader

# å‘åå…¼å®¹çš„æ¥å£
def get_dataloader(*args, **kwargs):
    """å‘åå…¼å®¹çš„æ•°æ®åŠ è½½å™¨æ¥å£"""
    return get_smart_dataloader(*args, **kwargs)

# åˆ›å»ºåŸå§‹æ•°æ®é›†çš„åˆ«å (å‘åå…¼å®¹)
AudioSpectrogramDataset = SmartAudioSpectrogramDataset

if __name__ == "__main__":
    print("ğŸ§ª æµ‹è¯•æ™ºèƒ½æ•°æ®åŠ è½½å™¨")
    
    # æµ‹è¯•æ™ºèƒ½æ¨¡å¼é€‰æ‹©
    try:
        dataloader = get_smart_dataloader(batch_size=2)
        
        # è·å–ä¸€ä¸ªæ‰¹æ¬¡æµ‹è¯•
        for batch in dataloader:
            print(f"âœ… æ‰¹æ¬¡æµ‹è¯•æˆåŠŸ:")
            print(f"   é¢‘è°±å½¢çŠ¶: {batch['spectrograms'].shape}")
            print(f"   æ ‡ç­¾å½¢çŠ¶: {batch['labels'].shape}")
            print(f"   æ–‡æœ¬: {batch['texts']}")
            break
            
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        print("è¯·ç¡®ä¿å®‰è£…äº†å¿…è¦çš„ä¾èµ–åŒ…")
    
    print("âœ… V2æ•°æ®å¤„ç†å·¥å…·æµ‹è¯•å®Œæˆ")