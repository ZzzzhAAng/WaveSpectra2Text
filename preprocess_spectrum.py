#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
é¢„å¤„ç†åˆ†ç¦»å®ç° - ç¦»çº¿é¢‘è°±æå–
å°†éŸ³é¢‘é¢„å¤„ç†å’Œæ¨¡å‹æ¨ç†å®Œå…¨åˆ†ç¦»
"""

import os
import numpy as np
import pandas as pd
import librosa
from pathlib import Path
import json
from tqdm import tqdm
import argparse

class SpectrumPreprocessor:
    """é¢‘è°±é¢„å¤„ç†å™¨ - ç¦»çº¿æå–é¢‘è°±ç‰¹å¾"""
    
    def __init__(self, sample_rate=48000, n_fft=1024, hop_length=512, max_length=200):
        """
        åˆå§‹åŒ–é¢„å¤„ç†å™¨
        
        Args:
            sample_rate: ç›®æ ‡é‡‡æ ·ç‡
            n_fft: FFTçª—å£å¤§å°
            hop_length: è·³è·ƒé•¿åº¦
            max_length: æœ€å¤§åºåˆ—é•¿åº¦
        """
        self.sample_rate = sample_rate
        self.n_fft = n_fft
        self.hop_length = hop_length
        self.max_length = max_length
        
        # é¢‘è°±å‚æ•°
        self.freq_bins = n_fft // 2 + 1  # 513
        
        print(f"é¢‘è°±é¢„å¤„ç†å™¨åˆå§‹åŒ–:")
        print(f"  é‡‡æ ·ç‡: {sample_rate}Hz")
        print(f"  FFTçª—å£: {n_fft}")
        print(f"  è·³è·ƒé•¿åº¦: {hop_length}")
        print(f"  é¢‘ç‡bins: {self.freq_bins}")
        print(f"  æœ€å¤§é•¿åº¦: {max_length}å¸§")
    
    def extract_spectrum_from_audio(self, audio_path):
        """ä»éŸ³é¢‘æ–‡ä»¶æå–é¢‘è°±"""
        try:
            # åŠ è½½éŸ³é¢‘
            audio, sr = librosa.load(audio_path, sr=self.sample_rate)
            
            # æå–STFTé¢‘è°±
            stft = librosa.stft(audio, n_fft=self.n_fft, hop_length=self.hop_length)
            magnitude = np.abs(stft)  # å¹…åº¦è°±
            
            # è½¬æ¢ä¸ºå¯¹æ•°åˆ»åº¦
            log_magnitude = np.log1p(magnitude)
            
            # è½¬ç½®ä½¿æ—¶é—´ç»´åº¦åœ¨å‰
            spectrogram = log_magnitude.T  # (time_steps, freq_bins)
            
            # å¡«å……æˆ–æˆªæ–­åˆ°å›ºå®šé•¿åº¦
            if len(spectrogram) > self.max_length:
                spectrogram = spectrogram[:self.max_length]
            else:
                pad_length = self.max_length - len(spectrogram)
                spectrogram = np.pad(spectrogram, ((0, pad_length), (0, 0)), mode='constant')
            
            return spectrogram.astype(np.float32)
            
        except Exception as e:
            print(f"å¤„ç†éŸ³é¢‘æ–‡ä»¶ {audio_path} æ—¶å‡ºé”™: {e}")
            return None
    
    def process_audio_directory(self, audio_dir, labels_file, output_dir):
        """æ‰¹é‡å¤„ç†éŸ³é¢‘ç›®å½•"""
        print(f"\nå¼€å§‹æ‰¹é‡å¤„ç†éŸ³é¢‘ç›®å½•: {audio_dir}")
        
        # åˆ›å»ºè¾“å‡ºç›®å½•
        os.makedirs(output_dir, exist_ok=True)
        
        # è¯»å–æ ‡ç­¾æ–‡ä»¶
        if not os.path.exists(labels_file):
            print(f"é”™è¯¯: æ ‡ç­¾æ–‡ä»¶ä¸å­˜åœ¨ {labels_file}")
            return None
        
        df = pd.read_csv(labels_file)
        
        # å¤„ç†ç»“æœ
        processed_data = []
        success_count = 0
        
        for idx, row in tqdm(df.iterrows(), total=len(df), desc="å¤„ç†éŸ³é¢‘"):
            audio_file = row['filename']
            label = row['label']
            
            audio_path = os.path.join(audio_dir, audio_file)
            
            if os.path.exists(audio_path):
                # æå–é¢‘è°±
                spectrogram = self.extract_spectrum_from_audio(audio_path)
                
                if spectrogram is not None:
                    # ä¿å­˜é¢‘è°±æ–‡ä»¶
                    spectrum_filename = f"{Path(audio_file).stem}.npy"
                    spectrum_path = os.path.join(output_dir, spectrum_filename)
                    np.save(spectrum_path, spectrogram)
                    
                    processed_data.append({
                        'spectrum_file': spectrum_filename,
                        'original_audio': audio_file,
                        'label': label,
                        'shape': spectrogram.shape
                    })
                    
                    success_count += 1
                else:
                    print(f"è·³è¿‡æ–‡ä»¶: {audio_file} (å¤„ç†å¤±è´¥)")
            else:
                print(f"è·³è¿‡æ–‡ä»¶: {audio_file} (æ–‡ä»¶ä¸å­˜åœ¨)")
        
        # ä¿å­˜å¤„ç†ç»“æœç´¢å¼•
        processed_df = pd.DataFrame(processed_data)
        index_file = os.path.join(output_dir, 'spectrum_index.csv')
        processed_df.to_csv(index_file, index=False, encoding='utf-8')
        
        # ä¿å­˜é¢„å¤„ç†å‚æ•°
        params = {
            'sample_rate': self.sample_rate,
            'n_fft': self.n_fft,
            'hop_length': self.hop_length,
            'max_length': self.max_length,
            'freq_bins': self.freq_bins,
            'total_files': len(df),
            'processed_files': success_count
        }
        
        params_file = os.path.join(output_dir, 'preprocess_params.json')
        with open(params_file, 'w', encoding='utf-8') as f:
            json.dump(params, f, indent=2, ensure_ascii=False)
        
        print(f"\nå¤„ç†å®Œæˆ:")
        print(f"  æ€»æ–‡ä»¶æ•°: {len(df)}")
        print(f"  æˆåŠŸå¤„ç†: {success_count}")
        print(f"  é¢‘è°±æ–‡ä»¶ä¿å­˜åˆ°: {output_dir}")
        print(f"  ç´¢å¼•æ–‡ä»¶: {index_file}")
        print(f"  å‚æ•°æ–‡ä»¶: {params_file}")
        
        return processed_df
    
    def validate_spectrum_files(self, spectrum_dir):
        """éªŒè¯é¢‘è°±æ–‡ä»¶"""
        print(f"\néªŒè¯é¢‘è°±æ–‡ä»¶: {spectrum_dir}")
        
        index_file = os.path.join(spectrum_dir, 'spectrum_index.csv')
        if not os.path.exists(index_file):
            print("é”™è¯¯: æ‰¾ä¸åˆ°ç´¢å¼•æ–‡ä»¶ spectrum_index.csv")
            return False
        
        df = pd.read_csv(index_file)
        
        valid_count = 0
        for _, row in df.iterrows():
            spectrum_file = os.path.join(spectrum_dir, row['spectrum_file'])
            
            if os.path.exists(spectrum_file):
                try:
                    spectrum = np.load(spectrum_file)
                    expected_shape = eval(row['shape']) if isinstance(row['shape'], str) else row['shape']
                    
                    if spectrum.shape == expected_shape:
                        valid_count += 1
                    else:
                        print(f"å½¢çŠ¶ä¸åŒ¹é…: {row['spectrum_file']} - æœŸæœ›{expected_shape}, å®é™…{spectrum.shape}")
                except Exception as e:
                    print(f"åŠ è½½å¤±è´¥: {row['spectrum_file']} - {e}")
            else:
                print(f"æ–‡ä»¶ç¼ºå¤±: {row['spectrum_file']}")
        
        print(f"éªŒè¯ç»“æœ: {valid_count}/{len(df)} æ–‡ä»¶æœ‰æ•ˆ")
        return valid_count == len(df)

def create_spectrum_only_inference():
    """åˆ›å»ºçº¯é¢‘è°±æ¨ç†è„šæœ¬"""
    
    inference_code = '''#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
çº¯é¢‘è°±æ¨ç†è„šæœ¬ - å®Œå…¨ç‹¬ç«‹äºéŸ³é¢‘æ–‡ä»¶
åªéœ€è¦é¢„æå–çš„é¢‘è°±æ–‡ä»¶å’Œè®­ç»ƒå¥½çš„æ¨¡å‹
"""

import os
import torch
import numpy as np
import pandas as pd
import json
from vocab import vocab

class SpectrumOnlyRecognizer:
    """çº¯é¢‘è°±è¯†åˆ«å™¨ - ä¸ä¾èµ–éŸ³é¢‘å¤„ç†"""
    
    def __init__(self, model_path):
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        self.model = self._load_model(model_path)
        self.model.eval()
    
    def _load_model(self, model_path):
        """åŠ è½½æ¨¡å‹"""
        from model import create_model
        
        checkpoint = torch.load(model_path, map_location=self.device)
        config = checkpoint.get('config', {})
        
        model = create_model(
            vocab_size=vocab.vocab_size,
            hidden_dim=config.get('hidden_dim', 256),
            encoder_layers=config.get('encoder_layers', 4),
            decoder_layers=config.get('decoder_layers', 4),
            dropout=config.get('dropout', 0.1)
        )
        
        model.load_state_dict(checkpoint['model_state_dict'])
        model.to(self.device)
        
        return model
    
    def recognize_from_spectrum(self, spectrum_path, use_beam_search=True, beam_size=3):
        """ä»é¢‘è°±æ–‡ä»¶è¯†åˆ«æ–‡æœ¬"""
        try:
            # åŠ è½½é¢‘è°±
            spectrogram = np.load(spectrum_path)
            spectrogram_tensor = torch.FloatTensor(spectrogram).unsqueeze(0).to(self.device)
            
            with torch.no_grad():
                # ç¼–ç 
                encoder_output = self.model.encode(spectrogram_tensor)
                
                # è§£ç 
                if use_beam_search:
                    decoded_seq, score = self._beam_search(encoder_output, beam_size)
                else:
                    decoded_seq = self._greedy_decode(encoder_output)
                    score = None
                
                # è½¬æ¢ä¸ºæ–‡æœ¬
                text = vocab.decode(decoded_seq.tolist())
                
                return {
                    'text': text,
                    'score': score,
                    'success': True
                }
        
        except Exception as e:
            return {
                'text': '',
                'score': None,
                'success': False,
                'error': str(e)
            }
    
    def batch_recognize(self, spectrum_dir):
        """æ‰¹é‡è¯†åˆ«é¢‘è°±ç›®å½•"""
        index_file = os.path.join(spectrum_dir, 'spectrum_index.csv')
        
        if not os.path.exists(index_file):
            print("é”™è¯¯: æ‰¾ä¸åˆ°é¢‘è°±ç´¢å¼•æ–‡ä»¶")
            return []
        
        df = pd.read_csv(index_file)
        results = []
        
        for _, row in df.iterrows():
            spectrum_path = os.path.join(spectrum_dir, row['spectrum_file'])
            result = self.recognize_from_spectrum(spectrum_path)
            
            result.update({
                'spectrum_file': row['spectrum_file'],
                'original_audio': row['original_audio'],
                'expected_label': row['label']
            })
            
            results.append(result)
        
        return results

# ä½¿ç”¨ç¤ºä¾‹
if __name__ == "__main__":
    recognizer = SpectrumOnlyRecognizer("checkpoints/best_model.pth")
    
    # å•æ–‡ä»¶è¯†åˆ«
    result = recognizer.recognize_from_spectrum("spectrums/audio_001.npy")
    print(f"è¯†åˆ«ç»“æœ: {result['text']}")
    
    # æ‰¹é‡è¯†åˆ«
    results = recognizer.batch_recognize("spectrums/")
    for result in results:
        print(f"{result['original_audio']} -> {result['text']}")
'''
    
    with open('spectrum_only_inference.py', 'w', encoding='utf-8') as f:
        f.write(inference_code)
    
    print("âœ… å·²åˆ›å»ºçº¯é¢‘è°±æ¨ç†è„šæœ¬: spectrum_only_inference.py")

def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description='é¢‘è°±é¢„å¤„ç†å·¥å…·')
    parser.add_argument('--audio_dir', default='data/audio', help='éŸ³é¢‘ç›®å½•')
    parser.add_argument('--labels_file', default='data/labels.csv', help='æ ‡ç­¾æ–‡ä»¶')
    parser.add_argument('--output_dir', default='data/spectrums', help='è¾“å‡ºç›®å½•')
    parser.add_argument('--validate', action='store_true', help='éªŒè¯é¢‘è°±æ–‡ä»¶')
    parser.add_argument('--create_inference', action='store_true', help='åˆ›å»ºçº¯é¢‘è°±æ¨ç†è„šæœ¬')
    
    args = parser.parse_args()
    
    print("ğŸ¯ é¢‘è°±é¢„å¤„ç†åˆ†ç¦»å·¥å…·")
    print("=" * 60)
    
    if args.create_inference:
        create_spectrum_only_inference()
        return
    
    # åˆ›å»ºé¢„å¤„ç†å™¨
    preprocessor = SpectrumPreprocessor()
    
    if args.validate:
        # éªŒè¯ç°æœ‰é¢‘è°±æ–‡ä»¶
        preprocessor.validate_spectrum_files(args.output_dir)
    else:
        # æ‰¹é‡å¤„ç†éŸ³é¢‘æ–‡ä»¶
        result = preprocessor.process_audio_directory(
            args.audio_dir, 
            args.labels_file, 
            args.output_dir
        )
        
        if result is not None:
            print(f"\nâœ… é¢„å¤„ç†å®Œæˆ!")
            print(f"ç°åœ¨å¯ä»¥ä½¿ç”¨çº¯é¢‘è°±æ¨ç†ï¼Œå®Œå…¨ç‹¬ç«‹äºéŸ³é¢‘æ–‡ä»¶")
            print(f"é¢‘è°±æ–‡ä»¶ç›®å½•: {args.output_dir}")

if __name__ == "__main__":
    main()
'''

# ä½¿ç”¨æ–¹æ³•è¯´æ˜
ä½¿ç”¨æ­¥éª¤:
1. é¢„å¤„ç†: python preprocess_spectrum.py --audio_dir data/audio --labels_file data/labels.csv --output_dir data/spectrums
2. åˆ›å»ºæ¨ç†è„šæœ¬: python preprocess_spectrum.py --create_inference  
3. çº¯é¢‘è°±æ¨ç†: python spectrum_only_inference.py
4. éªŒè¯: python preprocess_spectrum.py --validate --output_dir data/spectrums
'''