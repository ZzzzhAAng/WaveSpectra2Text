
# ğŸ¯ æ¨ç†ç³»ç»Ÿä½¿ç”¨æŒ‡å—

## åŸºæœ¬ç”¨æ³•

### 1. å•æ–‡ä»¶æ¨ç†
```bash
python inference.py --model checkpoints/best_model.pth --audio data/audio/test.wav
```

### 2. æ‰¹é‡æ¨ç†
```bash
python inference.py --model checkpoints/best_model.pth --audio_dir data/audio
```

### 3. æ•°æ®é›†è¯„ä¼°
```bash
python inference.py \
    --model checkpoints/best_model.pth \
    --audio_dir data/audio \
    --labels data/labels.csv \
    --output results.csv
```

## Python API ç”¨æ³•

```python
from inference import SpeechRecognizer

# åˆ›å»ºè¯†åˆ«å™¨
recognizer = SpeechRecognizer('checkpoints/best_model.pth')

# å•æ–‡ä»¶è¯†åˆ«
result = recognizer.recognize_file('test.wav')
print(f"è¯†åˆ«ç»“æœ: {result['text']}")

# æ‰¹é‡è¯†åˆ«
results = recognizer.recognize_batch(['file1.wav', 'file2.wav'])
for result in results:
    print(f"{result['file']}: {result['text']}")

# æ•°æ®é›†è¯„ä¼°
results, accuracy = recognizer.evaluate_on_dataset('data/audio', 'data/labels.csv')
print(f"å‡†ç¡®ç‡: {accuracy:.2%}")
```

## é«˜çº§é€‰é¡¹

- `--beam_size 5`: æŸæœç´¢å¤§å°
- `--no_beam_search`: ä½¿ç”¨è´ªå©ªè§£ç 
- `--device cuda`: ä½¿ç”¨GPUåŠ é€Ÿ
- `--output results.csv`: ä¿å­˜ç»“æœåˆ°æ–‡ä»¶
