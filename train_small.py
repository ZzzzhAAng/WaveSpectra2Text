# -*- coding: utf-8 -*-
"""
ç®€åŒ–çš„è®­ç»ƒè„šæœ¬ - ä¸“é—¨å¤„ç†å°æ•°æ®é›†
é€‚ç”¨äºæ¯ä¸ªæ ‡ç­¾åªæœ‰å°‘é‡æ ·æœ¬çš„æƒ…å†µ
"""

import os
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.tensorboard import SummaryWriter
import numpy as np
from tqdm import tqdm
import json
from datetime import datetime

from model import create_model
from data_utils import get_dataloader, check_audio_files
from vocab import vocab


class SimpleTrainer:
    def __init__(self, model, dataloader, device, config):
        self.model = model
        self.dataloader = dataloader
        self.device = device
        self.config = config

        # ä¼˜åŒ–å™¨ - é’ˆå¯¹å°æ•°æ®é›†çš„è®¾ç½®
        self.optimizer = optim.Adam(
            model.parameters(),
            lr=config['learning_rate'],
            weight_decay=config['weight_decay']
        )

        # å­¦ä¹ ç‡è°ƒåº¦å™¨ - æ›´ä¿å®ˆçš„è®¾ç½®
        self.scheduler = optim.lr_scheduler.StepLR(
            self.optimizer,
            step_size=20,  # æ¯20ä¸ªepoché™ä½å­¦ä¹ ç‡
            gamma=0.8  # é™ä½åˆ°80%
        )

        # æŸå¤±å‡½æ•° - æ·»åŠ æ ‡ç­¾å¹³æ»‘
        self.criterion = nn.CrossEntropyLoss(
            ignore_index=vocab.get_padding_idx(),
            label_smoothing=0.1
        )

        # æ—¥å¿—
        self.writer = SummaryWriter(f"runs/{config['experiment_name']}")

        # è®­ç»ƒçŠ¶æ€
        self.epoch = 0
        self.best_loss = float('inf')
        self.losses = []
        self.patience_counter = 0
        self.max_patience = 15

    def train_epoch(self):
        """è®­ç»ƒä¸€ä¸ªepoch"""
        self.model.train()
        total_loss = 0
        total_correct = 0
        total_tokens = 0
        num_batches = len(self.dataloader)

        progress_bar = tqdm(self.dataloader, desc=f'Epoch {self.epoch + 1}')

        for batch_idx, batch in enumerate(progress_bar):
            # å…¼å®¹æ–°æ—§æ¥å£
            if 'features' in batch:
                spectrograms = batch['features'].to(self.device)
            else:
                spectrograms = batch['spectrograms'].to(self.device)
            labels = batch['labels'].to(self.device)

            # å‡†å¤‡è¾“å…¥å’Œç›®æ ‡
            tgt_input = labels[:, :-1]
            tgt_output = labels[:, 1:]

            # å‰å‘ä¼ æ’­
            self.optimizer.zero_grad()

            outputs = self.model(spectrograms, tgt_input)

            # è®¡ç®—æŸå¤±
            loss = self.criterion(
                outputs.reshape(-1, outputs.size(-1)),
                tgt_output.reshape(-1)
            )

            # åå‘ä¼ æ’­
            loss.backward()

            # æ¢¯åº¦è£å‰ª
            torch.nn.utils.clip_grad_norm_(self.model.parameters(), self.config['grad_clip'])

            self.optimizer.step()

            total_loss += loss.item()

            # è®¡ç®—å‡†ç¡®ç‡
            predictions = outputs.argmax(dim=-1)
            mask = (tgt_output != vocab.get_padding_idx())
            correct = (predictions == tgt_output) & mask
            total_correct += correct.sum().item()
            total_tokens += mask.sum().item()

            # æ›´æ–°è¿›åº¦æ¡
            current_acc = total_correct / total_tokens if total_tokens > 0 else 0
            progress_bar.set_postfix({
                'loss': f'{loss.item():.4f}',
                'avg_loss': f'{total_loss / (batch_idx + 1):.4f}',
                'acc': f'{current_acc:.3f}'
            })

            # è®°å½•åˆ°tensorboard
            global_step = self.epoch * num_batches + batch_idx
            self.writer.add_scalar('Train/Loss', loss.item(), global_step)

        avg_loss = total_loss / num_batches
        accuracy = total_correct / total_tokens if total_tokens > 0 else 0

        self.losses.append(avg_loss)

        return avg_loss, accuracy

    def save_checkpoint(self, filename):
        """ä¿å­˜æ£€æŸ¥ç‚¹"""
        checkpoint = {
            'epoch': self.epoch,
            'model_state_dict': self.model.state_dict(),
            'optimizer_state_dict': self.optimizer.state_dict(),
            'scheduler_state_dict': self.scheduler.state_dict(),
            'best_loss': self.best_loss,
            'losses': self.losses,
            'config': self.config
        }

        torch.save(checkpoint, filename)
        print(f"æ£€æŸ¥ç‚¹å·²ä¿å­˜: {filename}")

    def train(self, num_epochs):
        """å®Œæ•´è®­ç»ƒæµç¨‹"""
        print(f"å¼€å§‹è®­ç»ƒï¼Œå…± {num_epochs} ä¸ªepoch")
        print(f"è®¾å¤‡: {self.device}")
        print(f"æ¨¡å‹å‚æ•°æ•°é‡: {sum(p.numel() for p in self.model.parameters())}")
        print(f"æ•°æ®é›†å¤§å°: {len(self.dataloader.dataset)}")
        print(f"æ‰¹æ¬¡æ•°é‡: {len(self.dataloader)}")

        for epoch in range(num_epochs):
            self.epoch = epoch

            # è®­ç»ƒ
            train_loss, train_acc = self.train_epoch()

            # å­¦ä¹ ç‡è°ƒåº¦
            old_lr = self.optimizer.param_groups[0]['lr']
            self.scheduler.step()
            new_lr = self.optimizer.param_groups[0]['lr']

            # è®°å½•åˆ°tensorboard
            self.writer.add_scalar('Epoch/Loss', train_loss, epoch)
            self.writer.add_scalar('Epoch/Accuracy', train_acc, epoch)
            self.writer.add_scalar('Epoch/LR', new_lr, epoch)

            # æ‰“å°ç»“æœ
            print(f"Epoch {epoch + 1}/{num_epochs}:")
            print(f"  Loss: {train_loss:.4f}")
            print(f"  Accuracy: {train_acc:.4f}")
            print(f"  LR: {new_lr:.6f}")

            if new_lr != old_lr:
                print(f"  -> å­¦ä¹ ç‡ä» {old_lr:.6f} é™ä½åˆ° {new_lr:.6f}")

            # ä¿å­˜æœ€ä½³æ¨¡å‹
            if train_loss < self.best_loss:
                self.best_loss = train_loss
                self.patience_counter = 0
                self.save_checkpoint(f"checkpoints/best_model.pth")
                print("  -> æ–°çš„æœ€ä½³æ¨¡å‹!")
            else:
                self.patience_counter += 1
                if self.patience_counter >= self.max_patience:
                    print(f"  -> æ—©åœ: æŸå¤±è¿ç»­{self.max_patience}ä¸ªepochæœªæ”¹å–„")
                    break

            # å®šæœŸä¿å­˜æ£€æŸ¥ç‚¹
            if (epoch + 1) % self.config['save_every'] == 0:
                self.save_checkpoint(f"checkpoints/checkpoint_epoch_{epoch + 1}.pth")

            print("-" * 50)

        print("è®­ç»ƒå®Œæˆ!")
        self.writer.close()


def main():
    """ä¸»å‡½æ•°"""
    # é’ˆå¯¹å°æ•°æ®é›†ä¼˜åŒ–çš„é…ç½®
    config = {
        'experiment_name': f'simple_speech_recognition_{datetime.now().strftime("%Y%m%d_%H%M%S")}',
        'batch_size': 1,  # æå°æ‰¹å¤§å°
        'learning_rate': 1e-5,  # å¾ˆä½çš„å­¦ä¹ ç‡
        'weight_decay': 1e-3,  # å¼ºæ­£åˆ™åŒ–
        'grad_clip': 0.1,  # å¼ºæ¢¯åº¦è£å‰ª
        'num_epochs': 30,  # è¾ƒå°‘çš„è®­ç»ƒè½®æ•°
        'save_every': 10,
        'hidden_dim': 64,  # å¾ˆå°çš„æ¨¡å‹
        'encoder_layers': 1,  # æœ€å°‘çš„å±‚æ•°
        'decoder_layers': 1,
        'dropout': 0.5,  # å¾ˆé«˜çš„dropout
        'audio_dir': 'data/audio',
        'labels_file': 'data/labels.csv'
    }

    print("ğŸ¯ ç®€åŒ–è®­ç»ƒè„šæœ¬ - å°æ•°æ®é›†ä¸“ç”¨")
    print("é…ç½®ç‰¹ç‚¹:")
    print("  âœ… æå°æ¨¡å‹ (hidden_dim=64, 1å±‚)")
    print("  âœ… å¼ºæ­£åˆ™åŒ– (dropout=0.5, weight_decay=1e-3)")
    print("  âœ… ä½å­¦ä¹ ç‡ (1e-5)")
    print("  âœ… å°æ‰¹å¤§å° (batch_size=1)")
    print("  âœ… æ—©åœæœºåˆ¶")
    print("=" * 60)

    # æ£€æŸ¥éŸ³é¢‘æ–‡ä»¶
    if not check_audio_files(config['audio_dir'], config['labels_file']):
        print("é”™è¯¯: éŸ³é¢‘æ–‡ä»¶æ£€æŸ¥å¤±è´¥")
        return

    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"ä½¿ç”¨è®¾å¤‡: {device}")

    os.makedirs('checkpoints', exist_ok=True)
    os.makedirs('runs', exist_ok=True)

    try:
        # åˆ›å»ºæ•°æ®åŠ è½½å™¨ - ä½¿ç”¨å…¨éƒ¨æ•°æ®
        dataloader = get_dataloader(
            audio_dir=config['audio_dir'],
            labels_file=config['labels_file'],
            batch_size=config['batch_size'],
            shuffle=True
        )

    except Exception as e:
        print(f"æ•°æ®åŠ è½½å¤±è´¥: {e}")
        return

    # åˆ›å»ºå°æ¨¡å‹
    model = create_model(
        vocab_size=vocab.vocab_size,
        hidden_dim=config['hidden_dim'],
        encoder_layers=config['encoder_layers'],
        decoder_layers=config['decoder_layers'],
        dropout=config['dropout']
    ).to(device)

    print(f"æ¨¡å‹å¤§å°: {sum(p.numel() for p in model.parameters())} å‚æ•°")

    # åˆ›å»ºè®­ç»ƒå™¨
    trainer = SimpleTrainer(model, dataloader, device, config)

    # å¼€å§‹è®­ç»ƒ
    try:
        trainer.train(config['num_epochs'])
    except KeyboardInterrupt:
        print("è®­ç»ƒè¢«ä¸­æ–­")
        trainer.save_checkpoint("checkpoints/interrupted.pth")


if __name__ == "__main__":
    main()