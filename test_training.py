#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æµ‹è¯•è®­ç»ƒè„šæœ¬æ˜¯å¦èƒ½æ­£å¸¸è¿è¡Œ
"""

import torch
import json
from data_utils import get_dataloader
from model import create_model
from vocab import vocab

def test_training_loop():
    """æµ‹è¯•è®­ç»ƒå¾ªç¯"""
    print("ğŸ§ª æµ‹è¯•è®­ç»ƒå¾ªç¯...")
    
    # åŠ è½½é…ç½®
    with open('config.json', 'r') as f:
        config = json.load(f)
    
    # åˆ›å»ºæ•°æ®åŠ è½½å™¨
    dataloader = get_dataloader(
        audio_dir=config['audio_dir'],
        labels_file=config['labels_file'],
        batch_size=1,  # å°æ‰¹å¤§å°ç”¨äºæµ‹è¯•
        shuffle=True
    )
    
    # åˆ›å»ºå°æ¨¡å‹ç”¨äºæµ‹è¯•
    model = create_model(
        vocab_size=vocab.vocab_size,
        hidden_dim=64,
        encoder_layers=1,
        decoder_layers=1,
        dropout=0.1
    )
    
    # ä¼˜åŒ–å™¨å’ŒæŸå¤±å‡½æ•°
    optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)
    criterion = torch.nn.CrossEntropyLoss(ignore_index=vocab.get_padding_idx())
    
    print(f"æ•°æ®é›†å¤§å°: {len(dataloader.dataset)}")
    print(f"æ¨¡å‹å‚æ•°æ•°é‡: {sum(p.numel() for p in model.parameters())}")
    
    # æµ‹è¯•å‡ ä¸ªæ‰¹æ¬¡
    model.train()
    total_loss = 0
    
    for batch_idx, batch in enumerate(dataloader):
        if batch_idx >= 3:  # åªæµ‹è¯•3ä¸ªæ‰¹æ¬¡
            break
            
        # å…¼å®¹æ–°æ—§æ¥å£
        if 'features' in batch:
            spectrograms = batch['features']
        else:
            spectrograms = batch['spectrograms']
        labels = batch['labels']
        
        print(f"æ‰¹æ¬¡ {batch_idx + 1}:")
        print(f"  ç‰¹å¾å½¢çŠ¶: {spectrograms.shape}")
        print(f"  æ ‡ç­¾å½¢çŠ¶: {labels.shape}")
        
        # å‡†å¤‡è¾“å…¥å’Œç›®æ ‡
        tgt_input = labels[:, :-1]
        tgt_output = labels[:, 1:]
        
        # å‰å‘ä¼ æ’­
        optimizer.zero_grad()
        outputs = model(spectrograms, tgt_input)
        
        # è®¡ç®—æŸå¤±
        loss = criterion(
            outputs.reshape(-1, outputs.size(-1)),
            tgt_output.reshape(-1)
        )
        
        # åå‘ä¼ æ’­
        loss.backward()
        optimizer.step()
        
        total_loss += loss.item()
        print(f"  æŸå¤±: {loss.item():.4f}")
    
    avg_loss = total_loss / 3
    print(f"\nå¹³å‡æŸå¤±: {avg_loss:.4f}")
    print("âœ… è®­ç»ƒå¾ªç¯æµ‹è¯•æˆåŠŸ!")
    
    return True

if __name__ == "__main__":
    print("ğŸ¯ è®­ç»ƒåŠŸèƒ½æµ‹è¯•")
    print("=" * 50)
    
    try:
        test_training_loop()
        print("\nğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼ç°åœ¨å¯ä»¥å¼€å§‹æ­£å¼è®­ç»ƒäº†")
        print("\nğŸ’¡ å»ºè®®çš„è®­ç»ƒå‘½ä»¤:")
        print("python train_small.py --config config.json")
    except Exception as e:
        print(f"\nâŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()