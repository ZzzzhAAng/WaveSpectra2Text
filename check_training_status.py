#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ£€æŸ¥è®­ç»ƒçŠ¶æ€å’Œæ¨ç†é—®é¢˜
"""

import os
import glob
from pathlib import Path

def check_training_status():
    """æ£€æŸ¥è®­ç»ƒçŠ¶æ€"""
    print("ğŸ” æ£€æŸ¥è®­ç»ƒçŠ¶æ€")
    print("=" * 40)
    
    # æ£€æŸ¥checkpointsç›®å½•
    checkpoints_dir = "checkpoints"
    if os.path.exists(checkpoints_dir):
        print(f"âœ… checkpointsç›®å½•å­˜åœ¨")
        
        # åˆ—å‡ºæ‰€æœ‰æ¨¡å‹æ–‡ä»¶
        model_files = glob.glob(os.path.join(checkpoints_dir, "*.pth"))
        if model_files:
            print(f"âœ… æ‰¾åˆ° {len(model_files)} ä¸ªæ¨¡å‹æ–‡ä»¶:")
            for model_file in model_files:
                size = os.path.getsize(model_file) / (1024*1024)  # MB
                print(f"  - {model_file} ({size:.1f} MB)")
            return model_files[0]  # è¿”å›ç¬¬ä¸€ä¸ªæ¨¡å‹æ–‡ä»¶
        else:
            print("âŒ checkpointsç›®å½•å­˜åœ¨ä½†æ²¡æœ‰æ¨¡å‹æ–‡ä»¶")
    else:
        print("âŒ checkpointsç›®å½•ä¸å­˜åœ¨")
    
    # æ£€æŸ¥å…¶ä»–å¯èƒ½çš„æ¨¡å‹æ–‡ä»¶ä½ç½®
    possible_locations = [
        "*.pth",
        "models/*.pth", 
        "saved_models/*.pth",
        "outputs/*.pth"
    ]
    
    print("\nğŸ” æœç´¢å…¶ä»–ä½ç½®çš„æ¨¡å‹æ–‡ä»¶...")
    for pattern in possible_locations:
        files = glob.glob(pattern)
        if files:
            print(f"âœ… åœ¨ {pattern} æ‰¾åˆ°æ¨¡å‹æ–‡ä»¶:")
            for file in files:
                print(f"  - {file}")
            return files[0]
    
    print("âŒ æ²¡æœ‰æ‰¾åˆ°ä»»ä½•æ¨¡å‹æ–‡ä»¶")
    return None

def check_training_logs():
    """æ£€æŸ¥è®­ç»ƒæ—¥å¿—"""
    print("\nğŸ” æ£€æŸ¥è®­ç»ƒæ—¥å¿—")
    print("-" * 30)
    
    # æ£€æŸ¥TensorBoardæ—¥å¿—
    runs_dir = "runs"
    if os.path.exists(runs_dir):
        print(f"âœ… TensorBoardæ—¥å¿—ç›®å½•å­˜åœ¨: {runs_dir}")
        subdirs = [d for d in os.listdir(runs_dir) if os.path.isdir(os.path.join(runs_dir, d))]
        if subdirs:
            print(f"  å®éªŒç›®å½•: {subdirs}")
            latest_dir = max(subdirs, key=lambda x: os.path.getctime(os.path.join(runs_dir, x)))
            print(f"  æœ€æ–°å®éªŒ: {latest_dir}")
        else:
            print("  æ²¡æœ‰å®éªŒæ—¥å¿—")
    else:
        print("âŒ æ²¡æœ‰TensorBoardæ—¥å¿—")

def analyze_inference_issue():
    """åˆ†ææ¨ç†é—®é¢˜"""
    print("\nğŸ” åˆ†ææ¨ç†ç©ºç»“æœé—®é¢˜")
    print("-" * 30)
    
    print("æ ¹æ®æ‚¨çš„è¾“å‡ºï¼Œæ¨ç†ç³»ç»Ÿå·¥ä½œæ­£å¸¸ä½†ç»“æœä¸ºç©ºï¼Œå¯èƒ½åŸå› :")
    print("1. ğŸ¯ æ¨¡å‹è®­ç»ƒä¸å……åˆ† (28 epochå¯èƒ½ä¸å¤Ÿ)")
    print("2. ğŸ¯ æ¨¡å‹è¿˜åœ¨å­¦ä¹ é˜¶æ®µï¼Œæ²¡æœ‰å­¦ä¼šæ­£ç¡®çš„æ˜ å°„")
    print("3. ğŸ¯ è§£ç æ—¶ç«‹å³é‡åˆ°EOS token")
    print("4. ğŸ¯ æ¨¡å‹è¾“å‡ºçš„éƒ½æ˜¯ç‰¹æ®Štoken (PAD, UNKç­‰)")

def provide_solutions():
    """æä¾›è§£å†³æ–¹æ¡ˆ"""
    print("\nğŸ’¡ è§£å†³æ–¹æ¡ˆ")
    print("=" * 40)
    
    solutions = [
        {
            "title": "1. æ£€æŸ¥è®­ç»ƒæ˜¯å¦è¿˜åœ¨è¿›è¡Œ",
            "commands": [
                "ps aux | grep python",  # æ£€æŸ¥æ˜¯å¦æœ‰è®­ç»ƒè¿›ç¨‹
                "top | grep python"      # æ£€æŸ¥CPUä½¿ç”¨æƒ…å†µ
            ]
        },
        {
            "title": "2. ç»§ç»­è®­ç»ƒæ›´å¤šepoch",
            "commands": [
                "python train_small.py --config config_small_data.json"
            ]
        },
        {
            "title": "3. ä½¿ç”¨æ›´å°çš„æ¨¡å‹å’Œæ›´å¤šepoch",
            "description": "ä¿®æ”¹config_small_data.jsonï¼Œè®¾ç½®æ›´å¤šepoch"
        },
        {
            "title": "4. æ£€æŸ¥è®­ç»ƒæŸå¤±",
            "commands": [
                "tensorboard --logdir=runs",
                "# ç„¶ååœ¨æµè§ˆå™¨æ‰“å¼€ http://localhost:6006"
            ]
        },
        {
            "title": "5. åˆ›å»ºæµ‹è¯•æ¨¡å‹éªŒè¯æ¨ç†é€»è¾‘",
            "description": "ä½¿ç”¨æˆ‘ä»¬ä¹‹å‰çš„è™šæ‹Ÿæ¨¡å‹æµ‹è¯•"
        }
    ]
    
    for i, solution in enumerate(solutions):
        print(f"\n{solution['title']}:")
        if 'commands' in solution:
            for cmd in solution['commands']:
                print(f"  {cmd}")
        if 'description' in solution:
            print(f"  {solution['description']}")

def create_quick_test_model():
    """åˆ›å»ºä¸€ä¸ªå¿«é€Ÿæµ‹è¯•æ¨¡å‹"""
    print("\nğŸš€ åˆ›å»ºå¿«é€Ÿæµ‹è¯•æ¨¡å‹")
    print("-" * 30)
    
    try:
        import torch
        from model import create_model
        from vocab import vocab
        
        print("åˆ›å»ºä¸€ä¸ªç®€å•çš„æµ‹è¯•æ¨¡å‹...")
        
        # åˆ›å»ºè¶…å°æ¨¡å‹
        model = create_model(
            vocab_size=vocab.vocab_size,
            hidden_dim=32,
            encoder_layers=1,
            decoder_layers=1,
            dropout=0.0
        )
        
        # æ‰‹åŠ¨è®¾ç½®ä¸€äº›æƒé‡ï¼Œè®©æ¨¡å‹è¾“å‡ºæœ‰æ„ä¹‰çš„ç»“æœ
        with torch.no_grad():
            # è®¾ç½®è¾“å‡ºå±‚åç½®ï¼Œè®©æŸäº›tokenæ›´å®¹æ˜“è¢«é€‰ä¸­
            if hasattr(model.decoder, 'output_projection'):
                # ç»™ä¸­æ–‡æ•°å­—tokenæ›´é«˜çš„åç½®
                bias = model.decoder.output_projection.bias
                for word, idx in vocab.word_to_idx.items():
                    if word in ['ä¸€', 'äºŒ', 'ä¸‰', 'å››', 'äº”']:
                        bias[idx] = 2.0  # å¢åŠ è¿™äº›tokençš„æ¦‚ç‡
        
        # ä¿å­˜æµ‹è¯•æ¨¡å‹
        os.makedirs('checkpoints', exist_ok=True)
        checkpoint = {
            'epoch': 1,
            'model_state_dict': model.state_dict(),
            'best_val_loss': 1.0,
            'config': {
                'hidden_dim': 32,
                'encoder_layers': 1,
                'decoder_layers': 1,
                'dropout': 0.0
            }
        }
        
        test_model_path = 'checkpoints/test_model.pth'
        torch.save(checkpoint, test_model_path)
        
        print(f"âœ… æµ‹è¯•æ¨¡å‹å·²ä¿å­˜: {test_model_path}")
        print("ç°åœ¨å¯ä»¥æµ‹è¯•æ¨ç†:")
        print(f"  python inference.py --model {test_model_path} --audio data/audio/Chinese_Number_01.wav")
        
        return test_model_path
        
    except Exception as e:
        print(f"âŒ åˆ›å»ºæµ‹è¯•æ¨¡å‹å¤±è´¥: {e}")
        return None

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ¯ è®­ç»ƒçŠ¶æ€å’Œæ¨ç†é—®é¢˜æ£€æŸ¥")
    print("=" * 50)
    
    # æ£€æŸ¥è®­ç»ƒçŠ¶æ€
    model_file = check_training_status()
    
    # æ£€æŸ¥è®­ç»ƒæ—¥å¿—
    check_training_logs()
    
    # åˆ†ææ¨ç†é—®é¢˜
    analyze_inference_issue()
    
    # æä¾›è§£å†³æ–¹æ¡ˆ
    provide_solutions()
    
    # å¦‚æœæ²¡æœ‰æ¨¡å‹æ–‡ä»¶ï¼Œåˆ›å»ºæµ‹è¯•æ¨¡å‹
    if not model_file:
        print("\n" + "=" * 50)
        test_model = create_quick_test_model()
        if test_model:
            print(f"\nğŸ¯ ç«‹å³æµ‹è¯•æ¨ç†:")
            print(f"python inference.py --model {test_model} --audio data/audio/Chinese_Number_01.wav")
    
    print("\nğŸ‰ æ€»ç»“:")
    if model_file:
        print("âœ… æ‰¾åˆ°äº†è®­ç»ƒçš„æ¨¡å‹ï¼Œæ¨ç†ç©ºç»“æœå¯èƒ½æ˜¯è®­ç»ƒä¸å……åˆ†")
        print("ğŸ’¡ å»ºè®®: ç»§ç»­è®­ç»ƒæˆ–æ£€æŸ¥è®­ç»ƒæŸå¤±")
    else:
        print("âŒ æ²¡æœ‰æ‰¾åˆ°è®­ç»ƒçš„æ¨¡å‹æ–‡ä»¶")
        print("ğŸ’¡ å»ºè®®: æ£€æŸ¥è®­ç»ƒæ˜¯å¦åœ¨è¿›è¡Œï¼Œæˆ–é‡æ–°å¼€å§‹è®­ç»ƒ")

if __name__ == "__main__":
    main()