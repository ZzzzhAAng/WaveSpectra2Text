#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
åŸºæœ¬ä½¿ç”¨ç¤ºä¾‹
å±•ç¤ºWaveSpectra2Textçš„åŸºæœ¬åŠŸèƒ½
"""

import sys
import os
from pathlib import Path

# æ·»åŠ srcç›®å½•åˆ°Pythonè·¯å¾„
sys.path.insert(0, str(Path(__file__).parent.parent / 'src'))

from wavespectra2text import (
    create_model, vocab, DualInputSpeechRecognizer,
    AudioPreprocessor, PreprocessorFactory, AudioDataset
)


def basic_usage_example():
    """åŸºæœ¬ä½¿ç”¨ç¤ºä¾‹"""
    print("ğŸ¯ WaveSpectra2Text åŸºæœ¬ä½¿ç”¨ç¤ºä¾‹")
    print("=" * 50)
    
    # 1. åˆ›å»ºæ¨¡å‹
    print("1. åˆ›å»ºæ¨¡å‹...")
    model = create_model(
        vocab_size=vocab.vocab_size,
        hidden_dim=128,
        encoder_layers=2,
        decoder_layers=2,
        dropout=0.1
    )
    print(f"âœ… æ¨¡å‹åˆ›å»ºæˆåŠŸï¼Œå‚æ•°æ•°é‡: {sum(p.numel() for p in model.parameters())}")
    
    # 2. åˆ›å»ºéŸ³é¢‘é¢„å¤„ç†å™¨
    print("\n2. åˆ›å»ºéŸ³é¢‘é¢„å¤„ç†å™¨...")
    preprocessor = PreprocessorFactory.create('spectrogram')
    print(f"âœ… é¢„å¤„ç†å™¨åˆ›å»ºæˆåŠŸï¼Œç‰¹å¾å½¢çŠ¶: {preprocessor.get_feature_shape()}")
    
    # 3. åˆ›å»ºæ•°æ®é›†
    print("\n3. åˆ›å»ºæ•°æ®é›†...")
    try:
        dataset = AudioDataset(
            labels_file='data/labels.csv',
            audio_dir='data/audio',
            mode='realtime'
        )
        print(f"âœ… æ•°æ®é›†åˆ›å»ºæˆåŠŸï¼Œæ ·æœ¬æ•°é‡: {len(dataset)}")
    except Exception as e:
        print(f"âš ï¸  æ•°æ®é›†åˆ›å»ºå¤±è´¥: {e}")
        print("   è¯·ç¡®ä¿data/labels.csvå’Œdata/audioç›®å½•å­˜åœ¨")
    
    # 4. åˆ›å»ºè¯†åˆ«å™¨ï¼ˆéœ€è¦æ¨¡å‹æ–‡ä»¶ï¼‰
    print("\n4. åˆ›å»ºè¯†åˆ«å™¨...")
    model_path = 'experiments/checkpoints/best_model.pth'
    if os.path.exists(model_path):
        try:
            recognizer = DualInputSpeechRecognizer(model_path)
            print("âœ… è¯†åˆ«å™¨åˆ›å»ºæˆåŠŸ")
            
            # æµ‹è¯•è¯†åˆ«
            audio_file = 'data/audio/Chinese_Number_01.wav'
            if os.path.exists(audio_file):
                result = recognizer.recognize_from_audio(audio_file)
                if result['success']:
                    print(f"ğŸ¯ è¯†åˆ«ç»“æœ: '{result['text']}'")
                else:
                    print(f"âŒ è¯†åˆ«å¤±è´¥: {result['error']}")
            else:
                print("âš ï¸  éŸ³é¢‘æ–‡ä»¶ä¸å­˜åœ¨ï¼Œè·³è¿‡è¯†åˆ«æµ‹è¯•")
                
        except Exception as e:
            print(f"âŒ è¯†åˆ«å™¨åˆ›å»ºå¤±è´¥: {e}")
    else:
        print(f"âš ï¸  æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {model_path}")
        print("   è¯·å…ˆè®­ç»ƒæ¨¡å‹")
    
    print("\nâœ… åŸºæœ¬ä½¿ç”¨ç¤ºä¾‹å®Œæˆ!")


def advanced_usage_example():
    """é«˜çº§ä½¿ç”¨ç¤ºä¾‹"""
    print("\nğŸš€ WaveSpectra2Text é«˜çº§ä½¿ç”¨ç¤ºä¾‹")
    print("=" * 50)
    
    # 1. è‡ªå®šä¹‰é¢„å¤„ç†å™¨
    print("1. è‡ªå®šä¹‰é¢„å¤„ç†å™¨...")
    custom_preprocessor = PreprocessorFactory.create(
        'spectrogram',
        sample_rate=48000,
        n_fft=2048,  # æ›´å¤§çš„FFTçª—å£
        hop_length=1024,
        max_length=300  # æ›´é•¿çš„åºåˆ—
    )
    print(f"âœ… è‡ªå®šä¹‰é¢„å¤„ç†å™¨åˆ›å»ºæˆåŠŸ")
    print(f"   ç‰¹å¾å½¢çŠ¶: {custom_preprocessor.get_feature_shape()}")
    
    # 2. æ‰¹é‡å¤„ç†ç¤ºä¾‹
    print("\n2. æ‰¹é‡å¤„ç†ç¤ºä¾‹...")
    audio_files = [
        'data/audio/Chinese_Number_01.wav',
        'data/audio/Chinese_Number_02.wav',
        'data/audio/Chinese_Number_03.wav'
    ]
    
    results = []
    for audio_file in audio_files:
        if os.path.exists(audio_file):
            try:
                # é¢„å¤„ç†éŸ³é¢‘
                features = custom_preprocessor.process(audio_file)
                print(f"âœ… å¤„ç†å®Œæˆ: {audio_file}, ç‰¹å¾å½¢çŠ¶: {features.shape}")
                results.append(features)
            except Exception as e:
                print(f"âŒ å¤„ç†å¤±è´¥: {audio_file}, é”™è¯¯: {e}")
    
    print(f"ğŸ“Š æ‰¹é‡å¤„ç†å®Œæˆï¼ŒæˆåŠŸå¤„ç† {len(results)} ä¸ªæ–‡ä»¶")
    
    # 3. é…ç½®ç®¡ç†ç¤ºä¾‹
    print("\n3. é…ç½®ç®¡ç†ç¤ºä¾‹...")
    from wavespectra2text.training.config import ConfigManager, get_default_config
    
    # ä½¿ç”¨é»˜è®¤é…ç½®
    config = get_default_config('medium')
    print(f"âœ… é»˜è®¤é…ç½®åŠ è½½æˆåŠŸ")
    print(f"   æ‰¹å¤§å°: {config['batch_size']}")
    print(f"   å­¦ä¹ ç‡: {config['learning_rate']}")
    print(f"   éšè—å±‚ç»´åº¦: {config['hidden_dim']}")
    
    # æ›´æ–°é…ç½®
    config_manager = ConfigManager()
    config_manager.update_config({'batch_size': 8, 'learning_rate': 0.002})
    print(f"âœ… é…ç½®æ›´æ–°æˆåŠŸ")
    print(f"   æ–°æ‰¹å¤§å°: {config_manager['batch_size']}")
    print(f"   æ–°å­¦ä¹ ç‡: {config_manager['learning_rate']}")
    
    print("\nâœ… é«˜çº§ä½¿ç”¨ç¤ºä¾‹å®Œæˆ!")


if __name__ == "__main__":
    basic_usage_example()
    advanced_usage_example()
    
    print("\n" + "=" * 60)
    print("ğŸ“š æ›´å¤šç¤ºä¾‹:")
    print("  - examples/custom_training.py: è‡ªå®šä¹‰è®­ç»ƒç¤ºä¾‹")
    print("  - examples/batch_inference.py: æ‰¹é‡æ¨ç†ç¤ºä¾‹")
    print("  - scripts/train.py: è®­ç»ƒè„šæœ¬")
    print("  - scripts/inference.py: æ¨ç†è„šæœ¬")
    print("\nğŸ’¡ æç¤º:")
    print("  - ç¡®ä¿å·²å®‰è£…æ‰€æœ‰ä¾èµ–: pip install -r requirements.txt")
    print("  - å‡†å¤‡æ•°æ®: python setup_data.py")
    print("  - å¼€å§‹è®­ç»ƒ: python scripts/train.py --scale small")
