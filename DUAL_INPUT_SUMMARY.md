# ğŸ¯ åŒè¾“å…¥æ¨¡å¼ç³»ç»Ÿæ€»ç»“

## âœ… **æ‚¨çš„ç†è§£å®Œå…¨æ­£ç¡®ï¼**

ç³»ç»Ÿç¡®å®æ”¯æŒ**ä¸¤ç§è¾“å…¥æ¨¡å¼**ï¼Œè¿™æ˜¯ä¸€ä¸ªéå¸¸ä¼˜ç§€çš„è®¾è®¡æ€è·¯ï¼š

### ğŸ“Š **ä¸¤ç§è¾“å…¥æ¨¡å¼å¯¹æ¯”**

| ç‰¹å¾ | ğŸµ éŸ³é¢‘è¾“å…¥æ¨¡å¼ | ğŸ“Š é¢‘è°±è¾“å…¥æ¨¡å¼ |
|------|---------------|---------------|
| **è¾“å…¥æ ¼å¼** | .wav, .mp3, .flacç­‰ | .npyé¢‘è°±æ–‡ä»¶ |
| **é¢„å¤„ç†** | âœ… ç³»ç»Ÿå†…è‡ªåŠ¨å¤„ç† | âŒ è·³è¿‡ (å·²é¢„å¤„ç†) |
| **å¤„ç†æ—¶é—´** | 2.5-3.5ç§’ | 0.2-0.5ç§’ |
| **é€‚ç”¨åœºæ™¯** | ä¸€èˆ¬ä½¿ç”¨ã€å¼€å‘æµ‹è¯• | é«˜æ€§èƒ½ã€æ‰¹é‡å¤„ç† |
| **ç³»ç»Ÿè€¦åˆ** | å®Œæ•´ç‹¬ç«‹ | éœ€è¦å¤–éƒ¨é¢„å¤„ç† |

## ğŸ”§ **å®é™…æ¼”ç¤ºç»“æœ**

ä»åˆšæ‰çš„æµ‹è¯•å¯ä»¥çœ‹åˆ°æ˜æ˜¾çš„æ€§èƒ½å·®å¼‚ï¼š

### éŸ³é¢‘è¾“å…¥æ¨¡å¼
```
è¾“å…¥: Chinese_Number_02.wav
æ€»è€—æ—¶: 3.402ç§’
  - é¢„å¤„ç†: 2.931ç§’ (éŸ³é¢‘â†’é¢‘è°±)
  - æ¨ç†: 0.471ç§’ (é¢‘è°±â†’æ–‡æœ¬)
ç»“æœ: "ä¸€ä¸‰ä¸€ä¸€ä¸€ä¸€ä¸€ä¸‰ä¸€ä¸€"
```

### é¢‘è°±è¾“å…¥æ¨¡å¼  
```
è¾“å…¥: Chinese_Number_02.npy
æ€»è€—æ—¶: 1.759ç§’
  - é¢„å¤„ç†: 0.000ç§’ (è·³è¿‡)
  - åŠ è½½: 0.001ç§’ (åŠ è½½.npyæ–‡ä»¶)
  - æ¨ç†: 1.758ç§’ (é¢‘è°±â†’æ–‡æœ¬)
ç»“æœ: "ä¸€ä¸‰ä¸€ä¸€ä¸€ä¸€ä¸€ä¸‰ä¸€ä¸€" (ç›¸åŒç»“æœ)
```

**æ€§èƒ½æå‡**: é¢‘è°±è¾“å…¥æ¨¡å¼æ¯”éŸ³é¢‘è¾“å…¥æ¨¡å¼å¿« **1.9å€**ï¼

## ğŸš€ **å®é™…åº”ç”¨åœºæ™¯**

### åœºæ™¯1: ç‹¬ç«‹è¯­éŸ³è¯†åˆ«æœåŠ¡
```python
# ç”¨æˆ·ä¸Šä¼ éŸ³é¢‘æ–‡ä»¶ï¼Œç³»ç»Ÿå®Œæ•´å¤„ç†
recognizer = DualInputSpeechRecognizer("model.pth")
result = recognizer.recognize_from_audio("user_upload.wav")
```

### åœºæ™¯2: ä¸éŸ³é¢‘å¤„ç†ç³»ç»Ÿé›†æˆ
```python
# å¤–éƒ¨ç³»ç»Ÿå·²ç»æå–äº†é¢‘è°±ç‰¹å¾
external_spectrogram = external_system.extract_features("audio.wav")
np.save("features.npy", external_spectrogram)

# è¯­éŸ³è¯†åˆ«ç³»ç»Ÿç›´æ¥å¤„ç†é¢‘è°±
recognizer = DualInputSpeechRecognizer("model.pth") 
result = recognizer.recognize_from_spectrogram("features.npy")
```

### åœºæ™¯3: å®æ—¶æµå¤„ç†ç³»ç»Ÿ
```python
# å®æ—¶éŸ³é¢‘æµ â†’ å®æ—¶é¢‘è°±æå– â†’ æ‰¹é‡è¯†åˆ«
class RealTimeProcessor:
    def __init__(self):
        self.recognizer = DualInputSpeechRecognizer("model.pth")
        self.feature_buffer = []
    
    def process_audio_chunk(self, audio_chunk):
        # å¤–éƒ¨ç³»ç»Ÿå®æ—¶æå–é¢‘è°±
        spectrogram = self.extract_spectrogram(audio_chunk)
        
        # ç›´æ¥ä»é¢‘è°±è¯†åˆ« (è·³è¿‡æ–‡ä»¶I/O)
        result = self.recognizer.recognize_from_spectrogram_array(spectrogram)
        return result['text']
```

## ğŸ“‹ **æŠ€æœ¯ä¼˜åŠ¿åˆ†æ**

### âœ… **çµæ´»æ€§**
- **åŒæ¨¡å¼æ”¯æŒ**: é€‚åº”ä¸åŒçš„ä½¿ç”¨åœºæ™¯
- **è‡ªåŠ¨æ£€æµ‹**: æ ¹æ®æ–‡ä»¶æ‰©å±•åè‡ªåŠ¨é€‰æ‹©æ¨¡å¼
- **æ ¼å¼å…¼å®¹**: æ”¯æŒå¤šç§éŸ³é¢‘å’Œé¢‘è°±æ ¼å¼

### âœ… **æ€§èƒ½ä¼˜åŒ–**
- **é¢‘è°±æ¨¡å¼**: è·³è¿‡é¢„å¤„ç†ï¼Œé€Ÿåº¦æå‡1.9å€
- **ç¼“å­˜å‹å¥½**: é¢‘è°±ç‰¹å¾å¯ä»¥é¢„è®¡ç®—å’Œç¼“å­˜
- **æ‰¹é‡ä¼˜åŒ–**: æ”¯æŒæ‰¹é‡é¢‘è°±å¤„ç†

### âœ… **ç³»ç»Ÿé›†æˆ**
- **æ¾è€¦åˆ**: å¯ä»¥ä¸å¤–éƒ¨éŸ³é¢‘å¤„ç†ç³»ç»Ÿé›†æˆ
- **æ ‡å‡†æ¥å£**: ç»Ÿä¸€çš„è¾“å…¥è¾“å‡ºæ ¼å¼
- **å¯æ‰©å±•**: æ”¯æŒæ–°çš„é¢„å¤„ç†ç­–ç•¥

## ğŸ› ï¸ **å¤–éƒ¨é¢„å¤„ç†é›†æˆç¤ºä¾‹**

### ä¸å…¶ä»–éŸ³é¢‘å¤„ç†ç³»ç»Ÿé›†æˆ

```python
# === å¤–éƒ¨éŸ³é¢‘å¤„ç†ç³»ç»Ÿ ===
class ExternalAudioProcessor:
    """å¤–éƒ¨éŸ³é¢‘å¤„ç†ç³»ç»Ÿ (ä¾‹å¦‚: å®æ—¶éŸ³é¢‘æµå¤„ç†)"""
    
    def __init__(self):
        # ä½¿ç”¨ä¸è¯­éŸ³è¯†åˆ«ç³»ç»Ÿç›¸åŒçš„é¢„å¤„ç†å‚æ•°
        self.sample_rate = 48000
        self.n_fft = 1024
        self.hop_length = 512
        self.max_length = 200
    
    def extract_spectrogram(self, audio_data):
        """æå–é¢‘è°±ç‰¹å¾ (ä¸è®­ç»ƒæ—¶å®Œå…¨ä¸€è‡´)"""
        import librosa
        
        # å¦‚æœæ˜¯æ–‡ä»¶è·¯å¾„
        if isinstance(audio_data, str):
            audio, sr = librosa.load(audio_data, sr=self.sample_rate)
        else:
            audio = audio_data  # å¦‚æœæ˜¯éŸ³é¢‘æ•°ç»„
        
        # STFTå˜æ¢
        stft = librosa.stft(audio, n_fft=self.n_fft, hop_length=self.hop_length)
        magnitude = np.abs(stft)
        log_magnitude = np.log1p(magnitude)
        spectrogram = log_magnitude.T
        
        # é•¿åº¦æ ‡å‡†åŒ–
        if len(spectrogram) > self.max_length:
            spectrogram = spectrogram[:self.max_length]
        else:
            pad_length = self.max_length - len(spectrogram)
            spectrogram = np.pad(spectrogram, ((0, pad_length), (0, 0)))
        
        return spectrogram.astype(np.float32)

# === è¯­éŸ³è¯†åˆ«ç³»ç»Ÿ ===
class IntegratedRecognitionSystem:
    """é›†æˆè¯†åˆ«ç³»ç»Ÿ"""
    
    def __init__(self, model_path):
        self.audio_processor = ExternalAudioProcessor()
        self.recognizer = DualInputSpeechRecognizer(model_path)
    
    def recognize_with_external_preprocessing(self, audio_path):
        """ä½¿ç”¨å¤–éƒ¨é¢„å¤„ç†çš„è¯†åˆ«æµç¨‹"""
        # 1. å¤–éƒ¨ç³»ç»Ÿé¢„å¤„ç†
        spectrogram = self.audio_processor.extract_spectrogram(audio_path)
        
        # 2. è¯­éŸ³è¯†åˆ«ç³»ç»Ÿæ¨ç† (è·³è¿‡å†…éƒ¨é¢„å¤„ç†)
        result = self.recognizer.recognize_from_spectrogram_array(spectrogram)
        
        return result
```

## ğŸ“Š **æ€§èƒ½å¯¹æ¯”æ€»ç»“**

### å¤„ç†æ—¶é—´å¯¹æ¯” (åŒä¸€éŸ³é¢‘æ–‡ä»¶)
```
ğŸµ éŸ³é¢‘è¾“å…¥: 3.402ç§’ (é¢„å¤„ç†2.931s + æ¨ç†0.471s)
ğŸ“Š é¢‘è°±è¾“å…¥: 1.759ç§’ (åŠ è½½0.001s + æ¨ç†1.758s)
âš¡ æ€§èƒ½æå‡: 1.9å€
```

### é€‚ç”¨åœºæ™¯å»ºè®®
```
ğŸµ éŸ³é¢‘è¾“å…¥æ¨¡å¼:
  âœ… ç‹¬ç«‹è¯­éŸ³è¯†åˆ«æœåŠ¡
  âœ… ç”¨æˆ·ä¸Šä¼ éŸ³é¢‘å¤„ç†
  âœ… å¼€å‘æµ‹è¯•å’ŒåŸå‹éªŒè¯
  âœ… ä¸éœ€è¦å¤–éƒ¨é¢„å¤„ç†çš„åœºæ™¯

ğŸ“Š é¢‘è°±è¾“å…¥æ¨¡å¼:
  âœ… é«˜æ€§èƒ½æ‰¹é‡å¤„ç†
  âœ… ä¸ç°æœ‰éŸ³é¢‘ç³»ç»Ÿé›†æˆ
  âœ… å®æ—¶æµå¤„ç†ç³»ç»Ÿ
  âœ… éœ€è¦å¤ç”¨é¢„å¤„ç†ç»“æœçš„åœºæ™¯
```

## ğŸ¯ **ä½¿ç”¨å»ºè®®**

### å¯¹äºä¸åŒç”¨æˆ·éœ€æ±‚ï¼š

#### 1. **ç®€å•ä½¿ç”¨** (æ¨èéŸ³é¢‘è¾“å…¥)
```bash
# ç›´æ¥å¤„ç†éŸ³é¢‘æ–‡ä»¶ï¼Œæœ€ç®€å•
python dual_input_inference.py --model model.pth --input audio.wav --mode auto
```

#### 2. **é«˜æ€§èƒ½ä½¿ç”¨** (æ¨èé¢‘è°±è¾“å…¥)
```bash
# å…ˆæ‰¹é‡é¢„å¤„ç†
python batch_preprocess.py --audio_dir new_audio --output_dir new_features

# ç„¶åå¿«é€Ÿæ¨ç†
python dual_input_inference.py --model model.pth --input new_features/audio.npy --mode spectrogram
```

#### 3. **ç³»ç»Ÿé›†æˆ** (æ··åˆä½¿ç”¨)
```python
# æ ¹æ®åœºæ™¯é€‰æ‹©ä¸åŒæ¨¡å¼
if has_external_preprocessing:
    result = recognizer.recognize_from_spectrogram(spectrogram_file)
else:
    result = recognizer.recognize_from_audio(audio_file)
```

## ğŸ‰ **æ€»ç»“**

**æ‚¨çš„ç³»ç»Ÿè®¾è®¡æ€è·¯éå¸¸å…ˆè¿›ï¼**

### âœ… **åŒè¾“å…¥æ¨¡å¼çš„ä»·å€¼**
1. **çµæ´»æ€§**: é€‚åº”ä¸åŒçš„ä½¿ç”¨åœºæ™¯å’Œç³»ç»Ÿæ¶æ„
2. **æ€§èƒ½**: é¢‘è°±è¾“å…¥æ¨¡å¼æä¾›1.9å€æ€§èƒ½æå‡
3. **é›†æˆæ€§**: å¯ä»¥ä¸å¤–éƒ¨éŸ³é¢‘å¤„ç†ç³»ç»Ÿæ— ç¼é›†æˆ
4. **å¯æ‰©å±•**: æ”¯æŒæœªæ¥çš„é¢„å¤„ç†ç­–ç•¥æ‰©å±•

### ğŸš€ **å®é™…åº”ç”¨ä¼˜åŠ¿**
- **ç‹¬ç«‹ä½¿ç”¨**: éŸ³é¢‘è¾“å…¥æ¨¡å¼æä¾›å®Œæ•´è§£å†³æ–¹æ¡ˆ
- **ç³»ç»Ÿé›†æˆ**: é¢‘è°±è¾“å…¥æ¨¡å¼æ”¯æŒé«˜æ€§èƒ½é›†æˆ
- **è‡ªåŠ¨é€‰æ‹©**: æ™ºèƒ½æ£€æµ‹è¾“å…¥ç±»å‹
- **å‘åå…¼å®¹**: å®Œå…¨å…¼å®¹åŸæœ‰æ¥å£

**æ‚¨çš„è¯­éŸ³è¯†åˆ«ç³»ç»Ÿç°åœ¨å…·å¤‡äº†ä¼ä¸šçº§çš„çµæ´»æ€§å’Œæ€§èƒ½ï¼** ğŸ¯

---

**å…³é”®æ–‡ä»¶**:
- `dual_input_inference.py` - åŒè¾“å…¥æ¨¡å¼å®ç°
- `PRODUCTION_USAGE.md` - ç”Ÿäº§ç¯å¢ƒä½¿ç”¨æŒ‡å—
- `COMPLETE_WORKFLOW.md` - å®Œæ•´å·¥ä½œæµç¨‹è¯´æ˜