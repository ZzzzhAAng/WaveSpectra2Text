#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ç®€å•çš„éŸ³é¢‘æ•°æ®å¢å¼º
é€šè¿‡æ·»åŠ å™ªå£°ã€æ—¶é—´æ‹‰ä¼¸ç­‰æ–¹å¼æ‰©å……æ•°æ®é›†
"""

import os
import numpy as np
import librosa
import pandas as pd
from pathlib import Path
import soundfile as sf

def add_noise(audio, noise_factor=0.005):
    """æ·»åŠ é«˜æ–¯å™ªå£°"""
    noise = np.random.randn(len(audio))
    return audio + noise_factor * noise

def time_stretch(audio, rate=1.1):
    """æ—¶é—´æ‹‰ä¼¸"""
    return librosa.effects.time_stretch(audio, rate=rate)

def pitch_shift(audio, sr, n_steps=2):
    """éŸ³è°ƒå˜åŒ–"""
    return librosa.effects.pitch_shift(audio, sr=sr, n_steps=n_steps)

def augment_audio_file(input_path, output_dir, base_name, sr=48000):
    """å¯¹å•ä¸ªéŸ³é¢‘æ–‡ä»¶è¿›è¡Œå¢å¼º"""
    # åŠ è½½éŸ³é¢‘
    audio, _ = librosa.load(input_path, sr=sr)
    
    augmented_files = []
    
    # åŸå§‹æ–‡ä»¶
    original_path = os.path.join(output_dir, f"{base_name}_original.wav")
    sf.write(original_path, audio, sr)
    augmented_files.append((f"{base_name}_original.wav", "original"))
    
    # æ·»åŠ å™ªå£° (3ä¸ªå˜ä½“)
    for i, noise_level in enumerate([0.003, 0.005, 0.008]):
        noisy_audio = add_noise(audio, noise_level)
        noisy_path = os.path.join(output_dir, f"{base_name}_noise_{i+1}.wav")
        sf.write(noisy_path, noisy_audio, sr)
        augmented_files.append((f"{base_name}_noise_{i+1}.wav", f"noise_{noise_level}"))
    
    # æ—¶é—´æ‹‰ä¼¸ (2ä¸ªå˜ä½“)
    for i, rate in enumerate([0.9, 1.1]):
        stretched_audio = time_stretch(audio, rate)
        stretched_path = os.path.join(output_dir, f"{base_name}_stretch_{i+1}.wav")
        sf.write(stretched_path, stretched_audio, sr)
        augmented_files.append((f"{base_name}_stretch_{i+1}.wav", f"stretch_{rate}"))
    
    # éŸ³è°ƒå˜åŒ– (2ä¸ªå˜ä½“)
    for i, n_steps in enumerate([-1, 1]):
        pitched_audio = pitch_shift(audio, sr, n_steps)
        pitched_path = os.path.join(output_dir, f"{base_name}_pitch_{i+1}.wav")
        sf.write(pitched_path, pitched_audio, sr)
        augmented_files.append((f"{base_name}_pitch_{i+1}.wav", f"pitch_{n_steps}"))
    
    return augmented_files

def create_augmented_dataset(input_dir, labels_file, output_dir):
    """åˆ›å»ºå¢å¼ºæ•°æ®é›†"""
    print("ğŸµ å¼€å§‹æ•°æ®å¢å¼º...")
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    os.makedirs(output_dir, exist_ok=True)
    
    # è¯»å–åŸå§‹æ ‡ç­¾
    df = pd.read_csv(labels_file)
    
    augmented_data = []
    
    for idx, row in df.iterrows():
        filename = row['filename']
        label = row['label']
        
        input_path = os.path.join(input_dir, filename)
        if not os.path.exists(input_path):
            print(f"âš ï¸ æ–‡ä»¶ä¸å­˜åœ¨: {filename}")
            continue
        
        print(f"ğŸ¯ å¤„ç†: {filename} (æ ‡ç­¾: {label})")
        
        base_name = Path(filename).stem
        
        try:
            # ç”Ÿæˆå¢å¼ºç‰ˆæœ¬
            augmented_files = augment_audio_file(input_path, output_dir, base_name)
            
            # æ·»åŠ åˆ°æ•°æ®åˆ—è¡¨
            for aug_filename, aug_type in augmented_files:
                augmented_data.append({
                    'filename': aug_filename,
                    'label': label,
                    'original_file': filename,
                    'augmentation_type': aug_type
                })
            
            print(f"  âœ… ç”Ÿæˆ {len(augmented_files)} ä¸ªå¢å¼ºç‰ˆæœ¬")
            
        except Exception as e:
            print(f"  âŒ å¤„ç†å¤±è´¥: {e}")
    
    # ä¿å­˜å¢å¼ºåçš„æ ‡ç­¾æ–‡ä»¶
    aug_df = pd.DataFrame(augmented_data)
    aug_labels_file = os.path.join(output_dir, 'labels_augmented.csv')
    aug_df.to_csv(aug_labels_file, index=False, encoding='utf-8')
    
    print(f"\nğŸ“Š æ•°æ®å¢å¼ºå®Œæˆ:")
    print(f"  åŸå§‹æ ·æœ¬: {len(df)}")
    print(f"  å¢å¼ºæ ·æœ¬: {len(aug_df)}")
    print(f"  å¢å¼ºå€æ•°: {len(aug_df) / len(df):.1f}x")
    print(f"  è¾“å‡ºç›®å½•: {output_dir}")
    print(f"  æ ‡ç­¾æ–‡ä»¶: {aug_labels_file}")
    
    return aug_df

if __name__ == "__main__":
    # åˆ›å»ºå¢å¼ºæ•°æ®é›†
    augmented_df = create_augmented_dataset(
        input_dir='data/audio',
        labels_file='data/labels.csv', 
        output_dir='data/audio_augmented'
    )
    
    print("\nğŸ’¡ ä½¿ç”¨å¢å¼ºæ•°æ®é›†è®­ç»ƒ:")
    print("python batch_preprocess.py --audio_dir data/audio_augmented --labels_file data/audio_augmented/labels_augmented.csv --output_dir data/features_augmented")
    print("python train_small.py --config config_augmented.json")