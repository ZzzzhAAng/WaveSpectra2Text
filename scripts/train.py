#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ç»Ÿä¸€è®­ç»ƒè„šæœ¬
æ”¯æŒä¸åŒè§„æ¨¡çš„æ•°æ®é›†è®­ç»ƒ
"""

import sys
import os
import argparse

from wavespectra2text.training.config import ConfigManager, get_default_config
from wavespectra2text.training.trainer import create_trainer
from wavespectra2text.core.model import create_model
from wavespectra2text.core.vocab import vocab
from wavespectra2text.data.dataset import AudioDataset
from wavespectra2text.training.callbacks import CallbackList, EarlyStoppingCallback, CheckpointCallback, LoggingCallback, TensorBoardCallback


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description='WaveSpectra2Text è®­ç»ƒè„šæœ¬')
    parser.add_argument('--config', type=str, help='é…ç½®æ–‡ä»¶è·¯å¾„')
    parser.add_argument('--scale', type=str, choices=['small', 'medium', 'large', 'xlarge'], 
                        default='medium', help='æ•°æ®é›†è§„æ¨¡')
    parser.add_argument('--resume', type=str, help='æ¢å¤è®­ç»ƒçš„æ£€æŸ¥ç‚¹è·¯å¾„')
    parser.add_argument('--device', type=str, choices=['auto', 'cpu', 'cuda'], 
                        default='auto', help='è®¡ç®—è®¾å¤‡')
    
    args = parser.parse_args()
    
    # åŠ è½½é…ç½®
    if args.config and os.path.exists(args.config):
        config_manager = ConfigManager(args.config)
        config = config_manager.config
    else:
        config = get_default_config(args.scale)
    
    # è®¾ç½®è®¾å¤‡
    if args.device != 'auto':
        config['device'] = args.device
    
    print(f"ğŸ¯ WaveSpectra2Text è®­ç»ƒè„šæœ¬")
    print(f"ğŸ“Š æ•°æ®é›†è§„æ¨¡: {args.scale}")
    print(f"ğŸ”§ é…ç½®æ–‡ä»¶: {args.config or 'é»˜è®¤é…ç½®'}")
    print(f"ğŸ’» è®¡ç®—è®¾å¤‡: {config['device']}")
    print("=" * 60)
    
    # è®¾ç½®è®¾å¤‡
    import torch
    if config['device'] == 'auto':
        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    else:
        device = torch.device(config['device'])
    
    print(f"ä½¿ç”¨è®¾å¤‡: {device}")
    
    # åˆ›å»ºå¿…è¦ç›®å½•
    os.makedirs(config['checkpoint_dir'], exist_ok=True)
    os.makedirs(config['log_dir'], exist_ok=True)
    os.makedirs(config['tensorboard_log_dir'], exist_ok=True)
    
    try:
        # åˆ›å»ºæ•°æ®é›†
        dataset = AudioDataset(
            labels_file=config['labels_file'],
            audio_dir=config['audio_dir'],
            mode='realtime'
        )
        
        # åˆ†å‰²æ•°æ®é›†
        if config['validation_split'] > 0:
            from sklearn.model_selection import train_test_split
            
            # ç®€åŒ–æ•°æ®é›†åˆ†å‰²é€»è¾‘
            train_indices, val_indices = train_test_split(
                range(len(dataset)),
                test_size=config['validation_split'],
                random_state=config['random_seed']
            )
            
            from torch.utils.data import Subset
            train_dataset = Subset(dataset, train_indices)
            val_dataset = Subset(dataset, val_indices)
        else:
            train_dataset = dataset
            val_dataset = dataset
        
        # åˆ›å»ºæ•°æ®åŠ è½½å™¨
        from torch.utils.data import DataLoader
        from wavespectra2text.data.dataset import FlexibleDataLoader
        
        train_loader = FlexibleDataLoader.create_dataloader(
            train_dataset,
            batch_size=config['batch_size'],
            shuffle=config['shuffle'],
            num_workers=config['num_workers'],
            pin_memory=config['pin_memory']
        )
        
        val_loader = FlexibleDataLoader.create_dataloader(
            val_dataset,
            batch_size=config['batch_size'],
            shuffle=False,
            num_workers=config['num_workers'],
            pin_memory=config['pin_memory']
        )
        
        print(f"è®­ç»ƒé›†: {len(train_dataset)} æ ·æœ¬")
        print(f"éªŒè¯é›†: {len(val_dataset)} æ ·æœ¬")
        
        # åˆ›å»ºæ¨¡å‹
        model = create_model(
            vocab_size=vocab.vocab_size,
            hidden_dim=config['hidden_dim'],
            encoder_layers=config['encoder_layers'],
            decoder_layers=config['decoder_layers'],
            dropout=config['dropout']
        ).to(device)
        
        print(f"æ¨¡å‹å¤§å°: {sum(p.numel() for p in model.parameters())} å‚æ•°")
        
        # åˆ›å»ºè®­ç»ƒå™¨
        # å°†scaleå‚æ•°æ˜ å°„åˆ°è®­ç»ƒå™¨ç±»å‹
        scale_to_trainer = {
            'small': 'simple',
            'medium': 'improved', 
            'large': 'large',
            'xlarge': 'large'  # è¶…å¤§æ•°æ®é›†ä¹Ÿä½¿ç”¨largeè®­ç»ƒå™¨
        }
        trainer_type = scale_to_trainer.get(args.scale, 'simple')
        print(f"ğŸ¯ ä½¿ç”¨è®­ç»ƒå™¨: {trainer_type} (å¯¹åº”æ•°æ®é›†è§„æ¨¡: {args.scale})")
        trainer = create_trainer(trainer_type, model, train_loader, val_loader, device, config)
        
        # è®¾ç½®å›è°ƒ
        callbacks = CallbackList([
            EarlyStoppingCallback(patience=config['max_patience']),
            CheckpointCallback(
                filepath=os.path.join(config['checkpoint_dir'], 'checkpoint_epoch_{epoch}.pth'),
                save_every=config['save_every']
            ),
            LoggingCallback(log_dir=config['log_dir']),
            TensorBoardCallback(log_dir=config['tensorboard_log_dir'])
        ])
        
        callbacks.set_trainer(trainer)
        trainer.callbacks = callbacks
        
        # å¼€å§‹è®­ç»ƒ
        trainer.train(config['num_epochs'], args.resume)
        
    except Exception as e:
        print(f"âŒ è®­ç»ƒå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return


if __name__ == "__main__":
    main()
